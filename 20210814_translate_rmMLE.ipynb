{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Activation, MultiHeadAttention\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = '20210812_wmt19_cs_en'\n",
    "folder_name = '20210814_translate_rmMLE'\n",
    "\n",
    "wv_dim = 32\n",
    "en_que_pad = 30\n",
    "de_que_pad = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train = pickle.load(open(f'{d_name}/encoder_train.pkl', 'rb'))\n",
    "decoder_train = pickle.load(open(f'{d_name}/decoder_train.pkl', 'rb'))\n",
    "teacher_train = pickle.load(open(f'{d_name}/teacher_train.pkl', 'rb'))\n",
    "encoder_vali  = pickle.load(open(f'{d_name}/encoder_vali.pkl', 'rb'))\n",
    "decoder_vali  = pickle.load(open(f'{d_name}/decoder_vali.pkl', 'rb'))\n",
    "teacher_vali  = pickle.load(open(f'{d_name}/teacher_vali.pkl', 'rb'))\n",
    "\n",
    "decoder_idx2word   = pickle.load(open(f'{d_name}/en_idx2word.pkl','rb'))\n",
    "decoder_word2idx   = pickle.load(open(f'{d_name}/en_word2idx.pkl','rb'))\n",
    "encoder_idx2word   = pickle.load(open(f'{d_name}/cs_idx2word.pkl','rb'))\n",
    "encoder_word2idx   = pickle.load(open(f'{d_name}/cs_word2idx.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52575\n",
      "52573\n"
     ]
    }
   ],
   "source": [
    "num_decoder_words = np.max([np.max(decoder_train), np.max(decoder_vali)])+1\n",
    "num_encoder_words = np.max([np.max(encoder_train), np.max(encoder_vali)])+1\n",
    "\n",
    "print(num_decoder_words)\n",
    "print(num_encoder_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(seq_tensor, idx2word):\n",
    "    return np.array([' '.join([idx2word[str(i)] for i in seq]) for seq in seq_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "seq2word(decoder_vali[:10], decoder_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "[Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "(1, 10, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 22:49:47.881643: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-08-14 22:49:47.881713: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n, d = 10, 64\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OneHot relaxation](https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/RelaxedOneHotCategorical)\n",
    "based on [Jang+16](https://arxiv.org/abs/1611.01144) and [Maddison+16](https://arxiv.org/abs/1611.00712) \n",
    "<br>\n",
    "[Multi-Head Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) \n",
    "and [Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: It leaks the answer\n",
    "def MHA(en_que_pad, de_que_pad, wv_dim, rate = 0.1, mask = True):\n",
    "    # Inputs\n",
    "    en_in = Input((en_que_pad, wv_dim))\n",
    "    mem = Input((de_que_pad, wv_dim))\n",
    "    # Constants\n",
    "    ff_dim = wv_dim*16\n",
    "    # Make q, k, v\n",
    "    q = Dense(wv_dim)(mem)\n",
    "    k = Dense(wv_dim)(en_in)\n",
    "    peq = positional_encoding(de_que_pad, wv_dim)\n",
    "    pek = positional_encoding(en_que_pad, wv_dim)\n",
    "    # Position encoding\n",
    "    q = tf.keras.layers.Add()([q, peq])\n",
    "    k = tf.keras.layers.Add()([k, pek])\n",
    "    v = k\n",
    "    m = None\n",
    "    mem_new = mem\n",
    "    if mask:\n",
    "        m = np.tri(de_que_pad, en_que_pad, 0)\n",
    "        mem_new = MultiHeadAttention(\n",
    "            num_heads = 4, \n",
    "            key_dim = wv_dim, \n",
    "            value_dim = wv_dim\n",
    "        )(\n",
    "            q, k,\n",
    "            attention_mask = m,\n",
    "        )\n",
    "    else:\n",
    "        m = np.ones((de_que_pad, en_que_pad))\n",
    "        mem_new = MultiHeadAttention(\n",
    "            num_heads = 4, \n",
    "            key_dim = wv_dim, \n",
    "            value_dim = wv_dim\n",
    "        )(\n",
    "            q, k, v,\n",
    "            attention_mask = m,\n",
    "        )\n",
    "    #mem_new = Dropout(rate)(mem_new)\n",
    "    mem_new = LayerNormalization(epsilon=1e-6)(mem_new+mem)\n",
    "    # Feed-Forward skip-connection\n",
    "    ffn = Dense(ff_dim, activation = 'relu')(mem_new)\n",
    "    ffn = Dense(wv_dim)(ffn)\n",
    "    #ffn = Dropout(rate)(ffn)\n",
    "    out = LayerNormalization(epsilon=1e-6)(ffn+mem_new)\n",
    "    model = Model(\n",
    "        [en_in, mem],\n",
    "        out\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getG():\n",
    "    # Encoder\n",
    "    en_input = Input((en_que_pad,))\n",
    "    en_emb = Embedding(\n",
    "        num_encoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length = en_que_pad,\n",
    "        trainable = True,\n",
    "    )\n",
    "    vector_encoder = en_emb(en_input)\n",
    "    en_output = vector_encoder\n",
    "    \n",
    "    # Deocder\n",
    "    de_input = Input((de_que_pad,))\n",
    "    de_emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length = de_que_pad,\n",
    "        trainable = True,\n",
    "    )\n",
    "    vector_decoder = de_emb(de_input)   \n",
    "    de_output = vector_decoder\n",
    "    \n",
    "    for i in range(1):\n",
    "        # Encoding\n",
    "        mhaLayer = MHA(en_que_pad, en_que_pad, wv_dim, mask = False)\n",
    "        en_output = mhaLayer((vector_encoder, en_output))\n",
    "        en_output = Activation('relu')(en_output)\n",
    "    \n",
    "        # Decoding\n",
    "        mhaLayer = MHA(de_que_pad, de_que_pad, wv_dim)\n",
    "        de_output = mhaLayer((vector_decoder, de_output))\n",
    "        de_output = Activation('relu')(de_output)\n",
    "        \n",
    "        # Combine\n",
    "        mhaLayer = MHA(en_que_pad, de_que_pad, wv_dim, mask = False)\n",
    "        de_output = mhaLayer((en_output, de_output))\n",
    "        de_output = Activation('relu')(de_output)\n",
    "    \n",
    "    # Concatenation and output\n",
    "    de_output = Dense(num_decoder_words)(de_output)\n",
    "    output = Activation('softmax')(de_output)\n",
    "    model = Model(\n",
    "        [en_input, de_input], \n",
    "        output,\n",
    "    ) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 32)       1682336     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 32, 32)       1682400     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 30, 32)       52352       embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 32, 32)       52352       embedding_1[0][0]                \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 30, 32)       0           model[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32)       0           model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 32, 32)       52352       activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32)       0           model_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32, 52575)    1734975     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 52575)    0           dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,256,767\n",
      "Trainable params: 5,256,767\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleG=getG()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 22:49:48.282415: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-14 22:49:48.282592: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-08-14 22:49:48.827493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 8.8411 - accuracy: 0.2749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-14 22:50:54.261340: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 69s 425ms/step - loss: 8.8411 - accuracy: 0.2749 - val_loss: 6.8219 - val_accuracy: 0.4568\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacob975/miniforge3/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 69s 432ms/step - loss: 5.4527 - accuracy: 0.4384 - val_loss: 4.3996 - val_accuracy: 0.4568\n",
      "Epoch 3/300\n",
      "160/160 [==============================] - 67s 419ms/step - loss: 4.0336 - accuracy: 0.4688 - val_loss: 3.7477 - val_accuracy: 0.5143\n",
      "Epoch 4/300\n",
      "160/160 [==============================] - 65s 404ms/step - loss: 3.5609 - accuracy: 0.5197 - val_loss: 3.3096 - val_accuracy: 0.5651\n",
      "Epoch 5/300\n",
      "160/160 [==============================] - 69s 429ms/step - loss: 2.7653 - accuracy: 0.6084 - val_loss: 2.2277 - val_accuracy: 0.6925\n",
      "Epoch 6/300\n",
      "160/160 [==============================] - 74s 460ms/step - loss: 1.7471 - accuracy: 0.7443 - val_loss: 1.5053 - val_accuracy: 0.8059\n",
      "Epoch 7/300\n",
      "160/160 [==============================] - 68s 423ms/step - loss: 1.1415 - accuracy: 0.8341 - val_loss: 1.1423 - val_accuracy: 0.8628\n",
      "Epoch 8/300\n",
      "160/160 [==============================] - 66s 413ms/step - loss: 0.7958 - accuracy: 0.8855 - val_loss: 0.9385 - val_accuracy: 0.8950\n",
      "Epoch 9/300\n",
      "101/160 [=================>............] - ETA: 25s - loss: 0.5973 - accuracy: 0.9146"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zh/f93mc8qj0gn6jf1xs02wnwk40000gn/T/ipykernel_54503/1537406456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mleG.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m#[encoder_train, decoder_train],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#teacher_train,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mencoder_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10240\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10240\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mteacher_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10240\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mleG.fit(\n",
    "    #[encoder_train, decoder_train], \n",
    "    #teacher_train, \n",
    "    [encoder_train[:10240], decoder_train[:10240]], \n",
    "    teacher_train[:10240],\n",
    "    batch_size=64, \n",
    "    epochs=300, \n",
    "    shuffle=True, \n",
    "    validation_data = (\n",
    "        #[encoder_vali, decoder_vali], \n",
    "        #teacher_vali,\n",
    "        [encoder_vali[:640], decoder_vali[:640]], \n",
    "        teacher_vali[:640],\n",
    "    ), \n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            f'./{folder_name}/mleG.h5', \n",
    "            save_best_only=True, \n",
    "            monitor = \"val_loss\"\n",
    "        ),\n",
    "        EarlyStopping(monitor='val_loss', patience=5),\n",
    "        CSVLogger(f'{folder_name}/mleG.csv'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    enData = None,\n",
    "    inpData = None,\n",
    "    start_on = 0,\n",
    "    batch_size = 10,\n",
    "):\n",
    "    # Initialize\n",
    "    num_data = len(enData)\n",
    "    num_batch = (num_data-1)//batch_size +1\n",
    "    print(num_batch)\n",
    "    resp_pred_list = None\n",
    "    in_batch_list = None\n",
    "    the_first = True\n",
    "    #idx = np.arange(num_words)\n",
    "    for b in range(num_batch):\n",
    "        in_batch = np.zeros((batch_size, de_que_pad), dtype = int)\n",
    "        en_batch = np.zeros((batch_size, en_que_pad), dtype = int)\n",
    "        if start_on == 0:\n",
    "            in_batch[:,0] = decoder_word2idx['bos']\n",
    "        else:\n",
    "            in_batch = inpData[b*batch_size:(b+1)*batch_size]\n",
    "            en_batch = enData[ b*batch_size:(b+1)*batch_size]\n",
    "        resp_pred = np.zeros((batch_size, de_que_pad), dtype = int)\n",
    "        # Generate the sequence recurrsively.\n",
    "        for i in range(start_on, de_que_pad):\n",
    "            #print(i)\n",
    "            # Run\n",
    "            resp_pred_wv = model([en_batch, in_batch])\n",
    "            the_last = resp_pred_wv[:,i]\n",
    "            #We the_last = tf.keras.backend.argmax(the_last).numpy()\n",
    "            the_last = tf.reshape(\n",
    "                tf.random.categorical(tf.math.log(the_last), 1), \n",
    "                [batch_size,]\n",
    "            )\n",
    "            try:\n",
    "                resp_pred[:,i] = the_last\n",
    "                in_batch[:,i+1] = the_last\n",
    "            except:\n",
    "                resp_pred[:,i] = the_last\n",
    "        for i in range(len(resp_pred)):\n",
    "            try:\n",
    "                index = list(resp_pred[i]).index(decoder_word2idx['eos'])\n",
    "            except:\n",
    "                continue\n",
    "            resp_pred[i,index+1:] = 0\n",
    "            in_batch[i,index+1:] = 0\n",
    "        if the_first:\n",
    "            resp_pred_list = resp_pred\n",
    "            in_batch_list = in_batch\n",
    "            the_first = False\n",
    "        else:\n",
    "            resp_pred_list = np.vstack((resp_pred_list, resp_pred))\n",
    "            in_batch_list = np.vstack((in_batch_list, in_batch))\n",
    "    resp_pred_list = resp_pred_list[:num_data]\n",
    "    in_batch_list = in_batch_list[:num_data]\n",
    "    if start_on != 0:\n",
    "        resp_pred_list[:,:start_on] = inpData[:,1:start_on+1]\n",
    "        in_batch_list[:, :start_on+1] = inpData[:,:start_on+1]\n",
    "    return resp_pred_list, in_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG,\n",
    "    encoder_vali[:16],\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s\\xa0usa za dne vyšší bez než nebo říct podle a nad rozvojové to – malárie nebo zůstává pad pad pad pad pad pad pad pad pad pad pad pad pad']\n",
      "['eos pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad']\n"
     ]
    }
   ],
   "source": [
    "print(seq2word(encoder_vali[2:3], encoder_idx2word))\n",
    "print(seq2word(teacher_pred[2:3], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
