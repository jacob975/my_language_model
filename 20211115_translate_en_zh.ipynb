{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Activation, Dropout\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# If you have more than 1 GPU, you might want to specify which GPU for training.\n",
    "# In this case, I have 2 GPU and the second one is RTX 2080ti, so I pick the `second` one.\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' # The second\n",
    "tf.config.set_soft_device_placement(True)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = '20211112_wmt19_en_zh'\n",
    "folder_name = '20211115_translate_mle_en_zh'\n",
    "\n",
    "encoder_wv_dim = 16\n",
    "decoder_wv_dim = 8\n",
    "encoder_que_pad = 88\n",
    "decoder_que_pad = 279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train = pickle.load(open(f'{d_name}/encoder_train.pkl', 'rb'))\n",
    "decoder_train = pickle.load(open(f'{d_name}/decoder_train.pkl', 'rb'))\n",
    "teacher_train = pickle.load(open(f'{d_name}/teacher_train.pkl', 'rb'))\n",
    "encoder_vali  = pickle.load(open(f'{d_name}/encoder_vali.pkl', 'rb'))\n",
    "decoder_vali  = pickle.load(open(f'{d_name}/decoder_vali.pkl', 'rb'))\n",
    "teacher_vali  = pickle.load(open(f'{d_name}/teacher_vali.pkl', 'rb'))\n",
    "\n",
    "decoder_idx2word   = pickle.load(open(f'{d_name}/en_idx2word.pkl','rb'))\n",
    "decoder_word2idx   = pickle.load(open(f'{d_name}/en_word2idx.pkl','rb'))\n",
    "encoder_idx2word   = pickle.load(open(f'{d_name}/zh_idx2word.pkl','rb'))\n",
    "encoder_word2idx   = pickle.load(open(f'{d_name}/zh_word2idx.pkl','rb'))\n",
    "\n",
    "decoder_emb8    = pickle.load(open(f'{d_name}/en_emb8.pkl', 'rb'))\n",
    "encoder_emb16   = pickle.load(open(f'{d_name}/zh_emb16.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "4716\n"
     ]
    }
   ],
   "source": [
    "num_decoder_words = np.max([np.max(decoder_train), np.max(decoder_vali)])+1\n",
    "num_encoder_words = np.max([np.max(encoder_train), np.max(encoder_vali)])+1\n",
    "\n",
    "print(num_decoder_words)\n",
    "print(num_encoder_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(seq_tensor, idx2word):\n",
    "    return np.array([[idx2word[i] for i in seq] for seq in seq_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['<bos>', '1', '9', '2', '9', ' ', 'o', 'r', ' ', '1', '9', '8',\n",
       "        '9', '?', '<eos>', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']], dtype='<U5')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(decoder_vali[:1], decoder_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '9', '2', '9', '年', '还', '是', '1', '9', '8', '9', '年', '?',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',\n",
       "        ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']], dtype='<U1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(encoder_vali[:1], encoder_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "[Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhzUlEQVR4nO3de5RcZZnv8e+vuxOBcDcQQxIFnAyKHECNoOJBEPCEDBL0iIKKiDgRDxnR5Tkj4iyd0TVjxhkvODJgBoGoyEUUzGjkYhQBFU1A5I7EcAuJuQEhgUAu/Zw/9m4sK9VdVV273rr9Pmvt1bWvz7sD6+m3n3r3uxURmJlZb+hrdQPMzCwdJ30zsx7ipG9m1kOc9M3MeoiTvplZD3HSNzPrIU76ZmZNJOkiSask3T3Mfkn6mqQlku6U9JqSfdMlPZDvO7uI9jjpm5k11yXA9BH2HwtMzZdZwPkAkvqB8/L9+wMnS9q/0cY46ZuZNVFE3AQ8McIhM4FvReZWYFdJE4FDgCURsTQiNgGX58c2ZKDRC6Sgge1CY3dsdTPMrAPExrVrImKPRq7Rt/PkYMtztcS6Byg9cG5EzK0z3CTgsZL1Zfm2StsPrfPa2+iMpD92Rwb2O77VzTCzDrD5josfafgiW56rKedsvuPi5yJiWoPRVGFbjLC9IR2R9M3MkpJQX3+qaMuAKSXrk4HlwNhhtjfENX0zs22IvoGxVZeCzAfen4/ieT2wLiJWAIuAqZL2kTQWOCk/tiHu6ZuZlSuwpy/pMuAIYLykZcBngTEAEXEBsACYASwBngVOy/dtkTQbuA7oBy6KiHsabY+TvplZGQHqLybpR8TJVfYHcOYw+xaQ/VIojJO+mVk5ib50Nf2knPTNzCpI+EVuUk76Zmbl0o7eScpJ38ysjBB9A2Na3YymcNI3MyvXxT39po7Tl7SrpKsk3S/pPklvkLS7pBskPZj/3K2ZbTAzGw319VddOlGzH846F7g2Il4BHATcB5wNLIyIqcDCfN3MrH1IqL+/6tKJmpb0Je0MHA58EyAiNkXEU2SzxM3LD5sHnNCsNpiZjYbo3p5+M2v6+wKrgYslHQTcBpwFTMgfMSYiVkjas9LJkmaRzS0NY8Y1sZlmZmXUR39x0yy0lWaWdwaA1wDnR8SrgWeoo5QTEXMjYlpETNPAds1qo5nZttS9Pf1mJv1lwLKI+E2+fhXZL4GV+QsCyH+uamIbzMzqJuSkX6+I+BPwmKT98k1HAfeSzRJ3ar7tVOCHzWqDmdlodWvSb/Y4/b8DLs2nBV1KNntcH3ClpNOBR4ETm9wGM7P6dPE4/aYm/Yi4A6j0VpmjmhnXzKwxTvpmZj1DEn1junP0jpO+mVk5l3fMzHqLk76ZWQ/p61Orm9AUTvpmZmUkISd9M7Pe0d9fzGNMkqaTTT7ZD1wYEXPK9v8/4L356gDwSmCPiHhC0sPAemArsCUiKo2GrIuTvplZOVFIT19SP3AecAzZLAWLJM2PiHuHjomIfwP+LT/+bcDHI+KJksscGRFrGm5MrtlTK5uZdZxslk1VXWpwCLAkIpZGxCbgcrKZhodzMnBZ43cwPCd9M7NtiD5VX4DxkhaXLLPKLjQJeKxkfVm+bduI0g7AdOD7JZsDuF7SbRWuPSou75iZlau9vLOmSp290kVimGPfBvyyrLRzWEQsz6egv0HS/RFxUy0NG457+mZmFRRU3lkGTClZnwwsH+bYkygr7UTE8vznKuBqsnJRQ5z0zczKSNA/oKpLDRYBUyXtk088eRLZTMNl8bQL8GZKZh2WNE7STkOfgbcCdzd6by7vmJlVIDU+eicitkiaDVxHNmTzooi4R9IZ+f4L8kPfDlwfEc+UnD4BuDpvxwDw3Yi4ttE2OembmZWRVNgTuRGxAFhQtu2CsvVLgEvKti0FDiqkESWc9M3MKvATuWZmPcRJ38ysV4ihcfhdx0nfzKyMEH0D3Tm40UnfzKycPLWymVlPKWLIZjty0jczK5NNuNbqVjSHk76ZWTmXd8zMeonoK+glKu3GSd/MrIzc0zcz6y1+OGsUKr3fUdLuwBXA3sDDwLsi4slmtsPMrB4S9Hdp0k9RtDoyIg4uedHA2cDCiJgKLMzXzczaSn+fqi6dqBXfVMwE5uWf5wEntKANZmbDEtUTfqcm/WbX9Ife7xjANyJiLjAhIlYARMSK/DVg28jfB5m9E3LMuCY308zszyQY62kYRmWb9zvWemL+C2IuQN8O44d7p6SZWeEkGOjQnnw1TU36pe93lDT0fseVkibmvfyJwKpmtsHMrF7CX+TWbYT3O84HTs0PO5WSd0KambUFdW9Nv5lFqwnALZJ+D/wW+HH+fsc5wDGSHgSOydfNzNpG1tPvq7rUdC1puqQHJC2RtM1oRUlHSFon6Y58+Uyt545G08o7w73fMSLWAkc1K66ZWRGK6MlL6gfOI+vgLgMWSZofEfeWHXpzRBw3ynPr4idyzczK9ElFjd45BFiSd4KRdDnZsPVaEncj5w6rO8ckmZk1qF+qugDjJS0uWWaVXWYS8FjJ+rJ8W7k3SPq9pJ9IelWd59bFPX0zszJ1TMOwpmS2gYqXqrCtfAj67cDLImKDpBnANcDUGs+tm3v6ZmYVFDR6ZxkwpWR9MrC89ICIeDoiNuSfFwBjJI2v5dzRcE/fzKxMgQ9nLQKmStoHeBw4CXjPX8bSS4CVERGSDiHrjK8Fnqp27mg46Zv1KPX1t7oJbUsU80VuRGyRNBu4DugHLoqIeySdke+/AHgn8BFJW4CNwEkREUDFcxttk5O+mVmZIqdWzks2C8q2XVDy+evA12s9t1FO+mZmZbp5GgYnfbMqurUM0q33VYgufomKk76ZWZmh+fS7kZO+mVkFTvpmNejGkkHKe+raWP2d9f9Fn1+iYmbWQ1zTNzPrHeKFuXW6jpO+mVkFfU761qlcZ29M38DYZLFS1r77E95X38CYZLGKIKC/O3O+k76Z2TYEfa7pm5n1BgFjanwdYqdx0rdCpSqF9I1JV5ro1jJI/9jtk8Uas/2OyWKtK+AaLu+YmfUSyeUdM7NeITx6x8ysp7i8Y4Xq1iGHqWrtAwnr0QPbjUsWa+y4XZLFGpMw1ovGpavpryzgGhKM6fcXuWZmPcHlHTOzHuPyzihJ6gcWA49HxHGSdgeuAPYGHgbeFRFPNrsd7SZpeSfh8MaxO+ycJE7K0sR2u+yRLNYOu6T59wPYcdftujLWkgKuIVRYT1/SdOBcsvfcXhgRc8r2vxf4ZL66AfhIRPw+3/cwsB7YCmyJiGmNtidF0eos4L6S9bOBhRExFViYr5uZtY98ls1qS9XLZJ3e84Bjgf2BkyXtX3bYQ8CbI+JA4PPA3LL9R0bEwUUkfGhy0pc0Gfgb4MKSzTOBefnnecAJzWyDmVm9spp+9aUGhwBLImJpRGwCLifLgS+IiF+VVDtuBSYXeCvbaHZ556vA3wM7lWybEBErACJihaQ9K50oaRYwC4AxaUZPdOuImlQlF0hXChm3x15J4gDsuke60TsvnpBulMurJqUrkR00OV2sXxRwjTqmYRgvaXHJ+tyIKO2pTwIeK1lfBhw6wvVOB35Ssh7A9ZIC+EbZtUelaUlf0nHAqoi4TdIR9Z6f39xcgL4dxkexrTMzG4GgxhGba6qUXSr9PVAxn0k6kizpv6lk82ERsTzvHN8g6f6IuKmmlg2jmT39w4DjJc0AtgN2lvQdYKWkiXkvfyKwqoltMDOrW4FDNpcBU0rWJwPLt4knHUhWBj82ItYObY+I5fnPVZKuJisXNZT0m1bTj4hPRcTkiNgbOAn4WUS8D5gPnJofdirww2a1wcxsdLI3Z1VbarAImCppH0ljyXLh/L+IJL0U+AFwSkT8oWT7OEk7DX0G3grc3eidtWKc/hzgSkmnA48CJ7agDRWlrOmnnHUw5ZDDXSe/NEmcPSen+57itX81Plmsw/bdPVmsg16yU/WDCjJlu63JYn2ggGsU1dOPiC2SZgPXkQ3ZvCgi7pF0Rr7/AuAzwIuB/1QWc2ho5gTg6nzbAPDdiLi20TYlSfoRcSNwY/55LXBUirhmZqORTcNQzDj9iFgALCjbdkHJ5w8BH6pw3lLgoEIaUcJP5JqZVdClszA46ZdKWd4Zu9NuyWKlKrkA7LNfmlLIO14zKUkcgCP2SVdyedmfv8Nruq2/uzJZrOXX35gsVlH6Kg686XxO+mZmZYR7+mZmPaVLX5zlpG9mtg25p98TBl6U7sUc4/bovjo7wBmH75skzlv3TjfckFsuTxbqwe9ckyzWXdf+MVmsRU8+lyxWEUTN4/A7jpO+mVkFLu+YmfWQLs35TvqlxiScjXLivt1XcgGYsdv6JHFW/Munk8QB+NXcXyeLddOaZ5PFSlm+OHrPdDOVfulPjV+j51+XKOlFwP8me9vVC+dExOea0ywzs9bq0pxfc0//h8A64Dbg+eY1x8ysPaR4rWAr1Jr0J0fE9Ka2pA1sv9tLksWa+YZ0o3dSlVwA7p49O0mcy/77wSRxADZuTfc6h5MOTfek8RsvnlP9oIJcsXGfZLF4zZTqx1Sh/HWJ3ajWX2a/kvQ/mtoSM7M2IlVfOtGIPX1Jd5G95WUAOE3SUrLyjoDIX+RrZtZVRO+Wd45L0gozszajTu3KVzFi0o+IRwAkfTsiTindJ+nbwCkVT+xQu09JV089/bXpYt192tuTxbrgBw8kiXP4+B2SxAF4983fSBbrI3eme9J4+ofmJYu1/W4TksUqhPxw1qtKVyT1A68tvjlmZq0noKB3qLSdEctWkj4laT1woKSnJa3P11fhd9uaWReTVHXpRNXKO18AviDpCxHxqURtapmDD0z3J+jY7/1LslipSi4AHzr25UnirP3KZUniAOx8+heSxXrp645MFuvpyz6YLNac/d6RLNY/FHCN7IncAi4ESJoOnEv2jtwLI2JO2X7l+2cAzwIfiIjbazl3NGot75wj6R3Am8hG89wcEdc0GtzMrF0VkfPzUvh5wDHAMmCRpPkRcW/JYccCU/PlUOB84NAaz61braOSzgPOAO4C7gbOkHReI4HNzNqX6FP1pQaHAEsiYmlEbAIuB2aWHTMT+FZkbgV2lTSxxnPrVmtP/83AARERAJLmkf0CMDPrPsU9fDUJeKxkfRlZb77aMZNqPLdutSb9B4CXAo/k61OAOxsNXqtXv+Kl/PKX3faHxauqH1KQr74n3YyU3WjtDem+f0lpc8JYn1ibLF3wDzs0PpxXEWhway2Hjpe0uGR9bkTMLb1UhXPK5/UY7phazq1brUn/xcB9kn6br78O+LWk+QARcXyjDTEzayeKwVoOWxMR00bYv4yskzxkMrC8xmPG1nBu3WpN+p9pNJCZWecIqC3pV7MImCppH+Bx4CTgPWXHzAdmS7qcrHyzLiJWSFpdw7l1qynpR8QvJL0MmBoRP5W0PTAQEcNO3yhpO+Am4EV5nKsi4rOSdgeuIJub/2HgXRHxZGO3YWZWsGh8dtWI2CJpNnAd2bDLiyLiHkln5PsvABaQDddcQjZk87SRzm20TbW+ROVvgVnA7sDLyf7MuAA4aoTTngfeEhEbJI0BbpH0E+AdwMKImCPpbOBs4JMN3IOZWbGisJ4+EbGALLGXbrug5HMAZ9Z6bqNqHbJ5JnAY8HTekAeBPUc6IR9+tCFfHZMvQTbkaGjSj3nACfU12cys+RSDVZdOVGvSfz4fJwqApAFq+BZZUr+kO8imbbghIn4DTIiIFQD5z4q/PCTNkrRY0uLVa9bU2EwzsyIEDG6pvnSgWpP+LySdA2wv6Rjge8B/VzspIrZGxMFk5aBDJB1Qa8MiYm5ETIuIaXuMT/cScTMzgqy8U23pQLUm/bOB1WQPZH2YrMZU8xQXEfEUcCMwHViZP21G/nNV7c01M0shYHCw+tKBah29MyjpGuCaiFhdyzmS9gA2R8RT+Wifo4F/JRuedCowJ//p2TrNrO10as2+mmqvSxTwWWA22dNhkrQV+I+I+FyVa08E5uWTBvUBV0bEjyT9GrhS0unAo8CJjd6EmVnhejHpAx8jG7Xzuoh4CEDSvsD5kj4eEV8Z7sSIuBN4dYXtaxl5qKeZWWtFQG3TMHScajX99wMnDyV8gIhYCrwv32dm1pW6dchmtZ7+mIjYZrxkRKzOH7gyM+tCxT2c1W6qJf1No9xnZtbZejTpHyTp6QrbBWzXhPaYmbVegdMwtJtq78jtT9UQM7N2IXp0yKaZWRGioNdQpROwtTtH7zjpm5mVG5qGoQs56ZuZVeDyjpk1XeeVQbpVj36Ra2bWs5z0zcx6RBdPw+Ckb1aFSy69KIgtm1vdiKaodT59M7PeEWQ9/WpLgyTtLukGSQ/mP3ercMwUST+XdJ+keySdVbLvHyU9LumOfJlRLaaTvplZmSCIrVurLgU4G1gYEVOBhfl6uS3AJyLilcDrgTMl7V+y/ysRcXC+VH2JupO+mVm5INWbs2YC8/LP84ATtmlKxIqIuD3/vB64D5g02oCu6VuhXP+27lDzF7njJS0uWZ8bEXPrCDQhIlZAltwl7TnSwZL2JntPyW9KNs+W9H5gMdlfBE+OdA0nfTOzclHzF7lrImLaSAdI+inwkgq7Pl1PkyTtCHwf+FhEDE2EeT7webK/TT4PfAn44EjXcdI3M9tGEAUN2YyIo4fbJ2mlpIl5L38isGqY48aQJfxLI+IHJddeWXLMfwE/qtYeJ/0e4JKLVRLR6ha0saHRO803HzgVmJP//GH5Afm7yr8J3BcRXy7bN3GoPAS8Hbi7WkB/kWtmto1I9UXuHOAYSQ8Cx+TrSNpL0tBInMOAU4C3VBia+UVJd0m6EzgS+Hi1gO7pm5mVC4oakjlymIi1wFEVti8HZuSfbyGb4r/S+afUG9NJ38xsG56GwaxnufbduMFO+0esffROx3HSNzPbhnv6Zma9I93oneSalvQlTQG+RfZQwiDZk2rnStoduALYG3gYeFe1J8i6kYdRNqbTqgW16rgySI067a6CIIoZndN2mjlkc7hJgmqZYMjMrHUSzbLZCk3r6ecPDAzNKbFe0tAkQTOBI/LD5gE3Ap9sVjvMzOoWQWze1OpWNEWSmn7ZJEE1TTAkaRYwC2DKlCkpmmkFSFWdcBmkswx23I1FUQ9ftZ2mP5E7zCRBVUXE3IiYFhHT9hg/vnkNNDOrxOWd+g0zSVBNEwyZmbVMFDfhWrtpWk9/hEmChiYYgmEmGDIza7UYHKy6dKJm9vSHJgm6S9Id+bZzyCYUulLS6cCjwIlNbENdunUYZcrydzfW2lPeUcrad3Thf6vCRBBbOzOpV9PM0TvDThJEhQmGzMzaRUQwuHlLq5vRFH4i18ysXOCevhWrW0suqSJ1axkk6X2lC9WBQzad9M3MekZEMJhgPv1WcNI3M6ugU0fnVOOkb2ZWzqN3rJN1Y+02ZZ19a9LvX9LFSvpdRbJIxUg1eqfWWYclPQysB7YCWyJiWj3nl/KL0c3MKhjcOlh1KUA9sw4fGREHDyX8UZwPOOmbmW0rH7JZbSnATLLZhsl/ntDs813eKdGtwyhTlgy2JgqWsmSV6p4gbSkp5X11Wnmnjpr+eEmLS9bnRsTcOiLVNOsw2f/y10sK4BslMWo9/wVO+mZmZYKaR++sKSu3bEPST8neIFju03U06bCIWJ4n9Rsk3R8RN9Vx/guc9M3MykUwuKmYL3Ij4ujh9kmqadbhiFie/1wl6WrgEOAmRjFrsZN+i7g80WicdPe0JWHNJWl5J+UIqE6r7wQMphmnPzTr8ByGmXVY0jigL38D4TjgrcDnaj2/nL/INTMrE0SqL3LnAMdIehA4Jl9H0l6SFuTHTABukfR74LfAjyPi2pHOH4l7+mZm5QIiwTQMEbGWCrMO5+WcGfnnpcBB9Zw/Eid9M7NthKdh6AUph1F2Y50dYEui+9qc8N8v1T1B4vtKOJ/Y5k5LoJ5a2cysd0QEWwsavdNunPTNzLbh8k5PSDqMsgtLLgCbEt1YqjipYz23JV2ieXZzuvpOyliFcHnHzKyHBETKnllCTvpmZmWCKGoWzbbjpG9mVi4gOvHFvjVw0i+R8r9xyqF5SWvSiXpHGzen64Wtfz5dPXpDwhEj6zelu6+nn9ucLFYRImBrwn+flJz0zczKRbimb2bWSwad9Osj6SLgOGBVRByQb6v7fY4ppXxKNuXMjalKLgBPP5fmT+InNqYrF6x7Pl3J5cmE97Vmw/PJYq3dsClZrEJ08ZDNZs6yeQkwvWxb3e9zNDNLLYDBwai6dKKm9fQj4iZJe5dtngkckX+eB9wIfLJZbTAzG5UIf5FbkJrf5yhpFjALYMqUKUkal7KE91zCYKlKLgArn0nzZ/yqZ9KVJlasey5drKcSxlq3MVmstQn/DYsQXfxwVtu+RCUi5kbEtIiYtsf48a1ujpn1kjzpV1s6Ueqeft3vczQzS697n8hN3dMfep8j1Pg+RzOz5PIncqstnaiZQzYvI/vSdrykZcBnyd7feKWk04FHgRObFX80Uj65ujHhbIqp6uwAjyWqEz+4ckOSOACPrH0mWayVq59NFmtDwpr+hoTfVRQhSDNOv5Zh7JL2y48Zsi/wmYj4qqR/BP4WWJ3vOyciFjCCZo7eOXmYXXW9z9HMLLkIBtOM3hkaxj5H0tn5+l+MaIyIB4CDAST1A48DV5cc8pWI+PdaA7btF7lmZq0SkfX0qy0FmEk2fJ385wlVjj8K+GNEPDLagJ6GocSmhF/crO7CkgvAncvWJYlzf6I4AE+uSldKWrcmXXnnmdWPJov1/Lo1yWIVJdGbs2oexp47CbisbNtsSe8HFgOfqDbLgXv6ZmblonovP+/pj5e0uGSZVX4pST+VdHeFZWY9TZI0Fjge+F7J5vOBl5OVf1YAX6p2Hff0zczK1f5w1pqImDbipSKOHm6fpHqGsR8L3B4RK0uu/cJnSf8F/Khag93TNzMrE2QTrlVbClDPMPaTKSvt5L8ohrwduLtaQPf0S2zckm7I5uNPp5tGIFWdHeDOJWuTxFn1WLp7Wrf8oWSxNq5dnizWpmfS/RvGYIfNYxPB1k1JavoVh7FL2gu4MCJm5Os7AMcAHy47/4uSDib7PfVwhf3bcNI3MysTAYPR/E5gRKylwjD2iFgOzChZfxZ4cYXjTqk3ppO+mVkFWxMk/VZw0i/xdMKXZTywcn2yWKlKLgCPL1ld/aACPPXwXUniAGx8cmX1gwqSsgzyop12TxZr50l/nSzW8jsubvgaQdpZd1Ny0jczq8A9fTOzHjEYsKlDJ1Srxkm/xIr16UbULHroiWSxUpVcAFbff2uSOJsTjjxJWQYZ/4rXJ4t1wLRJyWL9n8P3TRZrxuVVB7DUxOUdM7MeEYTLO2ZmvcJf5JqZ9Rgn/R7w0JPpZjhctiRdTT9VnR3S1drH//XrksQBeO1RByeLNedtr0oWa79V6f6/uP/zH0wWqwgRHr1jZtYzAo/eMTPrGa7p94g7E07i9af770wWK+Xwxpe98W1J4vzzhw9NEgfgHVF14sLC3PK2/5Us1n/eviJZrF3G9CeLVRSXd8zMekRW0291K5rDSd/MrAL39M3MekQA6d6YnZaTfol7Hkz38ub1K/6YLFaqOjvAdf807JvhCrX5nFOrH1SQsy68PVmsA3beLlmsr9z8xWSx/nnDgcliMf2VDV8iCI/eMTPrFdnoHSd9M7Pe4C9yiyVpOnAu0E/2Hsg5rWhHuRV/eCxZrB0n7J0sVqqSC8AfDj08SZzrHnkqSRxIWwY58ubxyWJ97KOXVT+oIF/46muTxSqCe/oFktQPnEf2kt9lwCJJ8yPi3tRtMTMbjnv6xTkEWBIRSwEkXQ7MBJz0zawtDNK90zAoEv8JI+mdwPSI+FC+fgpwaETMLjtuFjArXz0ASPdYZDrjgXRDhtLoxnuC7ryvbrwngP0iYqdGLiDpWrJ/n2rWRMT0RmKl1oqevips2+Y3T0TMBeYCSFocEdOa3bDUuvG+uvGeoDvvqxvvCbL7avQanZbI69HXgpjLgCkl65OB5S1oh5lZz2lF0l8ETJW0j6SxwEnA/Ba0w8ys5yQv70TEFkmzgevIhmxeFBH3VDltbvNb1hLdeF/deE/QnffVjfcE3XtfhUj+Ra6ZmbVOK8o7ZmbWIk76ZmY9pK2TvqTpkh6QtETS2a1uTxEkTZH0c0n3SbpH0lmtblNRJPVL+p2kH7W6LUWRtKukqyTdn/83e0Or21QESR/P//+7W9JlktJN71kgSRdJWiXp7pJtu0u6QdKD+c/dWtnGdtO2Sb9kuoZjgf2BkyXt39pWFWIL8ImIeCXweuDMLrkvgLOA+1rdiIKdC1wbEa8ADqIL7k/SJOCjwLSIOIBsQMVJrW3VqF0ClI+pPxtYGBFTgYX5uuXaNulTMl1DRGwChqZr6GgRsSIibs8/rydLIpNa26rGSZoM/A1wYavbUhRJOwOHA98EiIhNEfFUSxtVnAFge0kDwA506LMyEXET8ETZ5pnAvPzzPOCElG1qd+2c9CcBpdNeLqMLkmMpSXsDrwZ+0+KmFOGrwN/TXS8c2hdYDVycl60ulDSu1Y1qVEQ8Dvw78CiwAlgXEde3tlWFmhARKyDrZAF7trg9baWdk35N0zV0Kkk7At8HPhYRT7e6PY2QdBywKiJua3VbCjYAvAY4PyJeDTxDF5QK8hr3TGAfYC9gnKT3tbZVlko7J/2una5B0hiyhH9pRPyg1e0pwGHA8ZIeJivDvUXSd1rbpEIsA5ZFxNBfYleR/RLodEcDD0XE6ojYDPwAeGOL21SklZImAuQ/V7W4PW2lnZN+V07XIElkNeL7IuLLrW5PESLiUxExOSL2Jvvv9LOI6PieY0T8CXhM0n75pqPojinAHwVeL2mH/P/Ho+iCL6hLzAeGXqJ8KvDDFral7bTt6xJHOV1DJzgMOAW4S9Id+bZzImJB65pkI/g74NK847EUOK3F7WlYRPxG0lXA7WSjyX5Hh05dIOky4AhgvKRlwGeBOcCVkk4n+wV3Yuta2H48DYOZWQ9p5/KOmZkVzEnfzKyHOOmbmfUQJ30zsx7ipG9m1kOc9C0pSVsl3ZHP7vg9STvUef5e+XBDJB0saUbJvuO7ZTZWs2bxkE1LStKGiNgx/3wpcNtoH1KT9AGymSJnF9hEs67mnr610s3AX+Xzn18j6U5Jt0o6EEDSm/O/Cu7IJzzbSdLe+V8JY4HPAe/O979b0gckfT0/92WSFubXXCjppfn2SyR9TdKvJC2V9M6W3b1ZCzjpW0vkU/oeC9wF/BPwu4g4EDgH+FZ+2P8FzoyIg4H/CWwcOj+fbvszwBURcXBEXFEW4uvAt/JrXgp8rWTfROBNwHFkT2+a9QwnfUtt+3z6icVkj8h/kywBfxsgIn4GvFjSLsAvgS9L+iiwa0RsqSPOG4Dv5p+/nccYck1EDEbEvcCERm7GrNO07dw71rU25j33F+STfpWLiJgj6cfADOBWSUcDz40ybumXV8+Xhh/l9cw6knv61g5uAt4LIOkIYE1EPC3p5RFxV0T8K9lfBq8oO289sNMw1/wVf34F4HuBW4putFknctK3dvCPwDRJd5LV2Iemxf1Y/qXt78nq+T8pO+/nwP5DX+SW7fsocFp+zVPI3t9r1vM8ZNPMrIe4p29m1kOc9M3MeoiTvplZD3HSNzPrIU76ZmY9xEnfzKyHOOmbmfWQ/w958Kjs2GzfdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n, d = 10, 64\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Multi-Head Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) \n",
    "and [Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformer(q_que_pad, k_que_pad, wv_dim, k_wv_dim, rate = 0.1, mask = ''):\n",
    "    # Inputs\n",
    "    mem  = Input((q_que_pad, wv_dim))\n",
    "    encode = Input((k_que_pad, k_wv_dim))\n",
    "    # Constants\n",
    "    ff_dim = wv_dim*64\n",
    "    # Multi-Head Attention\n",
    "    q = Dense(wv_dim)(mem)\n",
    "    k = Dense(wv_dim)(encode)\n",
    "    v = Dense(wv_dim)(encode)\n",
    "    # Choose a mask, default: BERT (no mask)\n",
    "    mask_weights = np.ones((q_que_pad, k_que_pad))\n",
    "    if mask == 'GPT':\n",
    "        mask_weights = np.tri(q_que_pad, k_que_pad, 0)\n",
    "    mem_new = MultiHeadAttention(\n",
    "        num_heads = 8,\n",
    "        key_dim = wv_dim, \n",
    "        value_dim = wv_dim\n",
    "    )(\n",
    "        q, k, v,\n",
    "        attention_mask = mask_weights\n",
    "    )\n",
    "    mem_new = Dropout(rate)(mem_new)\n",
    "    mem_new = LayerNormalization(epsilon=1e-6)(mem_new+mem)\n",
    "    # Feed-Forward skip-connection\n",
    "    ffn = Dense(ff_dim, activation = 'relu')(mem_new)\n",
    "    ffn = Dense(wv_dim)(ffn)\n",
    "    ffn = Dropout(rate)(ffn)\n",
    "    out = LayerNormalization(epsilon=1e-6)(ffn+mem_new)\n",
    "    model = Model(\n",
    "        [mem, encode],\n",
    "        [mem_new, out],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getE(wv_dim = 16):\n",
    "    _input = Input((encoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_encoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(encoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(encoder_emb16),\n",
    "    )\n",
    "    mem = emb(_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(encoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # forward sentence\n",
    "    for i in range(2):\n",
    "        gptLayer = Transformer(encoder_que_pad, encoder_que_pad, wv_dim, wv_dim)\n",
    "        mem, output = gptLayer((mem, mem))\n",
    "        output = Activation('relu')(output)\n",
    "        mem = Activation('relu')(mem)\n",
    "    # Output\n",
    "    model = Model(\n",
    "        _input, \n",
    "        output) \n",
    "    return model\n",
    "\n",
    "def getD(wv_dim = 8, encoder_wv_dim = 16):\n",
    "    en_output = Input((encoder_que_pad, encoder_wv_dim))\n",
    "    de_input  = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb8),\n",
    "    )\n",
    "    mem = emb(de_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # Attention\n",
    "    for j in range(2):\n",
    "        # Self attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim, mask = 'GPT')\n",
    "            mem, _ = gptLayer((mem, mem))\n",
    "            mem = Activation('relu')(mem)\n",
    "        # Cross attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, encoder_que_pad, wv_dim, encoder_wv_dim)\n",
    "            mem, output = gptLayer((mem, en_output))\n",
    "            output = Activation('relu')(output)\n",
    "            mem = Activation('relu')(mem)\n",
    "    # Concatenation and output\n",
    "    output = Dense(num_decoder_words)(output)\n",
    "    output = Activation('softmax')(output)\n",
    "    model = Model(\n",
    "        [en_output, de_input], \n",
    "        output,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Language Model\n",
    "def getLM():\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((decoder_que_pad,))\n",
    "    # Encoder (Chinese -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    encoder.summary()\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim)\n",
    "    decoder.summary()\n",
    "    de_output = decoder([en_output, de_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input],\n",
    "        de_output,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_107\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_204 (InputLayer)          [(None, 88)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 88, 16)       75456       input_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_174 (TFOpL (None, 88, 16)       0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_174 (LayerN (None, 88, 16)       32          tf.__operators__.add_174[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "model_105 (Functional)          [(None, 88, 16), (No 43280       layer_normalization_174[0][0]    \n",
      "                                                                 layer_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 88, 16)       0           model_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_106 (Functional)          [(None, 88, 16), (No 43280       activation_140[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 88, 16)       0           model_106[0][1]                  \n",
      "==================================================================================================\n",
      "Total params: 162,048\n",
      "Trainable params: 162,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_210 (InputLayer)          [(None, 279)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 279, 8)       1592        input_210[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_179 (TFOpL (None, 279, 8)       0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_179 (LayerN (None, 279, 8)       16          tf.__operators__.add_179[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "model_108 (Functional)          [(None, 279, 8), (No 11208       layer_normalization_179[0][0]    \n",
      "                                                                 layer_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 279, 8)       0           model_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_209 (InputLayer)          [(None, 88, 16)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_109 (Functional)          [(None, 279, 8), (No 11336       activation_143[0][0]             \n",
      "                                                                 input_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 279, 8)       0           model_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_110 (Functional)          [(None, 279, 8), (No 11208       activation_145[0][0]             \n",
      "                                                                 activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 279, 8)       0           model_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_111 (Functional)          [(None, 279, 8), (No 11336       activation_146[0][0]             \n",
      "                                                                 input_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 279, 8)       0           model_111[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_429 (Dense)               (None, 279, 199)     1791        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 279, 199)     0           dense_429[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 48,487\n",
      "Trainable params: 48,487\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_113\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_202 (InputLayer)          [(None, 88)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_107 (Functional)          (None, 88, 16)       162048      input_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_203 (InputLayer)          [(None, 279)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_112 (Functional)          (None, 279, 199)     48487       model_107[0][0]                  \n",
      "                                                                 input_203[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 210,535\n",
      "Trainable params: 210,535\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleG = getLM()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_402/kernel:0', 'dense_402/bias:0', 'dense_403/kernel:0', 'dense_403/bias:0', 'layer_normalization_176/gamma:0', 'layer_normalization_176/beta:0', 'dense_412/kernel:0', 'dense_412/bias:0', 'dense_413/kernel:0', 'dense_413/bias:0', 'layer_normalization_181/gamma:0', 'layer_normalization_181/beta:0', 'dense_417/kernel:0', 'dense_417/bias:0', 'dense_418/kernel:0', 'dense_418/bias:0', 'layer_normalization_183/gamma:0', 'layer_normalization_183/beta:0', 'dense_422/kernel:0', 'dense_422/bias:0', 'dense_423/kernel:0', 'dense_423/bias:0', 'layer_normalization_185/gamma:0', 'layer_normalization_185/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_402/kernel:0', 'dense_402/bias:0', 'dense_403/kernel:0', 'dense_403/bias:0', 'layer_normalization_176/gamma:0', 'layer_normalization_176/beta:0', 'dense_412/kernel:0', 'dense_412/bias:0', 'dense_413/kernel:0', 'dense_413/bias:0', 'layer_normalization_181/gamma:0', 'layer_normalization_181/beta:0', 'dense_417/kernel:0', 'dense_417/bias:0', 'dense_418/kernel:0', 'dense_418/bias:0', 'layer_normalization_183/gamma:0', 'layer_normalization_183/beta:0', 'dense_422/kernel:0', 'dense_422/bias:0', 'dense_423/kernel:0', 'dense_423/bias:0', 'layer_normalization_185/gamma:0', 'layer_normalization_185/beta:0'] when minimizing the loss.\n",
      "2032/2032 [==============================] - 165s 79ms/step - loss: 1.7561 - accuracy: 0.6187 - val_loss: 1.2129 - val_accuracy: 0.6507\n",
      "Epoch 2/300\n",
      "2032/2032 [==============================] - 160s 79ms/step - loss: 1.2040 - accuracy: 0.6528 - val_loss: 1.1657 - val_accuracy: 0.6606\n",
      "Epoch 3/300\n",
      "2032/2032 [==============================] - 160s 79ms/step - loss: 1.1733 - accuracy: 0.6586 - val_loss: 1.1438 - val_accuracy: 0.6645\n",
      "Epoch 4/300\n",
      "2032/2032 [==============================] - 160s 79ms/step - loss: 1.1572 - accuracy: 0.6626 - val_loss: 1.1308 - val_accuracy: 0.6683\n",
      "Epoch 5/300\n",
      "2032/2032 [==============================] - 163s 80ms/step - loss: 1.1469 - accuracy: 0.6653 - val_loss: 1.1215 - val_accuracy: 0.6711\n",
      "Epoch 6/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1396 - accuracy: 0.6668 - val_loss: 1.1202 - val_accuracy: 0.6707\n",
      "Epoch 7/300\n",
      "2032/2032 [==============================] - 188s 93ms/step - loss: 1.1344 - accuracy: 0.6677 - val_loss: 1.1125 - val_accuracy: 0.6723\n",
      "Epoch 8/300\n",
      "2032/2032 [==============================] - 166s 82ms/step - loss: 1.1304 - accuracy: 0.6686 - val_loss: 1.1098 - val_accuracy: 0.6731\n",
      "Epoch 9/300\n",
      "2032/2032 [==============================] - 160s 79ms/step - loss: 1.1268 - accuracy: 0.6694 - val_loss: 1.1053 - val_accuracy: 0.6738\n",
      "Epoch 10/300\n",
      "2032/2032 [==============================] - 160s 79ms/step - loss: 1.1241 - accuracy: 0.6700 - val_loss: 1.1106 - val_accuracy: 0.6726\n",
      "Epoch 11/300\n",
      "2032/2032 [==============================] - 174s 86ms/step - loss: 1.1218 - accuracy: 0.6705 - val_loss: 1.1017 - val_accuracy: 0.6748\n",
      "Epoch 12/300\n",
      "2032/2032 [==============================] - 188s 92ms/step - loss: 1.1194 - accuracy: 0.6710 - val_loss: 1.1062 - val_accuracy: 0.6739\n",
      "Epoch 13/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1170 - accuracy: 0.6717 - val_loss: 1.0988 - val_accuracy: 0.6752\n",
      "Epoch 14/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1149 - accuracy: 0.6722 - val_loss: 1.1002 - val_accuracy: 0.6751\n",
      "Epoch 15/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1132 - accuracy: 0.6726 - val_loss: 1.0995 - val_accuracy: 0.6760\n",
      "Epoch 16/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1114 - accuracy: 0.6730 - val_loss: 1.0990 - val_accuracy: 0.6756\n",
      "Epoch 17/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1095 - accuracy: 0.6734 - val_loss: 1.0977 - val_accuracy: 0.6754\n",
      "Epoch 18/300\n",
      "2032/2032 [==============================] - 188s 93ms/step - loss: 1.1078 - accuracy: 0.6739 - val_loss: 1.0985 - val_accuracy: 0.6754\n",
      "Epoch 19/300\n",
      "2032/2032 [==============================] - 188s 93ms/step - loss: 1.1065 - accuracy: 0.6743 - val_loss: 1.0972 - val_accuracy: 0.6764\n",
      "Epoch 20/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1049 - accuracy: 0.6748 - val_loss: 1.0925 - val_accuracy: 0.6767\n",
      "Epoch 21/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1036 - accuracy: 0.6752 - val_loss: 1.0975 - val_accuracy: 0.6758\n",
      "Epoch 22/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1018 - accuracy: 0.6758 - val_loss: 1.1009 - val_accuracy: 0.6750\n",
      "Epoch 23/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.1003 - accuracy: 0.6762 - val_loss: 1.0905 - val_accuracy: 0.6771\n",
      "Epoch 24/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.0989 - accuracy: 0.6767 - val_loss: 1.0944 - val_accuracy: 0.6761\n",
      "Epoch 25/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.0976 - accuracy: 0.6771 - val_loss: 1.0899 - val_accuracy: 0.6775\n",
      "Epoch 26/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.0962 - accuracy: 0.6775 - val_loss: 1.0922 - val_accuracy: 0.6771\n",
      "Epoch 27/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.0953 - accuracy: 0.6779 - val_loss: 1.0881 - val_accuracy: 0.6783\n",
      "Epoch 28/300\n",
      "2032/2032 [==============================] - 189s 93ms/step - loss: 1.0927 - accuracy: 0.6788 - val_loss: 1.0923 - val_accuracy: 0.6777\n",
      "Epoch 30/300\n",
      "1201/2032 [================>.............] - ETA: 1:13 - loss: 1.0929 - accuracy: 0.6788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2032/2032 [==============================] - 190s 93ms/step - loss: 1.0857 - accuracy: 0.6812 - val_loss: 1.0838 - val_accuracy: 0.6807\n",
      "Epoch 38/300\n",
      "1251/2032 [=================>............] - ETA: 1:08 - loss: 1.0844 - accuracy: 0.6815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mleG.fit(\n",
    "    [encoder_train, decoder_train], \n",
    "    teacher_train, \n",
    "    batch_size=128, \n",
    "    epochs=300, \n",
    "    shuffle=True, \n",
    "    validation_data = (\n",
    "        [encoder_vali, decoder_vali], \n",
    "        teacher_vali\n",
    "    ), \n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            f'./{folder_name}/mleG.h5', \n",
    "            save_best_only=True, \n",
    "            monitor = \"val_loss\"\n",
    "        ),\n",
    "        EarlyStopping(monitor='val_loss', patience=5),\n",
    "        CSVLogger(f'{folder_name}/mleG.csv'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{folder_name}/mleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "rows = csv.reader(open(f'{folder_name}/mleG.csv'))\n",
    "nll_mle = []\n",
    "for i, row in enumerate(rows):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    nll_mle.append(float(row[-1]))\n",
    "plt.plot(nll_mle, )\n",
    "plt.grid(True)\n",
    "plt.ylabel('nll_test')\n",
    "plt.xlabel('training iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference train D (False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    enData = None,\n",
    "):\n",
    "    # Initialize\n",
    "    resp_pred_list = None\n",
    "    in_batch_list = None\n",
    "    the_first = True\n",
    "    \n",
    "    in_batch = np.zeros((len(enData), decoder_que_pad), dtype = int)\n",
    "    in_batch[:,0] = decoder_word2idx['<bos>']\n",
    "    en_batch = enData\n",
    "    resp_pred = np.zeros(in_batch.shape, dtype = int)\n",
    "    # Generate the sequence recurrsively.\n",
    "    for i in range(decoder_que_pad):\n",
    "        # Run\n",
    "        resp_pred_wv = model([en_batch, in_batch])\n",
    "        the_last = resp_pred_wv[:,i]\n",
    "        # Stochastic\n",
    "        the_last = tf.reshape(\n",
    "            tf.random.categorical(tf.math.log(the_last), 1), \n",
    "            [len(enData),]\n",
    "        )\n",
    "        # TODO: greedy\n",
    "        try:\n",
    "            resp_pred[:,i] = the_last\n",
    "            in_batch[:,i+1] = the_last\n",
    "        except:\n",
    "            resp_pred[:,i] = the_last\n",
    "    # Remove the words after <eos>\n",
    "    for i in range(len(resp_pred)):\n",
    "        try:\n",
    "            index = list(resp_pred[i]).index(en_word2idx['<eos>'])\n",
    "        except:\n",
    "            continue\n",
    "        resp_pred[i,index+1:] = 0\n",
    "        in_batch[i,index+1:] = 0\n",
    "        \n",
    "    return resp_pred, in_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_pred_list, _ = inference(mleG, [encoder_vali[99]])\n",
    "print('# Predicted sequence')\n",
    "print(seq2word(resp_pred_list, decoder_idx2word))\n",
    "print('# Real sequence')\n",
    "print(seq2word([decoder_vali[99]], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
