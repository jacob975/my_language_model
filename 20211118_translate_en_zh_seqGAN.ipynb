{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "# If you have more than 1 GPU, you might want to specify which GPU for training.\n",
    "# In this case, I have 2 GPU and the second one is RTX 2080ti, so I pick the `second` one.\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1' # The second\n",
    "tf.config.set_soft_device_placement(True)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = '20211116_wmt19_en_zh'\n",
    "g_name = '20211116_translate_mle_en_zh'\n",
    "folder_name = '20211118_translate_mle_en_zh_seqGAN'\n",
    "\n",
    "encoder_wv_dim = 32\n",
    "decoder_wv_dim = 32\n",
    "encoder_que_pad = 65\n",
    "decoder_que_pad = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train = pickle.load(open(f'{d_name}/encoder_train.pkl', 'rb'))\n",
    "decoder_train = pickle.load(open(f'{d_name}/decoder_train.pkl', 'rb'))\n",
    "teacher_train = pickle.load(open(f'{d_name}/teacher_train.pkl', 'rb'))\n",
    "encoder_vali  = pickle.load(open(f'{d_name}/encoder_vali.pkl', 'rb'))\n",
    "decoder_vali  = pickle.load(open(f'{d_name}/decoder_vali.pkl', 'rb'))\n",
    "teacher_vali  = pickle.load(open(f'{d_name}/teacher_vali.pkl', 'rb'))\n",
    "\n",
    "decoder_idx2word   = pickle.load(open(f'{d_name}/en_idx2word.pkl','rb'))\n",
    "decoder_word2idx   = pickle.load(open(f'{d_name}/en_word2idx.pkl','rb'))\n",
    "encoder_idx2word   = pickle.load(open(f'{d_name}/zh_idx2word.pkl','rb'))\n",
    "encoder_word2idx   = pickle.load(open(f'{d_name}/zh_word2idx.pkl','rb'))\n",
    "\n",
    "decoder_emb32    = pickle.load(open(f'{d_name}/en_emb32.pkl', 'rb'))\n",
    "encoder_emb32    = pickle.load(open(f'{d_name}/zh_emb32.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "4716\n"
     ]
    }
   ],
   "source": [
    "num_decoder_words = np.max([np.max(decoder_train), np.max(decoder_vali)])+1\n",
    "num_encoder_words = np.max([np.max(encoder_train), np.max(encoder_vali)])+1\n",
    "\n",
    "print(num_decoder_words)\n",
    "print(num_encoder_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(seq_tensor, idx2word):\n",
    "    return [''.join([idx2word[i] for i in seq]) for seq in seq_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>1929 or 1989?<eos>                                                                                                                                                                                                ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(decoder_vali[:1], decoder_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年还是1989年?                                                    ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(encoder_vali[:1], encoder_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "[Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n, d = 10, 64\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Multi-Head Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) \n",
    "and [Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_mask(n_gram, que_pad): # For backward sequence #中間那段的mask\n",
    "    mask_upper = np.tri(que_pad, que_pad, -1+n_gram)\n",
    "    mask_lower = np.tri(que_pad, que_pad, -1)\n",
    "    mask = mask_upper - mask_lower\n",
    "    return mask\n",
    "\n",
    "def Transformer(q_que_pad, k_que_pad, wv_dim, k_wv_dim, rate = 0.1, mask = ''):\n",
    "    # Inputs\n",
    "    mem  = Input((q_que_pad, wv_dim))\n",
    "    encode = Input((k_que_pad, k_wv_dim))\n",
    "    # Constants\n",
    "    ff_dim = wv_dim*64\n",
    "    # Multi-Head Attention\n",
    "    q = Dense(wv_dim)(mem)\n",
    "    k = Dense(wv_dim)(encode)\n",
    "    v = Dense(wv_dim)(encode)\n",
    "    # Choose a mask, default: BERT (no mask)\n",
    "    mask_weights = np.ones((q_que_pad, k_que_pad))\n",
    "    if mask == 'GPT':\n",
    "        mask_weights = np.tri(q_que_pad, k_que_pad, 0)\n",
    "    elif mask == 'band':\n",
    "        mask_weights = band_mask(10, q_que_pad)\n",
    "        print(mask_weights)\n",
    "    mem_new = MultiHeadAttention(\n",
    "        num_heads = 4,\n",
    "        key_dim = wv_dim, \n",
    "        value_dim = wv_dim\n",
    "    )(\n",
    "        q, k, v,\n",
    "        attention_mask = mask_weights,\n",
    "    )\n",
    "    mem_new = Dropout(rate)(mem_new)\n",
    "    mem_new = LayerNormalization(epsilon=1e-6)(mem_new+mem)\n",
    "    # Feed-Forward skip-connection\n",
    "    ffn = Dense(ff_dim, activation = 'relu')(mem_new)\n",
    "    ffn = Dense(wv_dim)(ffn)\n",
    "    ffn = Dropout(rate)(ffn)\n",
    "    out = LayerNormalization(epsilon=1e-6)(ffn+mem_new)\n",
    "    model = Model(\n",
    "        [mem, encode],\n",
    "        [mem_new, out],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getE(wv_dim = 16):\n",
    "    _input = Input((encoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_encoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(encoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(encoder_emb32),\n",
    "    )\n",
    "    mem = emb(_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(encoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # forward sentence\n",
    "    for i in range(1):\n",
    "        gptLayer = Transformer(encoder_que_pad, encoder_que_pad, wv_dim, wv_dim)\n",
    "        mem, output = gptLayer((mem, mem))\n",
    "        output = Activation('relu')(output)\n",
    "        mem = Activation('relu')(mem)\n",
    "    # Output\n",
    "    model = Model(\n",
    "        _input, \n",
    "        output) \n",
    "    return model\n",
    "\n",
    "def getD(wv_dim = 8, encoder_wv_dim = 16):\n",
    "    en_output = Input((encoder_que_pad, encoder_wv_dim))\n",
    "    de_input  = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    mem = emb(de_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # Attention\n",
    "    for j in range(1):\n",
    "        # Self attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim, mask = 'GPT')\n",
    "            mem, _ = gptLayer((mem, mem))\n",
    "            mem = Activation('relu')(mem)\n",
    "        # Cross attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, encoder_que_pad, wv_dim, encoder_wv_dim)\n",
    "            mem, output = gptLayer((mem, en_output))\n",
    "            output = Activation('relu')(output)\n",
    "            mem = Activation('relu')(mem)\n",
    "    # Concatenation and output\n",
    "    output = Dense(num_decoder_words)(output)\n",
    "    output = Activation('softmax')(output)\n",
    "    model = Model(\n",
    "        [en_output, de_input], \n",
    "        output,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Language Model\n",
    "def getLM():\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((decoder_que_pad,))\n",
    "    # Encoder (Czech -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim)\n",
    "    de_output = decoder([en_output, de_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input],\n",
    "        de_output,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 65, 32)       304224      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Functional)            (None, 207, 199)     319495      model_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 623,719\n",
      "Trainable params: 623,719\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleG = getLM()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 7s 7ms/step - loss: 0.6010 - accuracy: 0.8202\n",
      "0.6009974479675293\n"
     ]
    }
   ],
   "source": [
    "mleG.load_weights(f'./{g_name}/mleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    enData,\n",
    "    inpData = None,\n",
    "    start_on = 0,\n",
    "    end_on = decoder_que_pad,\n",
    "    batch_size = 1024,\n",
    "):\n",
    "    # Initialize\n",
    "    num_data = len(enData)\n",
    "    num_batch = (num_data-1)//batch_size +1\n",
    "    resp_pred_list = None\n",
    "    in_batch_list = None\n",
    "    the_first = True\n",
    "    for b in range(num_batch):\n",
    "        en_batch = np.zeros((batch_size, encoder_que_pad), dtype = int)\n",
    "        if b == num_batch -1:\n",
    "            en_batch[:num_data - (num_batch-1) * batch_size] = enData[b*batch_size:(b+1)*batch_size]\n",
    "        else:\n",
    "            en_batch = enData[b*batch_size:(b+1)*batch_size]\n",
    "        in_batch = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        if start_on == 0:\n",
    "            in_batch[:,0] = decoder_word2idx['<bos>']\n",
    "        elif b == num_batch -1:\n",
    "            in_batch[:num_data - (num_batch-1) * batch_size] = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        else: \n",
    "            in_batch = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        resp_pred = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        # Generate the sequence recurrsively.\n",
    "        for i in range(start_on, end_on):\n",
    "            # Run\n",
    "            resp_pred_wv = model([en_batch, in_batch])\n",
    "            the_last = resp_pred_wv[:,i]\n",
    "            the_last = tf.reshape(\n",
    "                tf.random.categorical(tf.math.log(the_last), 1), \n",
    "                [batch_size,]\n",
    "            )\n",
    "            try:\n",
    "                resp_pred[:,i] = the_last\n",
    "                in_batch[:,i+1] = the_last\n",
    "            except:\n",
    "                resp_pred[:,i] = the_last\n",
    "        for i in range(len(resp_pred)):\n",
    "            try:\n",
    "                index = list(resp_pred[i]).index(word2idx['<bos>'])\n",
    "            except:\n",
    "                continue\n",
    "            resp_pred[i,index+1:] = 0\n",
    "            in_batch[i,index+1:] = 0\n",
    "        if the_first:\n",
    "            resp_pred_list = resp_pred\n",
    "            in_batch_list = in_batch\n",
    "            the_first = False\n",
    "        else:\n",
    "            resp_pred_list = np.vstack((resp_pred_list, resp_pred))\n",
    "            in_batch_list = np.vstack((in_batch_list, in_batch))\n",
    "    resp_pred_list = resp_pred_list[:num_data]\n",
    "    in_batch_list = in_batch_list[:num_data]\n",
    "    if start_on != 0:\n",
    "        resp_pred_list[:,:start_on] = inpData[:,1:start_on+1]\n",
    "        in_batch_list[:, :start_on+1] = inpData[:,:start_on+1]\n",
    "    return resp_pred_list, in_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predicted sequence\n",
      "['I 1989.<eos>                                                                                                                                                                                                       ', 'PARIS – Economy, the economic and that the world renewak receiving ayond a boosting deeper is come righly uniquent we have retrictions almost likelying End hoperation us of hope.<eos>                            ']\n",
      "# Real sequence\n",
      "['1929 or 1989?<eos>                                                                                                                                                                                                 ', 'PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.<eos>                                                       ']\n"
     ]
    }
   ],
   "source": [
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2])\n",
    "print('# Predicted sequence')\n",
    "print(seq2word(resp_pred_list, decoder_idx2word))\n",
    "print('# Real sequence')\n",
    "print(seq2word(teacher_vali[:2], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 65)\n",
      "(2, 207)\n",
      "[[ 63  77 113  77   0 182 189  46 149   0  28 182 166 107   0  28  71 182\n",
      "  107  31   5 198   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 183   0  68  46   0 182 166 107   0 102   9 158\n",
      "   46 158  46   0 182  10 149 166 153   0   9  71 147 125 158   9  71  46\n",
      "    0 182 166 107   0 145 149   0 153   9 149 125  76   0  80   9  71  71\n",
      "    0  71 189  71 102 145 158 149 166   0 149 139   0 182 102 102 149   9\n",
      "  107 158 166 153   0 145 159  71   0  65 149   9 189 107 133   0 159 182\n",
      "   46   0 107 158 166 153 189  71   0 107  71 158 145 145 125 182 145 158\n",
      "  149 166 133   0  65 159 158 102 159   0 158 145   0 149 166   0 159 158\n",
      "   46 145 149   9  31   0  65 159 158 102 159   0  65 158 189 189   0 145\n",
      "    9 158  71 107   0 182   9  71   0  31  71 182   9  46   5 198   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]]\n",
      "[[ 63  77 113  77   0 149   9   0  63  77 170  77 151 198   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 183   0  68  46   0 145 159  71   0  71 102 149\n",
      "  166 149  10 158 102   0 102   9 158  46 158  46   0 107  71  71  76  71\n",
      "  166  46   0 182 166 107   0  65 158 107  71 166  46 133   0 145 159  71\n",
      "    0  65 149   9 189 107   0 159 182  46   0  13  71  71 166   0  46  71\n",
      "  182   9 102 159 158 166 153   0 139 149   9   0 159 158  46 145 149   9\n",
      "  158 102 182 189   0 182 166 182 189 149 153 158  71  46   0 145 149   0\n",
      "  159  71 189  76   0 125  46   0 125 166 107  71   9  46 145 182 166 107\n",
      "    0  65 159 182 145   0 159 182  46   0  13  71  71 166   0 159 182  76\n",
      "   76  71 166 158 166 153   5 198   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_vali[:2].shape)\n",
    "print(decoder_vali[:2].shape)\n",
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2], decoder_vali[:2], start_on =5)\n",
    "print(resp_pred_list)\n",
    "print(teacher_vali[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Train Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Pre-training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_train[:10240], \n",
    "    batch_size = 1024,\n",
    ")\n",
    "\n",
    "teacher_pre_train_d = np.vstack([teacher_train[:10240], teacher_pred])\n",
    "print(teacher_pre_train_d.shape)\n",
    "\n",
    "reward_train = np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_train_d = np.vstack([reward_train, reward_pred])\n",
    "print(reward_pre_train_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_train_d[-1])\n",
    "#print(reward_pre_train_d[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-validating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 207)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_vali[:1024],\n",
    "    batch_size = 512\n",
    ")\n",
    "teacher_pre_vali_d = np.vstack([teacher_vali[:1024], teacher_pred])\n",
    "print(teacher_pre_vali_d.shape)\n",
    "\n",
    "reward_vali =  np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_vali_d = np.vstack([reward_vali, reward_pred])\n",
    "print(reward_pre_vali_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_vali_d[0])\n",
    "#print(reward_pre_vali_d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(teacher_pre_train_d, open(f'{folder_name}/teacher_pre_train_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_train_d,  open(f'{folder_name}/reward_pre_train_d.pkl','wb'))\n",
    "pickle.dump(teacher_pre_vali_d,  open(f'{folder_name}/teacher_pre_vali_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_vali_d,   open(f'{folder_name}/reward_pre_vali_d.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pre_train_d = pickle.load(open(f'{folder_name}/teacher_pre_train_d.pkl','rb'))\n",
    "reward_pre_train_d  = pickle.load(open(f'{folder_name}/reward_pre_train_d.pkl','rb'))\n",
    "teacher_pre_vali_d  = pickle.load(open(f'{folder_name}/teacher_pre_vali_d.pkl','rb'))\n",
    "reward_pre_vali_d   = pickle.load(open(f'{folder_name}/reward_pre_vali_d.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getC(wv_dim): # Critic/Discriminator\n",
    "    resp = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim,\n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    resp_emb = emb(resp)\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    resp_emb = LayerNormalization(epsilon=1e-6)(resp_emb+pe)\n",
    "    bertLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim)\n",
    "    _, out = bertLayer((resp_emb, resp_emb))\n",
    "    out, *_ = tf.split(out, decoder_que_pad, axis = 1)\n",
    "    reward = Dense(1, activation = 'sigmoid')(out)\n",
    "    reward = Flatten()(reward)\n",
    "    model = Model(\n",
    "        resp,\n",
    "        reward\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 207, 32)      6368        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 207, 32)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 207, 32)      64          tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "model_6 (Functional)            [(None, 207, 32), (N 153248      layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.split (TFOpLambda)           [(None, 1, 32), (Non 0           model_6[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1, 1)         33          tf.split[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleD=getC(decoder_wv_dim)\n",
    "mleD.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "mleD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object_MleD = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_MleD = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_MleD(real, pred):\n",
    "    loss_ = loss_object_MleD(real, pred)\n",
    "    return loss_\n",
    "\n",
    "@tf.function()\n",
    "def trainMleD(te_in, y_real):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = mleD(te_in)\n",
    "        loss = loss_func_MleD(y_real, y_pred)\n",
    "    gradients = tape.gradient(loss, mleD.trainable_variables)    \n",
    "    optimizer_MleD.apply_gradients(zip(gradients, mleD.trainable_variables))\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved.\n",
      "Epoch 1, D loss: 0.0666, D NLL: 0.6918, elapsed time: 10 secs\n",
      "Epoch 2, D loss: 0.0642, D NLL: 0.7108, elapsed time: 8 secs\n",
      "Epoch 3, D loss: 0.0639, D NLL: 0.8663, elapsed time: 9 secs\n",
      "Epoch 4, D loss: 0.0638, D NLL: 1.0410, elapsed time: 9 secs\n",
      "Epoch 5, D loss: 0.0638, D NLL: 0.7384, elapsed time: 8 secs\n",
      "model saved.\n",
      "Epoch 6, D loss: 0.0627, D NLL: 0.6870, elapsed time: 8 secs\n",
      "Epoch 7, D loss: 0.0614, D NLL: 0.7111, elapsed time: 9 secs\n",
      "model saved.\n",
      "Epoch 8, D loss: 0.0611, D NLL: 0.6769, elapsed time: 9 secs\n",
      "Epoch 9, D loss: 0.0608, D NLL: 1.1400, elapsed time: 8 secs\n",
      "Epoch 10, D loss: 0.0633, D NLL: 0.6789, elapsed time: 8 secs\n",
      "Epoch 11, D loss: 0.0605, D NLL: 0.6913, elapsed time: 8 secs\n",
      "model saved.\n",
      "Epoch 12, D loss: 0.0603, D NLL: 0.6601, elapsed time: 9 secs\n",
      "Epoch 13, D loss: 0.0598, D NLL: 0.6744, elapsed time: 8 secs\n",
      "Epoch 14, D loss: 0.0598, D NLL: 0.6841, elapsed time: 8 secs\n",
      "Epoch 15, D loss: 0.0592, D NLL: 0.6974, elapsed time: 8 secs\n",
      "Epoch 16, D loss: 0.0594, D NLL: 0.6619, elapsed time: 9 secs\n",
      "Epoch 17, D loss: 0.0587, D NLL: 0.6738, elapsed time: 8 secs\n"
     ]
    }
   ],
   "source": [
    "epoch = 300\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "batch_size = 256\n",
    "num_data =  len(teacher_train)\n",
    "counter = 0\n",
    "d_best_loss = 999\n",
    "\n",
    "for e in range(epoch):\n",
    "    start = int(time.time())\n",
    "    train_d_loss.reset_states()\n",
    "    # Shuffle the data\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(teacher_pre_train_d)\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(reward_pre_train_d)\n",
    "    # Training \n",
    "    for i in range(0, num_data, batch_size):\n",
    "        teacher_batch = teacher_pre_train_d[i:i+batch_size]\n",
    "        reward_batch  = reward_pre_train_d[i:i+batch_size]\n",
    "        _, d_loss = trainMleD(teacher_batch, reward_batch)\n",
    "        train_d_loss.update_state(d_loss)\n",
    "    # NLL test\n",
    "    reward_pre_vali_d_fake = mleD(teacher_pre_vali_d)\n",
    "    d_vali_loss = loss_func_MleD(\n",
    "        reward_pre_vali_d,\n",
    "        reward_pre_vali_d_fake,\n",
    "    )\n",
    "    if d_vali_loss < d_best_loss:\n",
    "        mleD.save(f'{folder_name}/mleD.h5')\n",
    "        print('model saved.')\n",
    "        d_best_loss = d_vali_loss\n",
    "        counter = 0\n",
    "    elif d_vali_loss > d_best_loss:\n",
    "        counter += 1\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\n",
    "        f'Epoch {e+1},'\n",
    "        f' D loss: {train_d_loss.result():.4f},'\n",
    "        f' D NLL: {d_vali_loss:.4f},'\n",
    "        f' elapsed time: {elapsed_time:.0f} secs'\n",
    "    )\n",
    "    # Quit condition\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load parameters onto SeqGAN models from MLE models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeqGAN generator and discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=tf.keras.losses.Reduction.NONE # NONE for not to sum up all loss.\n",
    "    #reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "    #reduction=tf.keras.losses.Reduction.SUM,\n",
    ")\n",
    "\n",
    "optimizer_g = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "def policy_loss_function(real, pred, rewards):\n",
    "    loss_ = loss_object2(real, pred)\n",
    "    loss_ = loss_ * rewards[:,:,0]\n",
    "\n",
    "    return tf.reduce_sum(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_9 (Functional)            (None, 65, 32)       304224      input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_12 (Functional)           (None, 207, 199)     319495      model_9[0][0]                    \n",
      "                                                                 input_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 623,719\n",
      "Trainable params: 623,719\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_g = getLM()\n",
    "seqgan_g.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['sparse_categorical_crossentropy'],\n",
    ")\n",
    "seqgan_g.trainable = True\n",
    "seqgan_g.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_g_step(en_in, de_in, real, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = seqgan_g((en_in, de_in))\n",
    "        loss = policy_loss_function(real, pred, rewards)\n",
    "    gradients = tape.gradient(loss, seqgan_g.trainable_variables)    \n",
    "    optimizer_g.apply_gradients(zip(gradients, seqgan_g.trainable_variables))    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_g = f\"{folder_name}/seqgan_g\"\n",
    "ckpt_g = tf.train.Checkpoint(model=seqgan_g,optimizer=optimizer_g)\n",
    "ckpt_g_manager = tf.train.CheckpointManager(ckpt_g, checkpoint_path_g, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_g_manager.latest_checkpoint:\n",
    "#    ckpt_g.restore(ckpt_g_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_d = tf.keras.optimizers.Adam(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 207, 32)      6368        input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_19 (TFOpLa (None, 207, 32)      0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 207, 32)      64          tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "model_14 (Functional)           [(None, 207, 32), (N 153248      layer_normalization_19[0][0]     \n",
      "                                                                 layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.split_1 (TFOpLambda)         [(None, 1, 32), (Non 0           model_14[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1, 1)         33          tf.split_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           dense_43[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_d = getC(decoder_wv_dim)\n",
    "seqgan_d.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "seqgan_d.trainable = True\n",
    "seqgan_d.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_d_step(resp, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = seqgan_d(resp) \n",
    "        loss = loss_d(rewards, pred)\n",
    "    gradients = tape.gradient(loss, seqgan_d.trainable_variables)    \n",
    "    optimizer_d.apply_gradients(zip(gradients, seqgan_d.trainable_variables))\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_d = f\"{folder_name}/seqgan_d\"\n",
    "ckpt_d = tf.train.Checkpoint(model=seqgan_d,optimizer=optimizer_d)\n",
    "ckpt_d_manager = tf.train.CheckpointManager(ckpt_d, checkpoint_path_d, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_d_manager.latest_checkpoint:\n",
    "#    ckpt_d.restore(ckpt_d_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward for Every Generation Step (REGS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_g_predict_batch(model, _inp_list, batch_size, num_data, step, **kwargs):\n",
    "    is_first = 1\n",
    "    y_out = None\n",
    "    num_batch = num_data // batch_size +1\n",
    "    for i in range(0, num_batch*batch_size , batch_size):\n",
    "        y = model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs)[:,step]\n",
    "        if is_first:\n",
    "            is_first = 0\n",
    "            y_out = y\n",
    "        else:\n",
    "            y_out = np.vstack([y_out, y])\n",
    "    return y_out\n",
    "\n",
    "def model_predict_batch(model, _inp_list, batch_size, num_data, **kwargs):\n",
    "    y_out = tf.stack(\n",
    "        [ model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs) \n",
    "         for i in range(0, num_data, batch_size)]\n",
    "    )\n",
    "    return y_out\n",
    "\n",
    "# Under revision, not finished yet\n",
    "def regs_mcmc(\n",
    "    model_g, \n",
    "    model_d,\n",
    "    en_in, \n",
    "    y_inp = None, \n",
    "    start_on = 0, \n",
    "    end_on = 10, \n",
    "    beam = 2,\n",
    "):\n",
    "    # If start on the end of sequence, return.\n",
    "    if start_on == decoder_que_pad -1:\n",
    "        return model_d.predict(y_inp)\n",
    "    # Initialize\n",
    "    num_data = y_inp.shape[0]\n",
    "    en_mcmc = np.array(en_in[:], dtype = int)\n",
    "    y_mcmc = np.zeros((num_data, decoder_que_pad), dtype = int)\n",
    "    de_mcmc = np.zeros((num_data, decoder_que_pad), dtype = int)\n",
    "    r_out = None\n",
    "    de_mcmc[:,0] = decoder_word2idx['<bos>']\n",
    "    if not isinstance(y_inp, type(None)):\n",
    "        y_mcmc[:, :start_on+1] = y_inp[:, :start_on+1]\n",
    "        de_mcmc[:, 1:start_on+2] = y_inp[:, :start_on+1]\n",
    "\n",
    "    # It determines which word to pass down.\n",
    "    beam_list = np.ones(decoder_que_pad, dtype = int)*beam\n",
    "    beam_list[:start_on+1] = 1\n",
    "    beam_list[start_on] = num_data\n",
    "    # bcList stands for beam-candidate list\n",
    "    bcList = []\n",
    "    for i in range(decoder_que_pad):\n",
    "        if i < start_on+1:\n",
    "            bcList.append([])\n",
    "        elif i >= start_on+1:\n",
    "            bcList.append(list(range(num_decoder_words-beam_list[i], num_decoder_words)))\n",
    "        else:\n",
    "            print('Warning')\n",
    "    #print(bcList)\n",
    "    # Generate sequences using MCMC\n",
    "    for t in range(start_on+1, end_on+1):\n",
    "        to_expand = beam_list[t]\n",
    "        the_last = model_g_predict_batch(\n",
    "            model_g, \n",
    "            [en_mcmc, de_mcmc], \n",
    "            batch_size = 2048, \n",
    "            num_data = len(de_mcmc), \n",
    "            step = t,\n",
    "        )\n",
    "        most_possible = np.argsort(the_last, axis = 1)\n",
    "        most_possible = np.transpose(\n",
    "            most_possible[:,bcList[t]]).reshape(\n",
    "            reduce(lambda x,y: x*y, beam_list[:t+1])\n",
    "        )\n",
    "        en_mcmc = np.tile(en_mcmc, (to_expand, 1))\n",
    "        de_mcmc = np.tile(de_mcmc, (to_expand, 1))\n",
    "        y_mcmc = np.tile(y_mcmc, (to_expand, 1))\n",
    "        y_mcmc[:,t] = most_possible\n",
    "        #print(en_mcmc.shape)\n",
    "        #print(de_mcmc.shape)\n",
    "        #print(y_mcmc.shape)\n",
    "        #print('---')\n",
    "        if t+1 < decoder_que_pad:\n",
    "            de_mcmc[:,t+1] = most_possible\n",
    "    # Rank all synthetic sequences\n",
    "    r_mcmc = model_d.predict(y_mcmc)\n",
    "    r_out = np.reshape(np.array([\n",
    "        tf.reduce_mean(r_mcmc[np.arange(i, len(r_mcmc), num_data)], axis = 0) for i in range(num_data)\n",
    "    ]), (num_data, 1))\n",
    "    # Rank each tokens\n",
    "    return r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57967085]\n",
      " [0.58143747]\n",
      " [0.44573095]\n",
      " [0.2980736 ]]\n"
     ]
    }
   ],
   "source": [
    "#print(decoder_train[:4])\n",
    "#print(teacher_train[:4])\n",
    "r_tmp = regs_mcmc(\n",
    "    seqgan_g, \n",
    "    seqgan_d, \n",
    "    encoder_train[:4],\n",
    "    teacher_train[:4], \n",
    "    start_on = 2,\n",
    "    end_on = 11,\n",
    "    beam = 2,\n",
    ")\n",
    "print(r_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGS main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regs for one context\n",
    "def regs(model_g, model_d, enData, beam = 2):\n",
    "    r_out = np.zeros((enData.shape[0], decoder_que_pad, 1))\n",
    "    y_out, de_in = inference(model_g, enData)\n",
    "    y_out = np.array(y_out, dtype = np.int32)\n",
    "    de_in = np.array(de_in, dtype = np.int32)\n",
    "    for q in range(0, decoder_que_pad):\n",
    "        # The roll-out length is 10\n",
    "        q10 = q + 10 - 1\n",
    "        if q+10 >= decoder_que_pad:\n",
    "            q10 = decoder_que_pad -1\n",
    "        r_tmp = regs_mcmc(\n",
    "            model_g,\n",
    "            model_d,\n",
    "            enData,\n",
    "            y_out,\n",
    "            start_on = q, # Fix first q words and see the reward.\n",
    "            end_on = q10,\n",
    "            beam = beam,\n",
    "        )\n",
    "        r_out[:, q] = r_tmp[:]\n",
    "    # Variance reducing\n",
    "    r_mean = np.mean(r_out, axis = 0)\n",
    "    r_out = r_out - r_mean\n",
    "    r_out = np.array(r_out, dtype = np.float32)\n",
    "    return de_in, y_out, r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n",
      "[[[-0.0280029 ]\n",
      "  [-0.02804524]\n",
      "  [-0.02808037]\n",
      "  [-0.02797407]\n",
      "  [-0.02798048]\n",
      "  [-0.02794223]\n",
      "  [-0.02799205]\n",
      "  [-0.02805932]\n",
      "  [-0.02804729]\n",
      "  [-0.0280321 ]\n",
      "  [-0.0279795 ]\n",
      "  [-0.02790358]\n",
      "  [-0.02793542]\n",
      "  [-0.02787806]\n",
      "  [-0.02792408]\n",
      "  [-0.02788629]\n",
      "  [-0.02786341]\n",
      "  [-0.02785605]\n",
      "  [-0.0279609 ]\n",
      "  [-0.02795756]\n",
      "  [-0.0279142 ]\n",
      "  [-0.02791004]\n",
      "  [-0.02794739]\n",
      "  [-0.02793569]\n",
      "  [-0.02793002]\n",
      "  [-0.0279094 ]\n",
      "  [-0.02791344]\n",
      "  [-0.02795114]\n",
      "  [-0.02800065]\n",
      "  [-0.02797145]\n",
      "  [-0.0279642 ]\n",
      "  [-0.02790622]\n",
      "  [-0.02789776]\n",
      "  [-0.02787557]\n",
      "  [-0.02785873]\n",
      "  [-0.02785786]\n",
      "  [-0.02782436]\n",
      "  [-0.02779176]\n",
      "  [-0.02778708]\n",
      "  [-0.02777966]\n",
      "  [-0.02776162]\n",
      "  [-0.0277656 ]\n",
      "  [-0.02776456]\n",
      "  [-0.0277648 ]\n",
      "  [-0.02776543]\n",
      "  [-0.02776385]\n",
      "  [-0.02777765]\n",
      "  [-0.02779461]\n",
      "  [-0.02777971]\n",
      "  [-0.02775141]\n",
      "  [-0.02776356]\n",
      "  [-0.02775406]\n",
      "  [-0.0276907 ]\n",
      "  [-0.02766434]\n",
      "  [-0.02762859]\n",
      "  [-0.02761371]\n",
      "  [-0.0276138 ]\n",
      "  [-0.0276071 ]\n",
      "  [-0.02759771]\n",
      "  [-0.0275829 ]\n",
      "  [-0.02759264]\n",
      "  [-0.02758125]\n",
      "  [-0.02758516]\n",
      "  [-0.02759755]\n",
      "  [-0.02760471]\n",
      "  [-0.02759992]\n",
      "  [-0.02758653]\n",
      "  [-0.02756789]\n",
      "  [-0.02758495]\n",
      "  [-0.02759606]\n",
      "  [-0.02759319]\n",
      "  [-0.02758288]\n",
      "  [-0.02756205]\n",
      "  [-0.02753981]\n",
      "  [-0.02749058]\n",
      "  [-0.02745896]\n",
      "  [-0.02746376]\n",
      "  [-0.02743254]\n",
      "  [-0.027408  ]\n",
      "  [-0.02739875]\n",
      "  [-0.02742194]\n",
      "  [-0.02743283]\n",
      "  [-0.02743614]\n",
      "  [-0.02747177]\n",
      "  [-0.02747508]\n",
      "  [-0.02744617]\n",
      "  [-0.02742717]\n",
      "  [-0.02744129]\n",
      "  [-0.02745502]\n",
      "  [-0.0274201 ]\n",
      "  [-0.02743962]\n",
      "  [-0.02741446]\n",
      "  [-0.02737833]\n",
      "  [-0.0273592 ]\n",
      "  [-0.02736983]\n",
      "  [-0.02737454]\n",
      "  [-0.02733583]\n",
      "  [-0.02731796]\n",
      "  [-0.02729583]\n",
      "  [-0.02729234]\n",
      "  [-0.02729454]\n",
      "  [-0.02727509]\n",
      "  [-0.02728894]\n",
      "  [-0.0272729 ]\n",
      "  [-0.02726538]\n",
      "  [-0.0272549 ]\n",
      "  [-0.02726842]\n",
      "  [-0.02724121]\n",
      "  [-0.02722725]\n",
      "  [-0.02720198]\n",
      "  [-0.0271726 ]\n",
      "  [-0.02717485]\n",
      "  [-0.02714567]\n",
      "  [-0.02711561]\n",
      "  [-0.02713285]\n",
      "  [-0.02716222]\n",
      "  [-0.02713289]\n",
      "  [-0.02713683]\n",
      "  [-0.02711062]\n",
      "  [-0.0270692 ]\n",
      "  [-0.02704187]\n",
      "  [-0.02702291]\n",
      "  [-0.02701603]\n",
      "  [-0.02700823]\n",
      "  [-0.02700479]\n",
      "  [-0.02697901]\n",
      "  [-0.02697033]\n",
      "  [-0.02697004]\n",
      "  [-0.02696639]\n",
      "  [-0.02696913]\n",
      "  [-0.02694956]\n",
      "  [-0.02692106]\n",
      "  [-0.02693006]\n",
      "  [-0.02689475]\n",
      "  [-0.02686888]\n",
      "  [-0.0268716 ]\n",
      "  [-0.02685175]\n",
      "  [-0.02685471]\n",
      "  [-0.02685973]\n",
      "  [-0.02683694]\n",
      "  [-0.02681571]\n",
      "  [-0.02680265]\n",
      "  [-0.02678003]\n",
      "  [-0.02678628]\n",
      "  [-0.02679786]\n",
      "  [-0.02680229]\n",
      "  [-0.02678265]\n",
      "  [-0.0267724 ]\n",
      "  [-0.02677486]\n",
      "  [-0.0267574 ]\n",
      "  [-0.02676956]\n",
      "  [-0.02676432]\n",
      "  [-0.0267566 ]\n",
      "  [-0.02673493]\n",
      "  [-0.02672892]\n",
      "  [-0.02671787]\n",
      "  [-0.02672894]\n",
      "  [-0.02671925]\n",
      "  [-0.02669417]\n",
      "  [-0.02670653]\n",
      "  [-0.02667552]\n",
      "  [-0.02667664]\n",
      "  [-0.02669411]\n",
      "  [-0.02666722]\n",
      "  [-0.02664363]\n",
      "  [-0.02662142]\n",
      "  [-0.02663832]\n",
      "  [-0.02662288]\n",
      "  [-0.02664351]\n",
      "  [-0.02663727]\n",
      "  [-0.02662964]\n",
      "  [-0.02662809]\n",
      "  [-0.02664348]\n",
      "  [-0.02665763]\n",
      "  [-0.02664942]\n",
      "  [-0.02662367]\n",
      "  [-0.02661838]\n",
      "  [-0.02657968]\n",
      "  [-0.0265853 ]\n",
      "  [-0.02657449]\n",
      "  [-0.02653752]\n",
      "  [-0.02652479]\n",
      "  [-0.02653657]\n",
      "  [-0.02654048]\n",
      "  [-0.02654342]\n",
      "  [-0.02652868]\n",
      "  [-0.02652548]\n",
      "  [-0.0265136 ]\n",
      "  [-0.02648689]\n",
      "  [-0.02648938]\n",
      "  [-0.02647437]\n",
      "  [-0.0264643 ]\n",
      "  [-0.02646435]\n",
      "  [-0.02646407]\n",
      "  [-0.02646556]\n",
      "  [-0.02647329]\n",
      "  [-0.02647368]\n",
      "  [-0.02645744]\n",
      "  [-0.02645903]\n",
      "  [-0.02646062]\n",
      "  [-0.02646224]\n",
      "  [-0.02646406]\n",
      "  [-0.026466  ]\n",
      "  [-0.02646808]\n",
      "  [-0.02647   ]\n",
      "  [-0.02647159]\n",
      "  [-0.02647288]]\n",
      "\n",
      " [[ 0.01387717]\n",
      "  [ 0.01389128]\n",
      "  [ 0.01388767]\n",
      "  [ 0.01384047]\n",
      "  [ 0.01383518]\n",
      "  [ 0.01379071]\n",
      "  [ 0.01385837]\n",
      "  [ 0.01375161]\n",
      "  [ 0.01375402]\n",
      "  [ 0.01378127]\n",
      "  [ 0.01378348]\n",
      "  [ 0.01372445]\n",
      "  [ 0.01375729]\n",
      "  [ 0.01374452]\n",
      "  [ 0.01380957]\n",
      "  [ 0.01377947]\n",
      "  [ 0.0138113 ]\n",
      "  [ 0.01379979]\n",
      "  [ 0.01386189]\n",
      "  [ 0.01390135]\n",
      "  [ 0.01387697]\n",
      "  [ 0.01381682]\n",
      "  [ 0.01381562]\n",
      "  [ 0.0137656 ]\n",
      "  [ 0.01375932]\n",
      "  [ 0.01371843]\n",
      "  [ 0.01376532]\n",
      "  [ 0.01377927]\n",
      "  [ 0.01380435]\n",
      "  [ 0.01375761]\n",
      "  [ 0.01384991]\n",
      "  [ 0.01380935]\n",
      "  [ 0.0137976 ]\n",
      "  [ 0.01380524]\n",
      "  [ 0.01383916]\n",
      "  [ 0.01385386]\n",
      "  [ 0.01382191]\n",
      "  [ 0.01381112]\n",
      "  [ 0.01378534]\n",
      "  [ 0.01377697]\n",
      "  [ 0.01378199]\n",
      "  [ 0.01375222]\n",
      "  [ 0.01374811]\n",
      "  [ 0.01374573]\n",
      "  [ 0.01376759]\n",
      "  [ 0.01377609]\n",
      "  [ 0.01377027]\n",
      "  [ 0.01381864]\n",
      "  [ 0.01381328]\n",
      "  [ 0.01376206]\n",
      "  [ 0.01377483]\n",
      "  [ 0.01379756]\n",
      "  [ 0.01373935]\n",
      "  [ 0.01375499]\n",
      "  [ 0.01373903]\n",
      "  [ 0.0137202 ]\n",
      "  [ 0.01373549]\n",
      "  [ 0.01377119]\n",
      "  [ 0.01377894]\n",
      "  [ 0.01380254]\n",
      "  [ 0.01382972]\n",
      "  [ 0.0138241 ]\n",
      "  [ 0.01383605]\n",
      "  [ 0.0138612 ]\n",
      "  [ 0.01385076]\n",
      "  [ 0.01380048]\n",
      "  [ 0.01377724]\n",
      "  [ 0.01377083]\n",
      "  [ 0.01379018]\n",
      "  [ 0.01376703]\n",
      "  [ 0.01375613]\n",
      "  [ 0.01377717]\n",
      "  [ 0.01381305]\n",
      "  [ 0.01378272]\n",
      "  [ 0.01377419]\n",
      "  [ 0.0137803 ]\n",
      "  [ 0.01375086]\n",
      "  [ 0.0137425 ]\n",
      "  [ 0.01372048]\n",
      "  [ 0.01372294]\n",
      "  [ 0.01365764]\n",
      "  [ 0.01368949]\n",
      "  [ 0.01366234]\n",
      "  [ 0.01368935]\n",
      "  [ 0.01362232]\n",
      "  [ 0.01364087]\n",
      "  [ 0.01362589]\n",
      "  [ 0.0136636 ]\n",
      "  [ 0.0136791 ]\n",
      "  [ 0.01358783]\n",
      "  [ 0.01359982]\n",
      "  [ 0.01360314]\n",
      "  [ 0.01361909]\n",
      "  [ 0.01364852]\n",
      "  [ 0.01357579]\n",
      "  [ 0.01359992]\n",
      "  [ 0.01359939]\n",
      "  [ 0.0136423 ]\n",
      "  [ 0.01362252]\n",
      "  [ 0.01364991]\n",
      "  [ 0.01367093]\n",
      "  [ 0.01369014]\n",
      "  [ 0.01365462]\n",
      "  [ 0.01360697]\n",
      "  [ 0.01357283]\n",
      "  [ 0.01359311]\n",
      "  [ 0.01353709]\n",
      "  [ 0.01356193]\n",
      "  [ 0.01353792]\n",
      "  [ 0.0135009 ]\n",
      "  [ 0.01347893]\n",
      "  [ 0.01348002]\n",
      "  [ 0.01349701]\n",
      "  [ 0.01342789]\n",
      "  [ 0.01341923]\n",
      "  [ 0.01344743]\n",
      "  [ 0.01347799]\n",
      "  [ 0.01345057]\n",
      "  [ 0.01346894]\n",
      "  [ 0.01349826]\n",
      "  [ 0.01346511]\n",
      "  [ 0.01348941]\n",
      "  [ 0.01346965]\n",
      "  [ 0.01343478]\n",
      "  [ 0.01346518]\n",
      "  [ 0.01342576]\n",
      "  [ 0.01336908]\n",
      "  [ 0.01342886]\n",
      "  [ 0.01342779]\n",
      "  [ 0.01342756]\n",
      "  [ 0.0133638 ]\n",
      "  [ 0.0133976 ]\n",
      "  [ 0.01339496]\n",
      "  [ 0.01331985]\n",
      "  [ 0.01332888]\n",
      "  [ 0.01334136]\n",
      "  [ 0.01328631]\n",
      "  [ 0.0132608 ]\n",
      "  [ 0.01322758]\n",
      "  [ 0.01315852]\n",
      "  [ 0.01315916]\n",
      "  [ 0.0131226 ]\n",
      "  [ 0.01305661]\n",
      "  [ 0.01306574]\n",
      "  [ 0.01303068]\n",
      "  [ 0.01302183]\n",
      "  [ 0.01301987]\n",
      "  [ 0.01298643]\n",
      "  [ 0.01298087]\n",
      "  [ 0.01291167]\n",
      "  [ 0.01289167]\n",
      "  [ 0.01283725]\n",
      "  [ 0.01280428]\n",
      "  [ 0.01281203]\n",
      "  [ 0.01278941]\n",
      "  [ 0.01273349]\n",
      "  [ 0.01273154]\n",
      "  [ 0.01267394]\n",
      "  [ 0.01265294]\n",
      "  [ 0.01269113]\n",
      "  [ 0.0126397 ]\n",
      "  [ 0.01262246]\n",
      "  [ 0.01263026]\n",
      "  [ 0.01256762]\n",
      "  [ 0.01254511]\n",
      "  [ 0.01248498]\n",
      "  [ 0.01246519]\n",
      "  [ 0.01243413]\n",
      "  [ 0.01249805]\n",
      "  [ 0.01242845]\n",
      "  [ 0.01240905]\n",
      "  [ 0.01236816]\n",
      "  [ 0.01234329]\n",
      "  [ 0.01241274]\n",
      "  [ 0.01243147]\n",
      "  [ 0.01239287]\n",
      "  [ 0.01239205]\n",
      "  [ 0.01230112]\n",
      "  [ 0.01234526]\n",
      "  [ 0.01236016]\n",
      "  [ 0.01234888]\n",
      "  [ 0.01229652]\n",
      "  [ 0.01229556]\n",
      "  [ 0.01223151]\n",
      "  [ 0.0122632 ]\n",
      "  [ 0.012287  ]\n",
      "  [ 0.01227   ]\n",
      "  [ 0.01221821]\n",
      "  [ 0.01212983]\n",
      "  [ 0.01210496]\n",
      "  [ 0.01211946]\n",
      "  [ 0.01212941]\n",
      "  [ 0.01212894]\n",
      "  [ 0.01212806]\n",
      "  [ 0.01212481]\n",
      "  [ 0.01211583]\n",
      "  [ 0.01211541]\n",
      "  [ 0.01213285]\n",
      "  [ 0.01213572]\n",
      "  [ 0.01213852]\n",
      "  [ 0.01214106]\n",
      "  [ 0.01214366]\n",
      "  [ 0.01214667]\n",
      "  [ 0.01215   ]\n",
      "  [ 0.01215319]\n",
      "  [ 0.01215586]\n",
      "  [ 0.01215802]]\n",
      "\n",
      " [[ 0.14792265]\n",
      "  [ 0.14793909]\n",
      "  [ 0.14791739]\n",
      "  [ 0.14791358]\n",
      "  [ 0.14792207]\n",
      "  [ 0.14793055]\n",
      "  [ 0.14793453]\n",
      "  [ 0.147999  ]\n",
      "  [ 0.14801285]\n",
      "  [ 0.1479868 ]\n",
      "  [ 0.14796081]\n",
      "  [ 0.14792863]\n",
      "  [ 0.14792788]\n",
      "  [ 0.14791791]\n",
      "  [ 0.14791942]\n",
      "  [ 0.14792648]\n",
      "  [ 0.1479063 ]\n",
      "  [ 0.14790076]\n",
      "  [ 0.14793324]\n",
      "  [ 0.1479207 ]\n",
      "  [ 0.14790267]\n",
      "  [ 0.14795344]\n",
      "  [ 0.14798024]\n",
      "  [ 0.14801243]\n",
      "  [ 0.14800933]\n",
      "  [ 0.14801306]\n",
      "  [ 0.1479157 ]\n",
      "  [ 0.147938  ]\n",
      "  [ 0.14795631]\n",
      "  [ 0.14802688]\n",
      "  [ 0.1479733 ]\n",
      "  [ 0.14797392]\n",
      "  [ 0.14800443]\n",
      "  [ 0.14798868]\n",
      "  [ 0.14796066]\n",
      "  [ 0.14799255]\n",
      "  [ 0.14798874]\n",
      "  [ 0.14794716]\n",
      "  [ 0.14794365]\n",
      "  [ 0.1479365 ]\n",
      "  [ 0.14792284]\n",
      "  [ 0.14790776]\n",
      "  [ 0.14787886]\n",
      "  [ 0.1478942 ]\n",
      "  [ 0.1478906 ]\n",
      "  [ 0.14787209]\n",
      "  [ 0.14790538]\n",
      "  [ 0.1479154 ]\n",
      "  [ 0.1479204 ]\n",
      "  [ 0.1479046 ]\n",
      "  [ 0.14792265]\n",
      "  [ 0.1479035 ]\n",
      "  [ 0.14788857]\n",
      "  [ 0.14783448]\n",
      "  [ 0.14782791]\n",
      "  [ 0.147848  ]\n",
      "  [ 0.14784755]\n",
      "  [ 0.14777105]\n",
      "  [ 0.14772375]\n",
      "  [ 0.14771636]\n",
      "  [ 0.14770533]\n",
      "  [ 0.14770722]\n",
      "  [ 0.14769495]\n",
      "  [ 0.14769533]\n",
      "  [ 0.14771475]\n",
      "  [ 0.14773786]\n",
      "  [ 0.14774238]\n",
      "  [ 0.1477459 ]\n",
      "  [ 0.14779124]\n",
      "  [ 0.14780712]\n",
      "  [ 0.14777899]\n",
      "  [ 0.14776507]\n",
      "  [ 0.14773026]\n",
      "  [ 0.14772391]\n",
      "  [ 0.1477342 ]\n",
      "  [ 0.14770961]\n",
      "  [ 0.14772418]\n",
      "  [ 0.14773369]\n",
      "  [ 0.14774194]\n",
      "  [ 0.14777525]\n",
      "  [ 0.14776683]\n",
      "  [ 0.14781478]\n",
      "  [ 0.14783978]\n",
      "  [ 0.14786945]\n",
      "  [ 0.14791316]\n",
      "  [ 0.14793675]\n",
      "  [ 0.14793804]\n",
      "  [ 0.14791152]\n",
      "  [ 0.14792426]\n",
      "  [ 0.1479522 ]\n",
      "  [ 0.14794365]\n",
      "  [ 0.14796554]\n",
      "  [ 0.14796388]\n",
      "  [ 0.14797081]\n",
      "  [ 0.14798436]\n",
      "  [ 0.14795583]\n",
      "  [ 0.14791805]\n",
      "  [ 0.14789169]\n",
      "  [ 0.14790177]\n",
      "  [ 0.1478605 ]\n",
      "  [ 0.14782003]\n",
      "  [ 0.1477974 ]\n",
      "  [ 0.14783701]\n",
      "  [ 0.14782503]\n",
      "  [ 0.14782098]\n",
      "  [ 0.1477989 ]\n",
      "  [ 0.14779975]\n",
      "  [ 0.1478037 ]\n",
      "  [ 0.14780888]\n",
      "  [ 0.14783597]\n",
      "  [ 0.1478309 ]\n",
      "  [ 0.14783522]\n",
      "  [ 0.1477739 ]\n",
      "  [ 0.14782539]\n",
      "  [ 0.14778611]\n",
      "  [ 0.14777756]\n",
      "  [ 0.14776519]\n",
      "  [ 0.14780256]\n",
      "  [ 0.14775427]\n",
      "  [ 0.1476806 ]\n",
      "  [ 0.14765924]\n",
      "  [ 0.14762257]\n",
      "  [ 0.14762987]\n",
      "  [ 0.14763767]\n",
      "  [ 0.1476411 ]\n",
      "  [ 0.14770105]\n",
      "  [ 0.14775836]\n",
      "  [ 0.14771679]\n",
      "  [ 0.14772224]\n",
      "  [ 0.14772046]\n",
      "  [ 0.14774004]\n",
      "  [ 0.14776835]\n",
      "  [ 0.14779243]\n",
      "  [ 0.14780933]\n",
      "  [ 0.14778447]\n",
      "  [ 0.14778072]\n",
      "  [ 0.14779904]\n",
      "  [ 0.14781295]\n",
      "  [ 0.147825  ]\n",
      "  [ 0.14786556]\n",
      "  [ 0.14785135]\n",
      "  [ 0.14786437]\n",
      "  [ 0.14788657]\n",
      "  [ 0.1478797 ]\n",
      "  [ 0.14790577]\n",
      "  [ 0.14791778]\n",
      "  [ 0.14789939]\n",
      "  [ 0.14791039]\n",
      "  [ 0.1479083 ]\n",
      "  [ 0.14792606]\n",
      "  [ 0.14793263]\n",
      "  [ 0.1479745 ]\n",
      "  [ 0.14799215]\n",
      "  [ 0.14797325]\n",
      "  [ 0.14797851]\n",
      "  [ 0.14799955]\n",
      "  [ 0.14802364]\n",
      "  [ 0.14808026]\n",
      "  [ 0.14807361]\n",
      "  [ 0.14806132]\n",
      "  [ 0.14806354]\n",
      "  [ 0.14806734]\n",
      "  [ 0.14807469]\n",
      "  [ 0.14808168]\n",
      "  [ 0.1480844 ]\n",
      "  [ 0.14810093]\n",
      "  [ 0.14812085]\n",
      "  [ 0.14812335]\n",
      "  [ 0.14809942]\n",
      "  [ 0.14815421]\n",
      "  [ 0.14816077]\n",
      "  [ 0.14818098]\n",
      "  [ 0.1482015 ]\n",
      "  [ 0.14817844]\n",
      "  [ 0.14816073]\n",
      "  [ 0.14816216]\n",
      "  [ 0.14816174]\n",
      "  [ 0.14818826]\n",
      "  [ 0.14816627]\n",
      "  [ 0.14814588]\n",
      "  [ 0.1481215 ]\n",
      "  [ 0.14813456]\n",
      "  [ 0.14813502]\n",
      "  [ 0.14816853]\n",
      "  [ 0.14814499]\n",
      "  [ 0.14811388]\n",
      "  [ 0.14811763]\n",
      "  [ 0.14812991]\n",
      "  [ 0.14816804]\n",
      "  [ 0.14820123]\n",
      "  [ 0.14817198]\n",
      "  [ 0.14818285]\n",
      "  [ 0.14818272]\n",
      "  [ 0.14818245]\n",
      "  [ 0.14818016]\n",
      "  [ 0.14818215]\n",
      "  [ 0.14820242]\n",
      "  [ 0.14817786]\n",
      "  [ 0.14817953]\n",
      "  [ 0.14818123]\n",
      "  [ 0.14818306]\n",
      "  [ 0.14818506]\n",
      "  [ 0.14818706]\n",
      "  [ 0.14818902]\n",
      "  [ 0.14819092]\n",
      "  [ 0.14819261]\n",
      "  [ 0.14819406]]\n",
      "\n",
      " [[-0.13379692]\n",
      "  [-0.13378513]\n",
      "  [-0.13372469]\n",
      "  [-0.13377997]\n",
      "  [-0.13377675]\n",
      "  [-0.13377903]\n",
      "  [-0.13380083]\n",
      "  [-0.1336913 ]\n",
      "  [-0.1337196 ]\n",
      "  [-0.13373595]\n",
      "  [-0.13376477]\n",
      "  [-0.13374951]\n",
      "  [-0.13374975]\n",
      "  [-0.13378437]\n",
      "  [-0.13380492]\n",
      "  [-0.13381967]\n",
      "  [-0.13385421]\n",
      "  [-0.1338445 ]\n",
      "  [-0.13383424]\n",
      "  [-0.13386449]\n",
      "  [-0.13386542]\n",
      "  [-0.13386022]\n",
      "  [-0.13384849]\n",
      "  [-0.13384232]\n",
      "  [-0.13383862]\n",
      "  [-0.13382208]\n",
      "  [-0.13376759]\n",
      "  [-0.13376613]\n",
      "  [-0.13376   ]\n",
      "  [-0.13381302]\n",
      "  [-0.13385901]\n",
      "  [-0.13387704]\n",
      "  [-0.13390426]\n",
      "  [-0.13391834]\n",
      "  [-0.13394111]\n",
      "  [-0.13398856]\n",
      "  [-0.1339863 ]\n",
      "  [-0.13396654]\n",
      "  [-0.13394192]\n",
      "  [-0.13393381]\n",
      "  [-0.1339432 ]\n",
      "  [-0.13389438]\n",
      "  [-0.1338624 ]\n",
      "  [-0.13387513]\n",
      "  [-0.13389274]\n",
      "  [-0.13388431]\n",
      "  [-0.13389799]\n",
      "  [-0.13393942]\n",
      "  [-0.13395396]\n",
      "  [-0.13391528]\n",
      "  [-0.13393392]\n",
      "  [-0.13394701]\n",
      "  [-0.13393724]\n",
      "  [-0.13392511]\n",
      "  [-0.13393836]\n",
      "  [-0.13395448]\n",
      "  [-0.13396923]\n",
      "  [-0.13393514]\n",
      "  [-0.13390498]\n",
      "  [-0.133936  ]\n",
      "  [-0.13394241]\n",
      "  [-0.13395005]\n",
      "  [-0.13394582]\n",
      "  [-0.13395897]\n",
      "  [-0.1339608 ]\n",
      "  [-0.13393843]\n",
      "  [-0.13393308]\n",
      "  [-0.13394886]\n",
      "  [-0.13399646]\n",
      "  [-0.1339781 ]\n",
      "  [-0.13394195]\n",
      "  [-0.13395938]\n",
      "  [-0.13398126]\n",
      "  [-0.13396683]\n",
      "  [-0.13401783]\n",
      "  [-0.13403097]\n",
      "  [-0.1340113 ]\n",
      "  [-0.13404363]\n",
      "  [-0.13405442]\n",
      "  [-0.13409944]\n",
      "  [-0.13400254]\n",
      "  [-0.13407144]\n",
      "  [-0.13406599]\n",
      "  [-0.13408704]\n",
      "  [-0.13406041]\n",
      "  [-0.13413145]\n",
      "  [-0.13413677]\n",
      "  [-0.13413385]\n",
      "  [-0.13414834]\n",
      "  [-0.13411993]\n",
      "  [-0.13410386]\n",
      "  [-0.13415422]\n",
      "  [-0.13420463]\n",
      "  [-0.13426013]\n",
      "  [-0.13419032]\n",
      "  [-0.1341812 ]\n",
      "  [-0.13418159]\n",
      "  [-0.13421603]\n",
      "  [-0.13422847]\n",
      "  [-0.13421807]\n",
      "  [-0.13419643]\n",
      "  [-0.13421246]\n",
      "  [-0.13420269]\n",
      "  [-0.13415912]\n",
      "  [-0.13412842]\n",
      "  [-0.13413712]\n",
      "  [-0.13406841]\n",
      "  [-0.1341244 ]\n",
      "  [-0.13411957]\n",
      "  [-0.13413489]\n",
      "  [-0.13413721]\n",
      "  [-0.1341404 ]\n",
      "  [-0.13412525]\n",
      "  [-0.13413769]\n",
      "  [-0.13407248]\n",
      "  [-0.13406277]\n",
      "  [-0.1341103 ]\n",
      "  [-0.13411632]\n",
      "  [-0.13411258]\n",
      "  [-0.13410966]\n",
      "  [-0.1340825 ]\n",
      "  [-0.13408907]\n",
      "  [-0.1340835 ]\n",
      "  [-0.13406423]\n",
      "  [-0.1341015 ]\n",
      "  [-0.1341478 ]\n",
      "  [-0.13415712]\n",
      "  [-0.1341756 ]\n",
      "  [-0.13418365]\n",
      "  [-0.13417888]\n",
      "  [-0.13415426]\n",
      "  [-0.13424489]\n",
      "  [-0.13425735]\n",
      "  [-0.13423443]\n",
      "  [-0.13424447]\n",
      "  [-0.13425046]\n",
      "  [-0.1342336 ]\n",
      "  [-0.13421904]\n",
      "  [-0.13419285]\n",
      "  [-0.13418713]\n",
      "  [-0.13419479]\n",
      "  [-0.13418433]\n",
      "  [-0.13416317]\n",
      "  [-0.13415916]\n",
      "  [-0.13413858]\n",
      "  [-0.13413733]\n",
      "  [-0.13413662]\n",
      "  [-0.13412443]\n",
      "  [-0.1341143 ]\n",
      "  [-0.13408032]\n",
      "  [-0.13405474]\n",
      "  [-0.13404743]\n",
      "  [-0.13403983]\n",
      "  [-0.13405035]\n",
      "  [-0.13403901]\n",
      "  [-0.13401517]\n",
      "  [-0.13402623]\n",
      "  [-0.13403493]\n",
      "  [-0.1340324 ]\n",
      "  [-0.13404591]\n",
      "  [-0.13402772]\n",
      "  [-0.13401316]\n",
      "  [-0.13401085]\n",
      "  [-0.13398208]\n",
      "  [-0.13398588]\n",
      "  [-0.1339645 ]\n",
      "  [-0.13394773]\n",
      "  [-0.13393462]\n",
      "  [-0.13395396]\n",
      "  [-0.13394539]\n",
      "  [-0.13394018]\n",
      "  [-0.13392104]\n",
      "  [-0.1339013 ]\n",
      "  [-0.13393356]\n",
      "  [-0.13394275]\n",
      "  [-0.13393134]\n",
      "  [-0.13393542]\n",
      "  [-0.1339097 ]\n",
      "  [-0.13392624]\n",
      "  [-0.13393155]\n",
      "  [-0.13393286]\n",
      "  [-0.13390628]\n",
      "  [-0.13389401]\n",
      "  [-0.13385957]\n",
      "  [-0.13386476]\n",
      "  [-0.13387221]\n",
      "  [-0.13386214]\n",
      "  [-0.13383454]\n",
      "  [-0.13381098]\n",
      "  [-0.13381681]\n",
      "  [-0.13381706]\n",
      "  [-0.13384797]\n",
      "  [-0.1338473 ]\n",
      "  [-0.13384646]\n",
      "  [-0.13383943]\n",
      "  [-0.13382468]\n",
      "  [-0.13384414]\n",
      "  [-0.13385326]\n",
      "  [-0.13385624]\n",
      "  [-0.13385913]\n",
      "  [-0.13386188]\n",
      "  [-0.13386466]\n",
      "  [-0.13386773]\n",
      "  [-0.13387094]\n",
      "  [-0.13387412]\n",
      "  [-0.13387689]\n",
      "  [-0.1338792 ]]]\n",
      "float32\n",
      "(4, 207, 1)\n",
      "It takes 158.714 sec.\n"
     ]
    }
   ],
   "source": [
    "st = float(time.time())\n",
    "de_in, y_out, r_out = regs(\n",
    "    seqgan_g, \n",
    "    seqgan_d, \n",
    "    enData = encoder_train[:4],\n",
    ")\n",
    "print(de_in.dtype)\n",
    "print(y_out.dtype)\n",
    "print(r_out)\n",
    "print(r_out.dtype)\n",
    "print(r_out.shape)\n",
    "print('It takes {0:.3f} sec.'.format(float(time.time()) - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{g_name}/mleG.h5')\n",
    "mleD.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqgan_g.load_weights(f'./{g_name}/mleG.h5')\n",
    "seqgan_d.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 5s 7ms/step - loss: 0.6010 - accuracy: 0.8202\n",
      "0.6009974479675293\n",
      "768/768 [==============================] - 6s 7ms/step - loss: 0.6010 - sparse_categorical_crossentropy: 0.6010\n",
      "0.6009975075721741\n"
     ]
    }
   ],
   "source": [
    "loss, _acc = mleG.evaluate([encoder_vali, decoder_vali], teacher_vali)\n",
    "print(loss)\n",
    "loss, _acc = seqgan_g.evaluate([encoder_vali, decoder_vali], teacher_vali) # Full-test-data NLL test\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "minibatch_size = 32\n",
    "epoch = 300\n",
    "g_best_loss = 999\n",
    "num_batch = int(len(teacher_train)//batch_size)\n",
    "report_iter = 5\n",
    "g_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "model saved.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'layer_normalization_16/gamma:0', 'layer_normalization_16/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'layer_normalization_16/gamma:0', 'layer_normalization_16/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'layer_normalization_16/gamma:0', 'layer_normalization_16/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'layer_normalization_16/gamma:0', 'layer_normalization_16/beta:0'] when minimizing the loss.\n",
      "Batch: 1, AdvG loss: -24.1018, D loss: 0.6820, G NLL: 0.6139, D NLL: 0.6017, elapsed time: 1435 secs\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "model saved.\n",
      "Batch: 6, AdvG loss: -6.7229, D loss: 0.6438, G NLL: 0.6136, D NLL: 0.6034, elapsed time: 1540 secs\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "model saved.\n",
      "Batch: 11, AdvG loss: -6.7147, D loss: 0.6517, G NLL: 0.6133, D NLL: 0.6060, elapsed time: 1540 secs\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "model saved.\n",
      "Batch: 16, AdvG loss: -9.5157, D loss: 0.6447, G NLL: 0.6131, D NLL: 0.6089, elapsed time: 1535 secs\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "model saved.\n",
      "Batch: 21, AdvG loss: -13.3246, D loss: 0.6359, G NLL: 0.6130, D NLL: 0.6121, elapsed time: 1530 secs\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "model saved.\n",
      "Batch: 26, AdvG loss: -15.5996, D loss: 0.6322, G NLL: 0.6129, D NLL: 0.6163, elapsed time: 1529 secs\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "model saved.\n",
      "Batch: 31, AdvG loss: -15.8506, D loss: 0.6315, G NLL: 0.6129, D NLL: 0.6205, elapsed time: 1531 secs\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "model saved.\n",
      "Batch: 36, AdvG loss: -13.9917, D loss: 0.6260, G NLL: 0.6129, D NLL: 0.6252, elapsed time: 1531 secs\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "model saved.\n",
      "Batch: 41, AdvG loss: -16.5814, D loss: 0.6211, G NLL: 0.6129, D NLL: 0.6301, elapsed time: 1532 secs\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-aba4633736f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mseqgan_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0menData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_real_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mbeam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             )\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# Train G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-59e45cb575ff>\u001b[0m in \u001b[0;36mregs\u001b[0;34m(model_g, model_d, enData, beam)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mstart_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Fix first q words and see the reward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mend_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mbeam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m         \u001b[0mr_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-419a94d93c0c>\u001b[0m in \u001b[0;36mregs_mcmc\u001b[0;34m(model_g, model_d, en_in, y_inp, start_on, end_on, beam)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         )\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mmost_possible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         most_possible = np.transpose(\n\u001b[1;32m     71\u001b[0m             \u001b[0mmost_possible\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbcList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \"\"\"\n\u001b[0;32m-> 1107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_g_loss = tf.keras.metrics.Mean()\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "sec = int(time.time())\n",
    "\n",
    "g_nll_list = []\n",
    "counter = 0\n",
    "p_time = time.time() # Estimate the time for 50 batches.\n",
    "for e in range(epoch):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_g_loss.reset_states()\n",
    "    train_d_loss.reset_states()\n",
    "    \n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(encoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(decoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(teacher_train)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(encoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(decoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(teacher_vali)\n",
    "    for i in range(num_batch):\n",
    "        print(f'Batch {counter+1}')\n",
    "        #----------------------------- \n",
    "        # Evaluate the loss on model G every 50 batches\n",
    "        if counter % report_iter == 0:\n",
    "            syn_vali = [] # syn for Synthesized Data\n",
    "            for j in range(0, 1024, 128): # Define Test data size\n",
    "                t = seqgan_g.predict(\n",
    "                    [encoder_vali[j:j+128], decoder_vali[j:j+128]], \n",
    "                    batch_size = 128\n",
    "                )\n",
    "                syn_vali.append(t)\n",
    "            syn_vali = np.vstack(syn_vali)\n",
    "            g_vali_loss = loss_object(teacher_vali[:1024], syn_vali)\n",
    "            # Evaluate the loss on model D\n",
    "            syn_vali = np.argmax(syn_vali, axis = -1)\n",
    "            r_vali_fake = seqgan_d(np.vstack([teacher_vali[:1024], syn_vali]))\n",
    "            d_vali_loss = loss_d(\n",
    "                np.vstack([\n",
    "                    np.ones((1024, 1)), \n",
    "                    np.zeros((1024, 1))]),\n",
    "                r_vali_fake,\n",
    "            )\n",
    "            g_nll_list.append(g_vali_loss)\n",
    "            # Save the model G if it is better\n",
    "            if g_vali_loss < g_best_loss:\n",
    "                g_best_loss = g_vali_loss\n",
    "                ckpt_save_path = ckpt_g_manager.save()\n",
    "                ckpt_save_path = ckpt_d_manager.save()\n",
    "                print('model saved.')\n",
    "        #----------------------------- \n",
    "        # Data preparation\n",
    "        # Real part\n",
    "        e_real_batch = encoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        x_real_batch = decoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        y_real_batch = teacher_train[i*batch_size:(i+1)*batch_size]\n",
    "        r_real_batch  = np.ones((batch_size, 1))\n",
    "        # Synthesized part\n",
    "        y_fake_batch, x_fake_batch = inference(\n",
    "            seqgan_g, \n",
    "            e_real_batch,\n",
    "        )\n",
    "        r_fake_batch = np.zeros((batch_size, 1))\n",
    "        # Real + fake and then training\n",
    "        x_batch = np.vstack((x_real_batch, x_fake_batch))\n",
    "        y_batch = np.vstack((y_real_batch, y_fake_batch))\n",
    "        r_batch = np.vstack((r_real_batch, r_fake_batch))\n",
    "        #----------------------------- \n",
    "        # Train D with minibatch approaches.\n",
    "        for j in range(0, batch_size, minibatch_size):\n",
    "            y_minibatch = y_batch[j:j+minibatch_size]\n",
    "            r_minibatch = r_batch[j:j+minibatch_size]\n",
    "            _, d_loss = train_d_step(\n",
    "                y_minibatch, \n",
    "                r_minibatch,\n",
    "            )\n",
    "            train_d_loss.update_state(d_loss)\n",
    "        #----------------------------- \n",
    "        # Update Generator after certain batches\n",
    "        if counter % g_iter == 0:\n",
    "            gST = time.time()\n",
    "            de_in_mcmc, y_out_mcmc, r_out_mcmc = regs(\n",
    "                seqgan_g, \n",
    "                seqgan_d, \n",
    "                enData = e_real_batch,\n",
    "                beam = 2,\n",
    "            )\n",
    "            # Train G\n",
    "            gstep = minibatch_size\n",
    "            for k in range(0, len(de_in_mcmc), gstep):\n",
    "                # Update model\n",
    "                g_loss = train_g_step(\n",
    "                    e_real_batch[k:k+gstep],\n",
    "                    de_in_mcmc[k:k+gstep],\n",
    "                    y_out_mcmc[k:k+gstep],\n",
    "                    r_out_mcmc[k:k+gstep],\n",
    "                )\n",
    "            train_g_loss.update_state(g_loss)\n",
    "            # Teacher forcing\n",
    "            g_loss = seqgan_g.train_on_batch([e_real_batch, x_real_batch], y_real_batch)\n",
    "            train_g_loss.update_state(g_loss)\n",
    "        #-----------------------------\n",
    "        # 50 batches in time\n",
    "        if counter % report_iter == 0:\n",
    "            elapsed_time = time.time() - p_time\n",
    "            p_time = time.time()\n",
    "            print(\n",
    "                f'Batch: {counter+1}, '\n",
    "                f'AdvG loss: {train_g_loss.result():.4f}, '\n",
    "                f'D loss: {train_d_loss.result():.4f}, '\n",
    "                f'G NLL: {g_vali_loss:.4f}, '\n",
    "                f'D NLL: {d_vali_loss:.4f}, '\n",
    "                f'elapsed time: {elapsed_time:.0f} secs'\n",
    "            )\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e_real_batch.shape)\n",
    "print(de_in_mcmc.shape)\n",
    "print(y_out_mcmc.shape)\n",
    "print(r_out_mcmc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 207, 199)\n",
      "(4, 207, 1)\n",
      "(4, 207)\n",
      "tf.Tensor(4657.9746, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = seqgan_g((encoder_vali[:4], decoder_vali[:4]))\n",
    "print(pred.shape)\n",
    "\n",
    "reward = np.ones((pred.shape[0], pred.shape[1], 1))\n",
    "print(reward.shape)\n",
    "\n",
    "loss = loss_object2(teacher_vali[:4], pred)\n",
    "print(loss.shape)\n",
    "\n",
    "loss = policy_loss_function(teacher_vali[:4], pred, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
