{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "# If you have more than 1 GPU, you might want to specify which GPU for training.\n",
    "# In this case, I have 2 GPU and the second one is RTX 2080ti, so I pick the `second` one.\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1' # The second\n",
    "tf.config.set_soft_device_placement(True)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = '20211116_wmt19_en_zh'\n",
    "g_name = '20211122_translate_mle_en_zh_lstm'\n",
    "folder_name = '20211122_translate_mle_en_zh_seqGAN_lstm'\n",
    "\n",
    "encoder_wv_dim = 32\n",
    "decoder_wv_dim = 32\n",
    "encoder_que_pad = 65\n",
    "decoder_que_pad = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train = pickle.load(open(f'{d_name}/encoder_train.pkl', 'rb'))\n",
    "decoder_train = pickle.load(open(f'{d_name}/decoder_train.pkl', 'rb'))\n",
    "teacher_train = pickle.load(open(f'{d_name}/teacher_train.pkl', 'rb'))\n",
    "encoder_vali  = pickle.load(open(f'{d_name}/encoder_vali.pkl', 'rb'))\n",
    "decoder_vali  = pickle.load(open(f'{d_name}/decoder_vali.pkl', 'rb'))\n",
    "teacher_vali  = pickle.load(open(f'{d_name}/teacher_vali.pkl', 'rb'))\n",
    "\n",
    "decoder_idx2word   = pickle.load(open(f'{d_name}/en_idx2word.pkl','rb'))\n",
    "decoder_word2idx   = pickle.load(open(f'{d_name}/en_word2idx.pkl','rb'))\n",
    "encoder_idx2word   = pickle.load(open(f'{d_name}/zh_idx2word.pkl','rb'))\n",
    "encoder_word2idx   = pickle.load(open(f'{d_name}/zh_word2idx.pkl','rb'))\n",
    "\n",
    "decoder_emb32    = pickle.load(open(f'{d_name}/en_emb32.pkl', 'rb'))\n",
    "encoder_emb32    = pickle.load(open(f'{d_name}/zh_emb32.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "4716\n"
     ]
    }
   ],
   "source": [
    "num_decoder_words = np.max([np.max(decoder_train), np.max(decoder_vali)])+1\n",
    "num_encoder_words = np.max([np.max(encoder_train), np.max(encoder_vali)])+1\n",
    "\n",
    "print(num_decoder_words)\n",
    "print(num_encoder_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(seq_tensor, idx2word):\n",
    "    return [''.join([idx2word[i] for i in seq]) for seq in seq_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>1929 or 1989?<eos>                                                                                                                                                                                                ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(decoder_vali[:1], decoder_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年还是1989年?                                                    ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(encoder_vali[:1], encoder_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "[Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n, d = 10, 64\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Multi-Head Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) \n",
    "and [Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_mask(n_gram, que_pad): # For backward sequence #中間那段的mask\n",
    "    mask_upper = np.tri(que_pad, que_pad, -1+n_gram)\n",
    "    mask_lower = np.tri(que_pad, que_pad, -1)\n",
    "    mask = mask_upper - mask_lower\n",
    "    return mask\n",
    "\n",
    "def Transformer(q_que_pad, k_que_pad, wv_dim, k_wv_dim, rate = 0.1, mask = ''):\n",
    "    # Inputs\n",
    "    mem  = Input((q_que_pad, wv_dim))\n",
    "    encode = Input((k_que_pad, k_wv_dim))\n",
    "    # Constants\n",
    "    ff_dim = wv_dim*64\n",
    "    # Multi-Head Attention\n",
    "    q = Dense(wv_dim)(mem)\n",
    "    k = Dense(wv_dim)(encode)\n",
    "    v = Dense(wv_dim)(encode)\n",
    "    # Choose a mask, default: BERT (no mask)\n",
    "    mask_weights = np.ones((q_que_pad, k_que_pad))\n",
    "    if mask == 'GPT':\n",
    "        mask_weights = np.tri(q_que_pad, k_que_pad, 0)\n",
    "    elif mask == 'band':\n",
    "        mask_weights = band_mask(10, q_que_pad)\n",
    "        print(mask_weights)\n",
    "    mem_new = MultiHeadAttention(\n",
    "        num_heads = 4,\n",
    "        key_dim = wv_dim, \n",
    "        value_dim = wv_dim\n",
    "    )(\n",
    "        q, k, v,\n",
    "        attention_mask = mask_weights,\n",
    "    )\n",
    "    mem_new = Dropout(rate)(mem_new)\n",
    "    mem_new = LayerNormalization(epsilon=1e-6)(mem_new+mem)\n",
    "    # Feed-Forward skip-connection\n",
    "    ffn = Dense(ff_dim, activation = 'relu')(mem_new)\n",
    "    ffn = Dense(wv_dim)(ffn)\n",
    "    ffn = Dropout(rate)(ffn)\n",
    "    out = LayerNormalization(epsilon=1e-6)(ffn+mem_new)\n",
    "    model = Model(\n",
    "        [mem, encode],\n",
    "        [mem_new, out],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getE(wv_dim = 16):\n",
    "    _input = Input((encoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_encoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(encoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(encoder_emb32),\n",
    "    )\n",
    "    mem = emb(_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(encoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # forward sentence\n",
    "    for i in range(1):\n",
    "        #gptLayer = Transformer(encoder_que_pad, encoder_que_pad, wv_dim, wv_dim)\n",
    "        #mem, output = gptLayer((mem, mem))\n",
    "        #output = Activation('relu')(output)\n",
    "        #mem = Activation('relu')(mem)\n",
    "        lstmLayer = LSTM(32, return_sequences=True)\n",
    "        mem = lstmLayer(mem)\n",
    "    # Output\n",
    "    output = mem\n",
    "    model = Model(\n",
    "        _input, \n",
    "        output) \n",
    "    return model\n",
    "\n",
    "def getD(wv_dim = 8, encoder_wv_dim = 16):\n",
    "    en_output = Input((encoder_que_pad, encoder_wv_dim))\n",
    "    de_input  = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    mem = emb(de_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # Attention\n",
    "    for j in range(1):\n",
    "        # Self attention\n",
    "        for i in range(1):\n",
    "            #gptLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim, mask = 'GPT')\n",
    "            #mem, _ = gptLayer((mem, mem))\n",
    "            #mem = Activation('relu')(mem)\n",
    "            lstmLayer = LSTM(32, return_sequences=True)\n",
    "            mem = lstmLayer(mem)\n",
    "        # Cross attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, encoder_que_pad, wv_dim, encoder_wv_dim)\n",
    "            mem, output = gptLayer((mem, en_output))\n",
    "            output = Activation('relu')(output)\n",
    "            mem = Activation('relu')(mem)\n",
    "    # Concatenation and output\n",
    "    output = Dense(num_decoder_words)(output)\n",
    "    output = Activation('softmax')(output)\n",
    "    model = Model(\n",
    "        [en_output, de_input], \n",
    "        output,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Language Model\n",
    "def getLM():\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((decoder_que_pad,))\n",
    "    # Encoder (Czech -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim)\n",
    "    de_output = decoder([en_output, de_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input],\n",
    "        de_output,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 65, 32)       159296      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 207, 199)     174567      model[0][0]                      \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleG = getLM()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 11s 13ms/step - loss: 0.5332 - accuracy: 0.8420\n",
      "0.5332431793212891\n"
     ]
    }
   ],
   "source": [
    "mleG.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    enData,\n",
    "    inpData = None,\n",
    "    start_on = 0,\n",
    "    end_on = decoder_que_pad,\n",
    "    batch_size = 1024,\n",
    "):\n",
    "    # Initialize\n",
    "    num_data = len(enData)\n",
    "    num_batch = (num_data-1)//batch_size +1\n",
    "    resp_pred_list = None\n",
    "    in_batch_list = None\n",
    "    the_first = True\n",
    "    for b in range(num_batch):\n",
    "        en_batch = np.zeros((batch_size, encoder_que_pad), dtype = int)\n",
    "        if b == num_batch -1:\n",
    "            en_batch[:num_data - (num_batch-1) * batch_size] = enData[b*batch_size:(b+1)*batch_size]\n",
    "        else:\n",
    "            en_batch = enData[b*batch_size:(b+1)*batch_size]\n",
    "        in_batch = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        if start_on == 0:\n",
    "            in_batch[:,0] = decoder_word2idx['<bos>']\n",
    "        elif b == num_batch -1:\n",
    "            in_batch[:num_data - (num_batch-1) * batch_size] = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        else: \n",
    "            in_batch = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        resp_pred = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        # Generate the sequence recurrsively.\n",
    "        for i in range(start_on, end_on):\n",
    "            # Run\n",
    "            resp_pred_wv = model([en_batch, in_batch])\n",
    "            the_last = resp_pred_wv[:,i]\n",
    "            the_last = tf.reshape(\n",
    "                tf.random.categorical(tf.math.log(the_last), 1), \n",
    "                [batch_size,]\n",
    "            )\n",
    "            try:\n",
    "                resp_pred[:,i] = the_last\n",
    "                in_batch[:,i+1] = the_last\n",
    "            except:\n",
    "                resp_pred[:,i] = the_last\n",
    "        for i in range(len(resp_pred)):\n",
    "            try:\n",
    "                index = list(resp_pred[i]).index(word2idx['<bos>'])\n",
    "            except:\n",
    "                continue\n",
    "            resp_pred[i,index+1:] = 0\n",
    "            in_batch[i,index+1:] = 0\n",
    "        if the_first:\n",
    "            resp_pred_list = resp_pred\n",
    "            in_batch_list = in_batch\n",
    "            the_first = False\n",
    "        else:\n",
    "            resp_pred_list = np.vstack((resp_pred_list, resp_pred))\n",
    "            in_batch_list = np.vstack((in_batch_list, in_batch))\n",
    "    resp_pred_list = resp_pred_list[:num_data]\n",
    "    in_batch_list = in_batch_list[:num_data]\n",
    "    if start_on != 0:\n",
    "        resp_pred_list[:,:start_on] = inpData[:,1:start_on+1]\n",
    "        in_batch_list[:, :start_on+1] = inpData[:,:start_on+1]\n",
    "    return resp_pred_list, in_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predicted sequence\n",
      "['The 1920’s.<eos>                                                                                                                                                                                                   ', 'The Chen pohebing and close crisis may not deepin transfer-helping, one history remembling the opposition to seek hoped the lifting under the offer, it was been us the produced.<eos>                             ']\n",
      "# Real sequence\n",
      "['1929 or 1989?<eos>                                                                                                                                                                                                 ', 'PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.<eos>                                                       ']\n"
     ]
    }
   ],
   "source": [
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2])\n",
    "print('# Predicted sequence')\n",
    "print(seq2word(resp_pred_list, decoder_idx2word))\n",
    "print('# Real sequence')\n",
    "print(seq2word(teacher_vali[:2], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 65)\n",
      "(2, 207)\n",
      "[[ 63  77 113  77   0  76 189 182 102  71  46 151 198   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 183   0  16 158 187  71 166   0  65 158 145 159\n",
      "    0  46 102 182 189  71 152 102   9 158  46 158  46   0 149 139   0 182\n",
      "   46  46  71  10  13 189  31   0  46 159 182   9  71   0  13 182   9   9\n",
      "  158  71   9  46 133   0 158 166   0   9  71 102 149 166 102 158 189 158\n",
      "  182 145 158 149 166 152  46  71  71  85 158 166 153   0 182   0  10 182\n",
      "  166 166  71   9   0 182 166 107   0 158 166   0  46  71  71  85 158 166\n",
      "  153   0  65 159 158 189  71   0  65 149 125 189 107   0  46 145 182 145\n",
      "   71   0  65 159  71 166   0  46 149  10  71   0 149 139   0 145 159  71\n",
      "    0 149  76  76 149  46 158 145  71   0 149 166   0 145 159  71   0  76\n",
      "    9  71  46 158 107  71 166 145 158 182 189   0 182 102 125 145  71   0\n",
      "  145 149   0  65 182  85  71   0 149 125 145  46  37   0  76 182 102  85\n",
      "  182 153  71   5 198   0   0   0   0]]\n",
      "[[ 63  77 113  77   0 149   9   0  63  77 170  77 151 198   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 183   0  68  46   0 145 159  71   0  71 102 149\n",
      "  166 149  10 158 102   0 102   9 158  46 158  46   0 107  71  71  76  71\n",
      "  166  46   0 182 166 107   0  65 158 107  71 166  46 133   0 145 159  71\n",
      "    0  65 149   9 189 107   0 159 182  46   0  13  71  71 166   0  46  71\n",
      "  182   9 102 159 158 166 153   0 139 149   9   0 159 158  46 145 149   9\n",
      "  158 102 182 189   0 182 166 182 189 149 153 158  71  46   0 145 149   0\n",
      "  159  71 189  76   0 125  46   0 125 166 107  71   9  46 145 182 166 107\n",
      "    0  65 159 182 145   0 159 182  46   0  13  71  71 166   0 159 182  76\n",
      "   76  71 166 158 166 153   5 198   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_vali[:2].shape)\n",
    "print(decoder_vali[:2].shape)\n",
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2], decoder_vali[:2], start_on =5)\n",
    "print(resp_pred_list)\n",
    "print(teacher_vali[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Train Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Pre-training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20480, 207)\n",
      "(20480, 1)\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_train[:10240], \n",
    "    batch_size = 1024,\n",
    ")\n",
    "\n",
    "teacher_pre_train_d = np.vstack([teacher_train[:10240], teacher_pred])\n",
    "print(teacher_pre_train_d.shape)\n",
    "\n",
    "reward_train = np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_train_d = np.vstack([reward_train, reward_pred])\n",
    "print(reward_pre_train_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_train_d[-1])\n",
    "#print(reward_pre_train_d[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-validating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 207)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_vali[:1024],\n",
    "    batch_size = 512\n",
    ")\n",
    "teacher_pre_vali_d = np.vstack([teacher_vali[:1024], teacher_pred])\n",
    "print(teacher_pre_vali_d.shape)\n",
    "\n",
    "reward_vali =  np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_vali_d = np.vstack([reward_vali, reward_pred])\n",
    "print(reward_pre_vali_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_vali_d[0])\n",
    "#print(reward_pre_vali_d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(teacher_pre_train_d, open(f'{folder_name}/teacher_pre_train_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_train_d,  open(f'{folder_name}/reward_pre_train_d.pkl','wb'))\n",
    "pickle.dump(teacher_pre_vali_d,  open(f'{folder_name}/teacher_pre_vali_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_vali_d,   open(f'{folder_name}/reward_pre_vali_d.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pre_train_d = pickle.load(open(f'{folder_name}/teacher_pre_train_d.pkl','rb'))\n",
    "reward_pre_train_d  = pickle.load(open(f'{folder_name}/reward_pre_train_d.pkl','rb'))\n",
    "teacher_pre_vali_d  = pickle.load(open(f'{folder_name}/teacher_pre_vali_d.pkl','rb'))\n",
    "reward_pre_vali_d   = pickle.load(open(f'{folder_name}/reward_pre_vali_d.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getC(wv_dim): # Critic/Discriminator\n",
    "    resp = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim,\n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    resp_emb = emb(resp)\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    resp_emb = LayerNormalization(epsilon=1e-6)(resp_emb+pe)\n",
    "    bertLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim)\n",
    "    _, out = bertLayer((resp_emb, resp_emb))\n",
    "    out, *_ = tf.split(out, decoder_que_pad, axis = 1)\n",
    "    reward = Dense(1, activation = 'sigmoid')(out)\n",
    "    reward = Flatten()(reward)\n",
    "    model = Model(\n",
    "        resp,\n",
    "        reward\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 207, 32)      6368        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 207, 32)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 207, 32)      64          tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Functional)            [(None, 207, 32), (N 153248      layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.split (TFOpLambda)           [(None, 1, 32), (Non 0           model_4[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 1)         33          tf.split[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleD=getC(decoder_wv_dim)\n",
    "mleD.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "mleD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object_MleD = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_MleD = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_MleD(real, pred):\n",
    "    loss_ = loss_object_MleD(real, pred)\n",
    "    return loss_\n",
    "\n",
    "@tf.function()\n",
    "def trainMleD(te_in, y_real):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = mleD(te_in)\n",
    "        loss = loss_func_MleD(y_real, y_pred)\n",
    "    gradients = tape.gradient(loss, mleD.trainable_variables)    \n",
    "    optimizer_MleD.apply_gradients(zip(gradients, mleD.trainable_variables))\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved.\n",
      "Epoch 1, D loss: 0.0651, D NLL: 0.9813, elapsed time: 10 secs\n",
      "model saved.\n",
      "Epoch 2, D loss: 0.0653, D NLL: 0.7425, elapsed time: 9 secs\n",
      "Epoch 3, D loss: 0.0644, D NLL: 0.7904, elapsed time: 9 secs\n",
      "model saved.\n",
      "Epoch 4, D loss: 0.0646, D NLL: 0.6985, elapsed time: 9 secs\n",
      "Epoch 5, D loss: 0.0642, D NLL: 0.7167, elapsed time: 8 secs\n",
      "Epoch 6, D loss: 0.0643, D NLL: 0.7030, elapsed time: 10 secs\n",
      "model saved.\n",
      "Epoch 7, D loss: 0.0642, D NLL: 0.6936, elapsed time: 10 secs\n",
      "Epoch 8, D loss: 0.0642, D NLL: 0.7124, elapsed time: 10 secs\n",
      "Epoch 9, D loss: 0.0643, D NLL: 0.6968, elapsed time: 10 secs\n",
      "Epoch 10, D loss: 0.0643, D NLL: 0.7457, elapsed time: 9 secs\n",
      "model saved.\n",
      "Epoch 11, D loss: 0.0643, D NLL: 0.6929, elapsed time: 8 secs\n",
      "Epoch 12, D loss: 0.0641, D NLL: 0.7067, elapsed time: 9 secs\n",
      "Epoch 13, D loss: 0.0641, D NLL: 0.6949, elapsed time: 9 secs\n",
      "Epoch 14, D loss: 0.0639, D NLL: 0.7325, elapsed time: 10 secs\n",
      "Epoch 15, D loss: 0.0642, D NLL: 0.6967, elapsed time: 9 secs\n",
      "Epoch 16, D loss: 0.0639, D NLL: 0.6961, elapsed time: 8 secs\n"
     ]
    }
   ],
   "source": [
    "epoch = 300\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "batch_size = 256\n",
    "num_data =  len(teacher_train)\n",
    "counter = 0\n",
    "d_best_loss = 999\n",
    "\n",
    "for e in range(epoch):\n",
    "    start = int(time.time())\n",
    "    train_d_loss.reset_states()\n",
    "    # Shuffle the data\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(teacher_pre_train_d)\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(reward_pre_train_d)\n",
    "    # Training \n",
    "    for i in range(0, num_data, batch_size):\n",
    "        teacher_batch = teacher_pre_train_d[i:i+batch_size]\n",
    "        reward_batch  = reward_pre_train_d[i:i+batch_size]\n",
    "        _, d_loss = trainMleD(teacher_batch, reward_batch)\n",
    "        train_d_loss.update_state(d_loss)\n",
    "    # NLL test\n",
    "    reward_pre_vali_d_fake = mleD(teacher_pre_vali_d)\n",
    "    d_vali_loss = loss_func_MleD(\n",
    "        reward_pre_vali_d,\n",
    "        reward_pre_vali_d_fake,\n",
    "    )\n",
    "    if d_vali_loss < d_best_loss:\n",
    "        mleD.save(f'{folder_name}/mleD.h5')\n",
    "        print('model saved.')\n",
    "        d_best_loss = d_vali_loss\n",
    "        counter = 0\n",
    "    elif d_vali_loss > d_best_loss:\n",
    "        counter += 1\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\n",
    "        f'Epoch {e+1},'\n",
    "        f' D loss: {train_d_loss.result():.4f},'\n",
    "        f' D NLL: {d_vali_loss:.4f},'\n",
    "        f' elapsed time: {elapsed_time:.0f} secs'\n",
    "    )\n",
    "    # Quit condition\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load parameters onto SeqGAN models from MLE models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeqGAN generator and discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=tf.keras.losses.Reduction.NONE # NONE for not to sum up all loss.\n",
    "    #reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "    #reduction=tf.keras.losses.Reduction.SUM,\n",
    ")\n",
    "\n",
    "optimizer_g = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "def policy_loss_function(real, pred, rewards):\n",
    "    loss_ = loss_object2(real, pred)\n",
    "    loss_ = loss_ * rewards[:,:,0]\n",
    "\n",
    "    return tf.reduce_sum(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_12 (Functional)           (None, 65, 32)       159296      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_14 (Functional)           (None, 207, 199)     174567      model_12[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_g = getLM()\n",
    "seqgan_g.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['sparse_categorical_crossentropy'],\n",
    ")\n",
    "seqgan_g.trainable = True\n",
    "seqgan_g.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_g_step(en_in, de_in, real, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = seqgan_g((en_in, de_in))\n",
    "        loss = policy_loss_function(real, pred, rewards)\n",
    "    gradients = tape.gradient(loss, seqgan_g.trainable_variables)    \n",
    "    optimizer_g.apply_gradients(zip(gradients, seqgan_g.trainable_variables))    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path_g = f\"{folder_name}/seqgan_g\"\n",
    "ckpt_g = tf.train.Checkpoint(model=seqgan_g,optimizer=optimizer_g)\n",
    "ckpt_g_manager = tf.train.CheckpointManager(ckpt_g, checkpoint_path_g, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_g_manager.latest_checkpoint:\n",
    "#    ckpt_g.restore(ckpt_g_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_d = tf.keras.optimizers.Adam(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 207, 32)      6368        input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 207, 32)      0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 207, 32)      64          tf.__operators__.add_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "model_10 (Functional)           [(None, 207, 32), (N 153248      layer_normalization_11[0][0]     \n",
      "                                                                 layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.split_1 (TFOpLambda)         [(None, 1, 32), (Non 0           model_10[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1, 1)         33          tf.split_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_d = getC(decoder_wv_dim)\n",
    "seqgan_d.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "seqgan_d.trainable = True\n",
    "seqgan_d.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_d_step(resp, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = seqgan_d(resp) \n",
    "        loss = loss_d(rewards, pred)\n",
    "    gradients = tape.gradient(loss, seqgan_d.trainable_variables)    \n",
    "    optimizer_d.apply_gradients(zip(gradients, seqgan_d.trainable_variables))\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_d = f\"{folder_name}/seqgan_d\"\n",
    "ckpt_d = tf.train.Checkpoint(model=seqgan_d,optimizer=optimizer_d)\n",
    "ckpt_d_manager = tf.train.CheckpointManager(ckpt_d, checkpoint_path_d, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_d_manager.latest_checkpoint:\n",
    "#    ckpt_d.restore(ckpt_d_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward for Every Generation Step (REGS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_g_predict_batch(model, _inp_list, batch_size, num_data, step, **kwargs):\n",
    "    is_first = 1\n",
    "    y_out = None\n",
    "    num_batch = num_data // batch_size +1\n",
    "    for i in range(0, num_batch*batch_size , batch_size):\n",
    "        y = model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs)[:,step]\n",
    "        if is_first:\n",
    "            is_first = 0\n",
    "            y_out = y\n",
    "        else:\n",
    "            y_out = np.vstack([y_out, y])\n",
    "    return y_out\n",
    "\n",
    "def model_predict_batch(model, _inp_list, batch_size, num_data, **kwargs):\n",
    "    y_out = tf.stack(\n",
    "        [ model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs) \n",
    "         for i in range(0, num_data, batch_size)]\n",
    "    )\n",
    "    return y_out\n",
    "\n",
    "# Under revision, not finished yet\n",
    "def regs_mcmc(\n",
    "    model_g, \n",
    "    model_d,\n",
    "    en_in, \n",
    "    y_inp = None, \n",
    "    start_on = 0, \n",
    "    end_on = 10, \n",
    "    beam = 2,\n",
    "):\n",
    "    # If start on the end of sequence, return.\n",
    "    if start_on == decoder_que_pad -1:\n",
    "        return model_d.predict(y_inp)\n",
    "    # Initialize\n",
    "    num_data = y_inp.shape[0]\n",
    "    en_mcmc = np.array(en_in[:], dtype = int)\n",
    "    y_mcmc = np.zeros((num_data, decoder_que_pad), dtype = int)\n",
    "    de_mcmc = np.zeros((num_data, decoder_que_pad), dtype = int)\n",
    "    r_out = None\n",
    "    de_mcmc[:,0] = decoder_word2idx['<bos>']\n",
    "    if not isinstance(y_inp, type(None)):\n",
    "        y_mcmc[:, :start_on+1] = y_inp[:, :start_on+1]\n",
    "        de_mcmc[:, 1:start_on+2] = y_inp[:, :start_on+1]\n",
    "\n",
    "    # It determines which word to pass down.\n",
    "    beam_list = np.ones(decoder_que_pad, dtype = int)*beam\n",
    "    beam_list[:start_on+1] = 1\n",
    "    beam_list[start_on] = num_data\n",
    "    # bcList stands for beam-candidate list\n",
    "    bcList = []\n",
    "    for i in range(decoder_que_pad):\n",
    "        if i < start_on+1:\n",
    "            bcList.append([])\n",
    "        elif i >= start_on+1:\n",
    "            bcList.append(list(range(num_decoder_words-beam_list[i], num_decoder_words)))\n",
    "        else:\n",
    "            print('Warning')\n",
    "    #print(bcList)\n",
    "    # Generate sequences using MCMC\n",
    "    for t in range(start_on+1, end_on+1):\n",
    "        to_expand = beam_list[t]\n",
    "        the_last = model_g_predict_batch(\n",
    "            model_g, \n",
    "            [en_mcmc, de_mcmc], \n",
    "            batch_size = 1536, \n",
    "            num_data = len(de_mcmc), \n",
    "            step = t,\n",
    "        )\n",
    "        most_possible = np.argsort(the_last, axis = 1)\n",
    "        most_possible = np.transpose(\n",
    "            most_possible[:,bcList[t]]).reshape(\n",
    "            reduce(lambda x,y: x*y, beam_list[:t+1])\n",
    "        )\n",
    "        en_mcmc = np.tile(en_mcmc, (to_expand, 1))\n",
    "        de_mcmc = np.tile(de_mcmc, (to_expand, 1))\n",
    "        y_mcmc = np.tile(y_mcmc, (to_expand, 1))\n",
    "        y_mcmc[:,t] = most_possible\n",
    "        #print(en_mcmc.shape)\n",
    "        #print(de_mcmc.shape)\n",
    "        #print(y_mcmc.shape)\n",
    "        #print('---')\n",
    "        if t+1 < decoder_que_pad:\n",
    "            de_mcmc[:,t+1] = most_possible\n",
    "    # Rank all synthetic sequences\n",
    "    r_mcmc = model_d.predict(y_mcmc)\n",
    "    r_out = np.reshape(np.array([\n",
    "        tf.reduce_mean(r_mcmc[np.arange(i, len(r_mcmc), num_data)], axis = 0) for i in range(num_data)\n",
    "    ]), (num_data, 1))\n",
    "    # Rank each tokens\n",
    "    return r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4473937 ]\n",
      " [0.2266501 ]\n",
      " [0.22451663]\n",
      " [0.21652701]]\n"
     ]
    }
   ],
   "source": [
    "#print(decoder_train[:4])\n",
    "#print(teacher_train[:4])\n",
    "r_tmp = regs_mcmc(\n",
    "    seqgan_g, \n",
    "    seqgan_d, \n",
    "    encoder_train[:4],\n",
    "    teacher_train[:4], \n",
    "    start_on = 2,\n",
    "    end_on = 11,\n",
    "    beam = 2,\n",
    ")\n",
    "print(r_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGS main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regs for one context\n",
    "def regs(model_g, model_d, enData, beam = 2):\n",
    "    #st = float(time.time())\n",
    "    r_out = np.zeros((enData.shape[0], decoder_que_pad, 1))\n",
    "    y_out, de_in = inference(model_g, enData)\n",
    "    y_out = np.array(y_out, dtype = np.int32)\n",
    "    de_in = np.array(de_in, dtype = np.int32)\n",
    "    for q in range(0, decoder_que_pad):\n",
    "        # The roll-out length is 10\n",
    "        q10 = q + 10 - 1\n",
    "        if q+10 >= decoder_que_pad:\n",
    "            q10 = decoder_que_pad -1\n",
    "        r_tmp = regs_mcmc(\n",
    "            model_g,\n",
    "            model_d,\n",
    "            enData,\n",
    "            y_out,\n",
    "            start_on = q, # Fix first q words and see the reward.\n",
    "            end_on = q10,\n",
    "            beam = beam,\n",
    "        )\n",
    "        r_out[:, q] = r_tmp[:]\n",
    "        #print('{1} takes {0:.3f} sec.'.format(float(time.time()) - st, q))\n",
    "    # Variance reducing\n",
    "    r_mean = np.mean(r_out, axis = 0)\n",
    "    r_out = r_out - r_mean\n",
    "    r_out = np.array(r_out, dtype = np.float32)\n",
    "    return de_in, y_out, r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n",
      "float32\n",
      "(4, 207, 1)\n",
      "It takes 112.761 sec.\n"
     ]
    }
   ],
   "source": [
    "st = float(time.time())\n",
    "de_in, y_out, r_out = regs(\n",
    "    seqgan_g, \n",
    "    seqgan_d, \n",
    "    enData = encoder_train[:4],\n",
    "    beam = 2,\n",
    ")\n",
    "print(de_in.dtype)\n",
    "print(y_out.dtype)\n",
    "print(r_out.dtype)\n",
    "print(r_out.shape)\n",
    "#print(r_out)\n",
    "print('It takes {0:.3f} sec.'.format(float(time.time()) - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "mleD.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqgan_g.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "seqgan_d.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 10s 12ms/step - loss: 0.5332 - accuracy: 0.8420\n",
      "0.5332431793212891\n",
      "768/768 [==============================] - 11s 13ms/step - loss: 0.5332 - sparse_categorical_crossentropy: 0.5332\n",
      "0.5332278609275818\n"
     ]
    }
   ],
   "source": [
    "loss, _acc = mleG.evaluate([encoder_vali, decoder_vali], teacher_vali)\n",
    "print(loss)\n",
    "loss, _acc = seqgan_g.evaluate([encoder_vali, decoder_vali], teacher_vali) # Full-test-data NLL test\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "minibatch_size = 32\n",
    "epoch = 300\n",
    "g_best_loss = 999\n",
    "num_batch = int(len(teacher_train)//batch_size)\n",
    "report_iter = 5\n",
    "g_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2048,4,207,207] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Softmax]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ad473928c610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# Evaluate the loss on model D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0msyn_vali\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_vali\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mr_vali_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqgan_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteacher_vali\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn_vali\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             d_vali_loss = loss_d(\n\u001b[1;32m     45\u001b[0m                 np.vstack([\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 421\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 421\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/multi_head_attention.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, value, key, attention_mask, return_attention_scores, training)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     attention_output, attention_scores = self._compute_attention(\n\u001b[0;32m--> 511\u001b[0;31m         query, key, value, attention_mask, training)\n\u001b[0m\u001b[1;32m    512\u001b[0m     \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/multi_head_attention.py\u001b[0m in \u001b[0;36m_compute_attention\u001b[0;34m(self, query, key, value, attention_mask, training)\u001b[0m\n\u001b[1;32m    473\u001b[0m                                                query)\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masked_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/multi_head_attention.py\u001b[0m in \u001b[0;36m_masked_softmax\u001b[0;34m(self, attention_scores, attention_mask)\u001b[0m\n\u001b[1;32m    436\u001b[0m         attention_mask = array_ops.expand_dims(\n\u001b[1;32m    437\u001b[0m             attention_mask, axis=mask_expansion_axes)\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   def _compute_attention(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/advanced_activations.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    347\u001b[0m             inputs, axis=self.axis, keepdims=True))\n\u001b[1;32m    348\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   4780\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4781\u001b[0m   \"\"\"\n\u001b[0;32m-> 4782\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 instructions)\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(logits, axis, name, dim)\u001b[0m\n\u001b[1;32m   3709\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3711\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_2d_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_wrap_2d_function\u001b[0;34m(inputs, compute_op, dim, name)\u001b[0m\n\u001b[1;32m   3618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_last_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3620\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3622\u001b[0m   \u001b[0mdim_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(logits, name)\u001b[0m\n\u001b[1;32m  10862\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10863\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10864\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10865\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10866\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,4,207,207] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Softmax]"
     ]
    }
   ],
   "source": [
    "train_g_loss = tf.keras.metrics.Mean()\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "sec = int(time.time())\n",
    "\n",
    "g_nll_list = []\n",
    "counter = 0\n",
    "p_time = time.time() # Estimate the time for 50 batches.\n",
    "for e in range(epoch):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_g_loss.reset_states()\n",
    "    train_d_loss.reset_states()\n",
    "    \n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(encoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(decoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(teacher_train)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(encoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(decoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(teacher_vali)\n",
    "    for i in range(num_batch):\n",
    "        print(f'Batch {counter+1}')\n",
    "        #----------------------------- \n",
    "        # Evaluate the loss on model G every 50 batches\n",
    "        if counter % report_iter == 0:\n",
    "            syn_vali = [] # syn for Synthesized Data\n",
    "            for j in range(0, 1024, 128): # Define Test data size\n",
    "                t = seqgan_g.predict(\n",
    "                    [encoder_vali[j:j+128], decoder_vali[j:j+128]], \n",
    "                    batch_size = 128\n",
    "                )\n",
    "                syn_vali.append(t)\n",
    "            syn_vali = np.vstack(syn_vali)\n",
    "            g_vali_loss = loss_object(teacher_vali[:1024], syn_vali)\n",
    "            # Evaluate the loss on model D\n",
    "            syn_vali = np.argmax(syn_vali, axis = -1)\n",
    "            r_vali_fake = seqgan_d(np.vstack([teacher_vali[:1024], syn_vali]))\n",
    "            d_vali_loss = loss_d(\n",
    "                np.vstack([\n",
    "                    np.ones((1024, 1)), \n",
    "                    np.zeros((1024, 1))]),\n",
    "                r_vali_fake,\n",
    "            )\n",
    "            g_nll_list.append(g_vali_loss)\n",
    "            # Save the model G if it is better\n",
    "            if g_vali_loss < g_best_loss:\n",
    "                g_best_loss = g_vali_loss\n",
    "                ckpt_save_path = ckpt_g_manager.save()\n",
    "                ckpt_save_path = ckpt_d_manager.save()\n",
    "                print('model saved.')\n",
    "        #----------------------------- \n",
    "        # Data preparation\n",
    "        # Real part\n",
    "        e_real_batch = encoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        x_real_batch = decoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        y_real_batch = teacher_train[i*batch_size:(i+1)*batch_size]\n",
    "        r_real_batch  = np.ones((batch_size, 1))\n",
    "        # Synthesized part\n",
    "        y_fake_batch, x_fake_batch = inference(\n",
    "            seqgan_g, \n",
    "            e_real_batch,\n",
    "        )\n",
    "        r_fake_batch = np.zeros((batch_size, 1))\n",
    "        # Real + fake and then training\n",
    "        x_batch = np.vstack((x_real_batch, x_fake_batch))\n",
    "        y_batch = np.vstack((y_real_batch, y_fake_batch))\n",
    "        r_batch = np.vstack((r_real_batch, r_fake_batch))\n",
    "        #----------------------------- \n",
    "        # Train D with minibatch approaches.\n",
    "        for j in range(0, batch_size, minibatch_size):\n",
    "            y_minibatch = y_batch[j:j+minibatch_size]\n",
    "            r_minibatch = r_batch[j:j+minibatch_size]\n",
    "            _, d_loss = train_d_step(\n",
    "                y_minibatch, \n",
    "                r_minibatch,\n",
    "            )\n",
    "            train_d_loss.update_state(d_loss)\n",
    "        #----------------------------- \n",
    "        # Update Generator after certain batches\n",
    "        if counter % g_iter == 0:\n",
    "            gST = time.time()\n",
    "            de_in_mcmc, y_out_mcmc, r_out_mcmc = regs(\n",
    "                seqgan_g, \n",
    "                seqgan_d, \n",
    "                enData = e_real_batch,\n",
    "                beam = 2,\n",
    "            )\n",
    "            # Train G\n",
    "            gstep = minibatch_size\n",
    "            for k in range(0, len(de_in_mcmc), gstep):\n",
    "                # Update model\n",
    "                g_loss = train_g_step(\n",
    "                    e_real_batch[k:k+gstep],\n",
    "                    de_in_mcmc[k:k+gstep],\n",
    "                    y_out_mcmc[k:k+gstep],\n",
    "                    r_out_mcmc[k:k+gstep],\n",
    "                )\n",
    "            train_g_loss.update_state(g_loss)\n",
    "            # Teacher forcing\n",
    "            g_loss = seqgan_g.train_on_batch([e_real_batch, x_real_batch], y_real_batch)\n",
    "            train_g_loss.update_state(g_loss)\n",
    "        #-----------------------------\n",
    "        # 50 batches in time\n",
    "        if counter % report_iter == 0:\n",
    "            elapsed_time = time.time() - p_time\n",
    "            p_time = time.time()\n",
    "            print(\n",
    "                f'Batch: {counter+1}, '\n",
    "                f'AdvG loss: {train_g_loss.result():.4f}, '\n",
    "                f'D loss: {train_d_loss.result():.4f}, '\n",
    "                f'G NLL: {g_vali_loss:.4f}, '\n",
    "                f'D NLL: {d_vali_loss:.4f}, '\n",
    "                f'elapsed time: {elapsed_time:.0f} secs'\n",
    "            )\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(g_nll_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5af422d950>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_g.restore(ckpt_g_manager.latest_checkpoint)\n",
    "ckpt_d.restore(ckpt_d_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 65)\n",
      "(64, 207)\n",
      "(64, 207)\n",
      "(64, 207, 1)\n"
     ]
    }
   ],
   "source": [
    "print(e_real_batch.shape)\n",
    "print(de_in_mcmc.shape)\n",
    "print(y_out_mcmc.shape)\n",
    "print(r_out_mcmc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 207, 199)\n",
      "(4, 207, 1)\n",
      "(4, 207)\n"
     ]
    }
   ],
   "source": [
    "pred = seqgan_g((encoder_vali[:4], decoder_vali[:4]))\n",
    "print(pred.shape)\n",
    "\n",
    "reward = np.ones((pred.shape[0], pred.shape[1], 1))\n",
    "print(reward.shape)\n",
    "\n",
    "loss = loss_object2(teacher_vali[:4], pred)\n",
    "print(loss.shape)\n",
    "\n",
    "loss = policy_loss_function(teacher_vali[:4], pred, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
