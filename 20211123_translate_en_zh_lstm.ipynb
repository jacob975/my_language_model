{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a797fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.7.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Activation, Dropout\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# If you have more than 1 GPU, you might want to specify which GPU for training.\n",
    "# In this case, I have 2 GPU and the second one is RTX 2080ti, so I pick the `second` one.\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' # The second\n",
    "os.cpu_count()\n",
    "tf.config.set_soft_device_placement(True)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ffa7c1",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ef2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = '20211116_wmt19_en_zh'\n",
    "folder_name = '20211123_translate_mle_en_zh_lstm'\n",
    "\n",
    "encoder_wv_dim = 32\n",
    "decoder_wv_dim = 32\n",
    "encoder_que_pad = 65\n",
    "decoder_que_pad = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2830aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f8f60a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a677e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train = pickle.load(open(f'{d_name}/encoder_train.pkl', 'rb'))\n",
    "decoder_train = pickle.load(open(f'{d_name}/decoder_train.pkl', 'rb'))\n",
    "teacher_train = pickle.load(open(f'{d_name}/teacher_train.pkl', 'rb'))\n",
    "encoder_vali  = pickle.load(open(f'{d_name}/encoder_vali.pkl', 'rb'))\n",
    "decoder_vali  = pickle.load(open(f'{d_name}/decoder_vali.pkl', 'rb'))\n",
    "teacher_vali  = pickle.load(open(f'{d_name}/teacher_vali.pkl', 'rb'))\n",
    "\n",
    "decoder_idx2word   = pickle.load(open(f'{d_name}/en_idx2word.pkl','rb'))\n",
    "decoder_word2idx   = pickle.load(open(f'{d_name}/en_word2idx.pkl','rb'))\n",
    "encoder_idx2word   = pickle.load(open(f'{d_name}/zh_idx2word.pkl','rb'))\n",
    "encoder_word2idx   = pickle.load(open(f'{d_name}/zh_word2idx.pkl','rb'))\n",
    "\n",
    "#decoder_emb32   = pickle.load(open(f'{d_name}/en_emb32.pkl', 'rb'))\n",
    "#encoder_emb32   = pickle.load(open(f'{d_name}/zh_emb32.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c669c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221040, 65)\n",
      "(221040, 207)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_train.shape)\n",
    "print(teacher_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386102b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "4716\n"
     ]
    }
   ],
   "source": [
    "num_decoder_words = np.max([np.max(decoder_train), np.max(decoder_vali)])+1\n",
    "num_encoder_words = np.max([np.max(encoder_train), np.max(encoder_vali)])+1\n",
    "\n",
    "print(num_decoder_words)\n",
    "print(num_encoder_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83efa187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(seq_tensor, idx2word):\n",
    "    return [''.join([idx2word[i] for i in seq]) for seq in seq_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1e4a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>1929 or 1989?<eos>                                                                                                                                                                                                ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(decoder_vali[:1], decoder_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ee1b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年还是1989年?                                                    ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(encoder_vali[:1], encoder_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88816684",
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "[Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e8c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17791714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n, d = 10, 64\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359b1b1",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7aa58",
   "metadata": {},
   "source": [
    "[Multi-Head Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) \n",
    "and [Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fb7c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformer(q_que_pad, k_que_pad, wv_dim, k_wv_dim, rate = 0.1, mask = ''):\n",
    "    # Inputs\n",
    "    mem  = Input((q_que_pad, wv_dim))\n",
    "    encode = Input((k_que_pad, k_wv_dim))\n",
    "    # Constants\n",
    "    ff_dim = wv_dim*64\n",
    "    # Multi-Head Attention\n",
    "    q = Dense(wv_dim)(mem)\n",
    "    k = Dense(wv_dim)(encode)\n",
    "    v = Dense(wv_dim)(encode)\n",
    "    # Choose a mask, default: BERT (no mask)\n",
    "    mask_weights = np.ones((q_que_pad, k_que_pad))\n",
    "    if mask == 'GPT':\n",
    "        mask_weights = np.tri(q_que_pad, k_que_pad, 0)\n",
    "    mem_new = MultiHeadAttention(\n",
    "        num_heads = 4,\n",
    "        key_dim = wv_dim, \n",
    "        value_dim = wv_dim\n",
    "    )(\n",
    "        q, k, v,\n",
    "        attention_mask = mask_weights\n",
    "    )\n",
    "    mem_new = Dropout(rate)(mem_new)\n",
    "    mem_new = LayerNormalization(epsilon=1e-6)(mem_new+mem)\n",
    "    # Feed-Forward skip-connection\n",
    "    ffn = Dense(ff_dim, activation = 'relu')(mem_new)\n",
    "    ffn = Dense(wv_dim)(ffn)\n",
    "    ffn = Dropout(rate)(ffn)\n",
    "    out = LayerNormalization(epsilon=1e-6)(ffn+mem_new)\n",
    "    model = Model(\n",
    "        [mem, encode],\n",
    "        [mem_new, out],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getE(wv_dim = 16):\n",
    "    _input = Input((encoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_encoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(encoder_que_pad)),\n",
    "        trainable = True,\n",
    "        #embeddings_initializer=tf.keras.initializers.Constant(encoder_emb32),\n",
    "    )\n",
    "    mem = emb(_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(encoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # forward sentence\n",
    "    for i in range(1):\n",
    "        gptLayer = Transformer(encoder_que_pad, encoder_que_pad, wv_dim, wv_dim)\n",
    "        mem, output = gptLayer((mem, mem))\n",
    "        output = Activation('relu')(output)\n",
    "        mem = Activation('relu')(mem)\n",
    "    # Output\n",
    "    output = mem\n",
    "    model = Model(\n",
    "        _input, \n",
    "        output) \n",
    "    return model\n",
    "\n",
    "def getD(wv_dim = 8, encoder_wv_dim = 16):\n",
    "    en_output = Input((encoder_que_pad, encoder_wv_dim))\n",
    "    de_input  = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        #embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    mem = emb(de_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # Attention\n",
    "    for j in range(1):\n",
    "        # Self attention\n",
    "        for i in range(1):\n",
    "            #gptLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim, mask = 'GPT')\n",
    "            #mem, _ = gptLayer((mem, mem))\n",
    "            #mem = Activation('relu')(mem)\n",
    "            lstmLayer = LSTM(32, return_sequences=True)\n",
    "            mem = lstmLayer(mem)\n",
    "        # Cross attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, encoder_que_pad, wv_dim, encoder_wv_dim)\n",
    "            mem, output = gptLayer((mem, en_output))\n",
    "            output = Activation('relu')(output)\n",
    "            mem = Activation('relu')(mem)\n",
    "    # Concatenation and output\n",
    "    output = Dense(num_decoder_words)(output)\n",
    "    output = Activation('softmax')(output)\n",
    "    model = Model(\n",
    "        [en_output, de_input], \n",
    "        output,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Language Model\n",
    "def getLM():\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((decoder_que_pad,))\n",
    "    # Encoder (Chinese -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    encoder.summary()\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim)\n",
    "    decoder.summary()\n",
    "    de_output = decoder([en_output, de_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input],\n",
    "        de_output,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976817c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 65)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 65, 32)       150912      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 65, 32)      0           ['embedding[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 65, 32)      64          ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 65, 32),     153248      ['layer_normalization[0][0]',    \n",
      "                                 (None, 65, 32)]                  'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 65, 32)       0           ['model[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 304,224\n",
      "Trainable params: 304,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 207)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 207, 32)      6368        ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 207, 32)     0           ['embedding_1[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 207, 32)     64          ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 207, 32)      8320        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 65, 32)]     0           []                               \n",
      "                                                                                                  \n",
      " model_2 (Functional)           [(None, 207, 32),    153248      ['lstm[0][0]',                   \n",
      "                                 (None, 207, 32)]                 'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 207, 32)      0           ['model_2[0][1]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 207, 199)     6567        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 207, 199)     0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 174,567\n",
      "Trainable params: 174,567\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 65)]         0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 65, 32)       304224      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 207)]        0           []                               \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 207, 199)     174567      ['model_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 478,791\n",
      "Trainable params: 478,791\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleG = getLM()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff45dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'layer_normalization_2/gamma:0', 'layer_normalization_2/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'layer_normalization_2/gamma:0', 'layer_normalization_2/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      " 394/1727 [=====>........................] - ETA: 46s - loss: 2.1148 - accuracy: 0.5483"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6580/391621384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m mleG.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mencoder_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mteacher_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mleG.fit(\n",
    "    [encoder_train, decoder_train], \n",
    "    teacher_train, \n",
    "    batch_size=128, \n",
    "    epochs=300, \n",
    "    shuffle=True, \n",
    "    validation_data = (\n",
    "        [encoder_vali, decoder_vali], \n",
    "        teacher_vali\n",
    "    ), \n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            f'./{folder_name}/mleG.h5', \n",
    "            save_best_only=True, \n",
    "            monitor = \"val_loss\"\n",
    "        ),\n",
    "        EarlyStopping(monitor='val_loss', patience=5),\n",
    "        CSVLogger(f'{folder_name}/mleG.csv'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{folder_name}/mleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "rows = csv.reader(open(f'{folder_name}/mleG.csv'))\n",
    "nll_mle = []\n",
    "for i, row in enumerate(rows):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    nll_mle.append(float(row[-1]))\n",
    "plt.plot(nll_mle, )\n",
    "plt.grid(True)\n",
    "plt.ylabel('nll_test')\n",
    "plt.xlabel('training iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4739f",
   "metadata": {},
   "source": [
    "## Inference train D (False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6bbb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    enData = None,\n",
    "):\n",
    "    # Initialize\n",
    "    resp_pred_list = None\n",
    "    in_batch_list = None\n",
    "    the_first = True\n",
    "    \n",
    "    in_batch = np.zeros((len(enData), decoder_que_pad), dtype = int)\n",
    "    in_batch[:,0] = decoder_word2idx['<bos>']\n",
    "    en_batch = enData\n",
    "    resp_pred = np.zeros(in_batch.shape, dtype = int)\n",
    "    # Generate the sequence recurrsively.\n",
    "    for i in range(decoder_que_pad):\n",
    "        # Run\n",
    "        resp_pred_wv = model([en_batch, in_batch])\n",
    "        the_last = resp_pred_wv[:,i]\n",
    "        # Stochastic\n",
    "        the_last_one = tf.reshape(\n",
    "            tf.random.categorical(tf.math.log(the_last), 1), \n",
    "            [len(enData),]\n",
    "        )\n",
    "        # TODO: greedy\n",
    "        the_last_two = tf.math.argmax(the_last, axis = 1)\n",
    "        try:\n",
    "            resp_pred[:,i] = the_last_one\n",
    "            in_batch[:,i+1] = the_last_one\n",
    "        except:\n",
    "            resp_pred[:,i] = the_last_one\n",
    "    # Remove the words after <eos>\n",
    "    for i in range(len(resp_pred)):\n",
    "        try:\n",
    "            index = list(resp_pred[i]).index(en_word2idx['<eos>'])\n",
    "        except:\n",
    "            continue\n",
    "        resp_pred[i,index+1:] = 0\n",
    "        in_batch[i,index+1:] = 0\n",
    "        \n",
    "    return resp_pred, in_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_pred_list, _ = inference(mleG, [encoder_vali[123]])\n",
    "print('# Predicted sequence')\n",
    "print(seq2word(resp_pred_list, decoder_idx2word))\n",
    "print('# Real sequence')\n",
    "print(seq2word([decoder_vali[123]], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c7594",
   "metadata": {},
   "source": [
    "# Step 2: Slow MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG = getLM()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate = 1e-5),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7486d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{folder_name}/mleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19508014",
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.fit(\n",
    "    [encoder_train, decoder_train], \n",
    "    teacher_train, \n",
    "    batch_size=128, \n",
    "    epochs=300, \n",
    "    shuffle=True, \n",
    "    validation_data = (\n",
    "        [encoder_vali, decoder_vali], \n",
    "        teacher_vali\n",
    "    ), \n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            f'./{folder_name}/slowmleG.h5', \n",
    "            save_best_only=True, \n",
    "            monitor = \"val_loss\"\n",
    "        ),\n",
    "        EarlyStopping(monitor='val_loss', patience=5),\n",
    "        CSVLogger(f'{folder_name}/slowmleG.csv'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "with Pool(5) as p:\n",
    "    print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "rows = csv.reader(open(f'{folder_name}/slowmleG.csv'))\n",
    "nll_mle = []\n",
    "for i, row in enumerate(rows):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    nll_mle.append(float(row[-1]))\n",
    "plt.plot(nll_mle, )\n",
    "plt.grid(True)\n",
    "plt.ylabel('nll_test')\n",
    "plt.xlabel('training iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2277e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{folder_name}/slowmleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f76215",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_pred_list, _ = inference(mleG, [encoder_vali[123]])\n",
    "print('# Predicted sequence')\n",
    "print(seq2word(resp_pred_list, decoder_idx2word))\n",
    "print('# Real sequence')\n",
    "print(seq2word([decoder_vali[123]], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5ad4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
