{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "id": "f0d2ec03",
=======
   "id": "d4286ec7",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "# If you have more than 1 GPU, you might want to specify which GPU for training.\n",
    "# In this case, I have 2 GPU and the second one is RTX 2080ti, so I pick the `second` one.\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1' # The second\n",
    "tf.config.set_soft_device_placement(True)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "bcea2fe2",
=======
   "id": "5ee0f645",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
<<<<<<< HEAD
   "id": "c74b89e6",
=======
   "id": "68f0410f",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = '20211116_wmt19_en_zh'\n",
    "g_name = '20211122_translate_mle_en_zh_lstm'\n",
    "folder_name = '20211123_translate_mle_en_zh_seqGAN_lstm'\n",
    "\n",
    "encoder_wv_dim = 32\n",
    "decoder_wv_dim = 32\n",
    "encoder_que_pad = 65\n",
    "decoder_que_pad = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
<<<<<<< HEAD
   "id": "d5cae702",
=======
   "id": "a910b306",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "08b5790c",
=======
   "id": "eef1999a",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
<<<<<<< HEAD
   "id": "0b37ae9a",
=======
   "id": "6acf99e7",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train = pickle.load(open(f'{d_name}/encoder_train.pkl', 'rb'))\n",
    "decoder_train = pickle.load(open(f'{d_name}/decoder_train.pkl', 'rb'))\n",
    "teacher_train = pickle.load(open(f'{d_name}/teacher_train.pkl', 'rb'))\n",
    "encoder_vali  = pickle.load(open(f'{d_name}/encoder_vali.pkl', 'rb'))\n",
    "decoder_vali  = pickle.load(open(f'{d_name}/decoder_vali.pkl', 'rb'))\n",
    "teacher_vali  = pickle.load(open(f'{d_name}/teacher_vali.pkl', 'rb'))\n",
    "\n",
    "decoder_idx2word   = pickle.load(open(f'{d_name}/en_idx2word.pkl','rb'))\n",
    "decoder_word2idx   = pickle.load(open(f'{d_name}/en_word2idx.pkl','rb'))\n",
    "encoder_idx2word   = pickle.load(open(f'{d_name}/zh_idx2word.pkl','rb'))\n",
    "encoder_word2idx   = pickle.load(open(f'{d_name}/zh_word2idx.pkl','rb'))\n",
    "\n",
    "decoder_emb32    = pickle.load(open(f'{d_name}/en_emb32.pkl', 'rb'))\n",
    "encoder_emb32    = pickle.load(open(f'{d_name}/zh_emb32.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
<<<<<<< HEAD
   "id": "e25db064",
=======
   "id": "08f23689",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "4716\n"
     ]
    }
   ],
   "source": [
    "num_decoder_words = np.max([np.max(decoder_train), np.max(decoder_vali)])+1\n",
    "num_encoder_words = np.max([np.max(encoder_train), np.max(encoder_vali)])+1\n",
    "\n",
    "print(num_decoder_words)\n",
    "print(num_encoder_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
<<<<<<< HEAD
   "id": "e759c51e",
=======
   "id": "4cb12d01",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(seq_tensor, idx2word):\n",
    "    return [''.join([idx2word[i] for i in seq]) for seq in seq_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
<<<<<<< HEAD
   "id": "42189d71",
=======
   "id": "a95aaf53",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>1929 or 1989?<eos>                                                                                                                                                                                                ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(decoder_vali[:1], decoder_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
<<<<<<< HEAD
   "id": "11ee6c54",
=======
   "id": "f9308417",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年还是1989年?                                                    ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(encoder_vali[:1], encoder_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "1cb2bf07",
=======
   "id": "b0b2415c",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "[Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
<<<<<<< HEAD
   "id": "e9726c00",
=======
   "id": "557bc94f",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
<<<<<<< HEAD
   "id": "6016133b",
=======
   "id": "f525563b",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n, d = 10, 64\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "d92af70e",
=======
   "id": "52dbbaff",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "6238f4fa",
=======
   "id": "e3008b3f",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "[Multi-Head Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) \n",
    "and [Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
<<<<<<< HEAD
   "id": "453d4c3d",
=======
   "id": "c40951fa",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_mask(n_gram, que_pad): # For backward sequence #中間那段的mask\n",
    "    mask_upper = np.tri(que_pad, que_pad, -1+n_gram)\n",
    "    mask_lower = np.tri(que_pad, que_pad, -1)\n",
    "    mask = mask_upper - mask_lower\n",
    "    return mask\n",
    "\n",
    "def Transformer(q_que_pad, k_que_pad, wv_dim, k_wv_dim, rate = 0.1, mask = ''):\n",
    "    # Inputs\n",
    "    mem  = Input((q_que_pad, wv_dim))\n",
    "    encode = Input((k_que_pad, k_wv_dim))\n",
    "    # Constants\n",
    "    ff_dim = wv_dim*64\n",
    "    # Multi-Head Attention\n",
    "    q = Dense(wv_dim)(mem)\n",
    "    k = Dense(wv_dim)(encode)\n",
    "    v = Dense(wv_dim)(encode)\n",
    "    # Choose a mask, default: BERT (no mask)\n",
    "    mask_weights = np.ones((q_que_pad, k_que_pad))\n",
    "    if mask == 'GPT':\n",
    "        mask_weights = np.tri(q_que_pad, k_que_pad, 0)\n",
    "    elif mask == 'band':\n",
    "        mask_weights = band_mask(10, q_que_pad)\n",
    "        print(mask_weights)\n",
    "    mem_new = MultiHeadAttention(\n",
    "        num_heads = 4,\n",
    "        key_dim = wv_dim, \n",
    "        value_dim = wv_dim\n",
    "    )(\n",
    "        q, k, v,\n",
    "        attention_mask = mask_weights,\n",
    "    )\n",
    "    mem_new = Dropout(rate)(mem_new)\n",
    "    mem_new = LayerNormalization(epsilon=1e-6)(mem_new+mem)\n",
    "    # Feed-Forward skip-connection\n",
    "    ffn = Dense(ff_dim, activation = 'relu')(mem_new)\n",
    "    ffn = Dense(wv_dim)(ffn)\n",
    "    ffn = Dropout(rate)(ffn)\n",
    "    out = LayerNormalization(epsilon=1e-6)(ffn+mem_new)\n",
    "    model = Model(\n",
    "        [mem, encode],\n",
    "        [mem_new, out],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getE(wv_dim = 16):\n",
    "    _input = Input((encoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_encoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(encoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(encoder_emb32),\n",
    "    )\n",
    "    mem = emb(_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(encoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # forward sentence\n",
    "    for i in range(1):\n",
    "        #gptLayer = Transformer(encoder_que_pad, encoder_que_pad, wv_dim, wv_dim)\n",
    "        #mem, output = gptLayer((mem, mem))\n",
    "        #output = Activation('relu')(output)\n",
    "        #mem = Activation('relu')(mem)\n",
    "        lstmLayer = LSTM(32, return_sequences=True)\n",
    "        mem = lstmLayer(mem)\n",
    "    # Output\n",
    "    output = mem\n",
    "    model = Model(\n",
    "        _input, \n",
    "        output) \n",
    "    return model\n",
    "\n",
    "def getD(\n",
    "    wv_dim = 32, \n",
    "    encoder_wv_dim = 32, \n",
    "    decoder_que_pad = decoder_que_pad,\n",
    "    given_state = False,\n",
    "):\n",
    "    # Inputs\n",
    "    en_output = Input((encoder_que_pad, encoder_wv_dim))\n",
    "    de_input  = Input((decoder_que_pad,))\n",
    "    if given_state:\n",
    "        h_input = Input((wv_dim,))\n",
    "        c_input = Input((wv_dim,))\n",
    "    # Embedding\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    mem = emb(de_input)\n",
    "    # Position Encoding\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # Attention\n",
    "    for j in range(1):\n",
    "        # Self attention\n",
    "        for i in range(1):\n",
    "            #gptLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim, mask = 'GPT')\n",
    "            #mem, _ = gptLayer((mem, mem))\n",
    "            #mem = Activation('relu')(mem)\n",
    "            lstmLayer = LSTM(32, return_sequences=True, return_state = True)\n",
    "            if given_state:\n",
    "                mem, state_h, state_c = lstmLayer(mem, initial_state=[h_input, c_input])\n",
    "            else:\n",
    "                mem, state_h, state_c = lstmLayer(mem)\n",
    "        # Cross attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, encoder_que_pad, wv_dim, encoder_wv_dim)\n",
    "            mem, output = gptLayer((mem, en_output))\n",
    "            output = Activation('relu')(output)\n",
    "            mem = Activation('relu')(mem)\n",
    "    # Concatenation and output\n",
    "    output = Dense(num_decoder_words)(output)\n",
    "    output = Activation('softmax')(output)\n",
    "    if given_state:\n",
    "        model = Model(\n",
    "            [en_output, de_input, h_input, c_input], \n",
    "            [output, state_h, state_c],\n",
    "        )\n",
    "        return model\n",
    "    else:\n",
    "        model = Model(\n",
    "            [en_output, de_input], \n",
    "            [output, state_h, state_c],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# Language Model\n",
    "def getLM():\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((decoder_que_pad,))\n",
    "    # Encoder (Czech -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim)\n",
    "    de_output, _, _ = decoder([en_output, de_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input],\n",
    "        de_output,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getLMstate():\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((decoder_que_pad,))\n",
    "    # Encoder (Czech -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim)\n",
    "    de_output, state_h, state_c = decoder([en_output, de_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input],\n",
    "        [de_output, state_h, state_c],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getLMmcmc(len_mcmc = 10):\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((len_mcmc,))\n",
    "    h_input = Input((decoder_wv_dim,))\n",
    "    c_input = Input((decoder_wv_dim,))\n",
    "    # Encoder (Czech -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim, len_mcmc, given_state = True)\n",
    "    de_output, _, _ = decoder([en_output, de_input, h_input, c_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input, h_input, c_input],\n",
    "        de_output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
<<<<<<< HEAD
   "id": "06b2adb6",
=======
   "id": "c0069f1a",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 65, 32)       159296      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            [(None, 207, 199), ( 174567      model[0][0]                      \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleG = getLM()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
<<<<<<< HEAD
   "id": "bb8d20e0",
=======
   "id": "aeaa2f6d",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Functional)            (None, 65, 32)       159296      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_6 (Functional)            [(None, 207, 199), ( 174567      model_4[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(1, 32)\n",
      "(1, 32)\n"
     ]
    }
   ],
   "source": [
    "mleGstate = getLMstate()\n",
    "mleGstate.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "mleGstate.summary()\n",
    "_, state_h, state_c = mleGstate([encoder_train[:1], decoder_train[:1]])\n",
    "print(state_h.shape)\n",
    "print(state_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
<<<<<<< HEAD
   "id": "d8e8c139",
=======
   "id": "b6f12128",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 199)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_8 (Functional)            (None, 65, 32)       159296      input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_10 (Functional)           [(None, 10, 199), (N 174567      model_8[0][0]                    \n",
      "                                                                 input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleGmcmc = getLMmcmc()\n",
    "mleGmcmc.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "output = mleGmcmc([encoder_train[:1], decoder_train[:1, :10], np.ones((1,32)), np.ones((1,32))])\n",
    "print(output.shape)\n",
    "mleGmcmc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
<<<<<<< HEAD
   "id": "5755d5d8",
=======
   "id": "17bda4e4",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 10s 12ms/step - loss: 0.5332 - accuracy: 0.8420\n",
      "0.5332431793212891\n"
     ]
    }
   ],
   "source": [
    "mleG.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "9640c701",
=======
   "id": "f108e833",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
<<<<<<< HEAD
   "id": "ec3be59c",
=======
   "id": "26e09a89",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    enData,\n",
    "    inpData = None,\n",
    "    start_on = 0,\n",
    "    end_on = decoder_que_pad,\n",
    "    batch_size = 1024,\n",
    "):\n",
    "    # Initialize\n",
    "    num_data = len(enData)\n",
    "    num_batch = (num_data-1)//batch_size +1\n",
    "    resp_pred_list = None\n",
    "    in_batch_list = None\n",
    "    the_first = True\n",
    "    for b in range(num_batch):\n",
    "        en_batch = np.zeros((batch_size, encoder_que_pad), dtype = int)\n",
    "        if b == num_batch -1:\n",
    "            en_batch[:num_data - (num_batch-1) * batch_size] = enData[b*batch_size:(b+1)*batch_size]\n",
    "        else:\n",
    "            en_batch = enData[b*batch_size:(b+1)*batch_size]\n",
    "        in_batch = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        if start_on == 0:\n",
    "            in_batch[:,0] = decoder_word2idx['<bos>']\n",
    "        elif b == num_batch -1:\n",
    "            in_batch[:num_data - (num_batch-1) * batch_size] = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        else: \n",
    "            in_batch = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        resp_pred = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        # Generate the sequence recurrsively.\n",
    "        for i in range(start_on, end_on):\n",
    "            # Run\n",
    "            resp_pred_wv = model([en_batch, in_batch])\n",
    "            the_last = resp_pred_wv[:,i]\n",
    "            the_last = tf.reshape(\n",
    "                tf.random.categorical(tf.math.log(the_last), 1), \n",
    "                [batch_size,]\n",
    "            )\n",
    "            try:\n",
    "                resp_pred[:,i] = the_last\n",
    "                in_batch[:,i+1] = the_last\n",
    "            except:\n",
    "                resp_pred[:,i] = the_last\n",
    "        for i in range(len(resp_pred)):\n",
    "            try:\n",
    "                index = list(resp_pred[i]).index(word2idx['<bos>'])\n",
    "            except:\n",
    "                continue\n",
    "            resp_pred[i,index+1:] = 0\n",
    "            in_batch[i,index+1:] = 0\n",
    "        if the_first:\n",
    "            resp_pred_list = resp_pred\n",
    "            in_batch_list = in_batch\n",
    "            the_first = False\n",
    "        else:\n",
    "            resp_pred_list = np.vstack((resp_pred_list, resp_pred))\n",
    "            in_batch_list = np.vstack((in_batch_list, in_batch))\n",
    "    resp_pred_list = resp_pred_list[:num_data]\n",
    "    in_batch_list = in_batch_list[:num_data]\n",
    "    if start_on != 0:\n",
    "        resp_pred_list[:,:start_on] = inpData[:,1:start_on+1]\n",
    "        in_batch_list[:, :start_on+1] = inpData[:,:start_on+1]\n",
    "    return resp_pred_list, in_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
<<<<<<< HEAD
   "id": "ef5f07a2",
=======
   "id": "ed3b46b4",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predicted sequence\n",
      "['Consider Meeting the North<eos>                                                                                                                                                                                    ', 'PARIS, Brazers looking as the formism and primary unintensive political history and finding world in the world bear of which have of mistrust for current minority office.<eos>                                    ']\n",
      "# Real sequence\n",
      "['1929 or 1989?<eos>                                                                                                                                                                                                 ', 'PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.<eos>                                                       ']\n"
     ]
    }
   ],
   "source": [
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2])\n",
    "print('# Predicted sequence')\n",
    "print(seq2word(resp_pred_list, decoder_idx2word))\n",
    "print('# Real sequence')\n",
    "print(seq2word(teacher_vali[:2], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
<<<<<<< HEAD
   "id": "21a9e3d1",
=======
   "id": "5b369f21",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 65)\n",
      "(2, 207)\n",
      "[[ 63  77 113  77   0  65 182  46   0  82  71  46 158  46 145 182  79  71\n",
      "  198   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 139 149   9   0  76   9 149  46  71 102 145  46\n",
      "    0 182 166 107   0  46  65 158 166 153   0  76 189 182  31 158 166 153\n",
      "    0 102   9 158  46  71  46 133   0 182 166 107   0  76 189 182  31  46\n",
      "  133   0 182 166 107   0  46  76 149   9 145  46   0  76 182  46  46  71\n",
      "  107 133   0 159 149  65  71 187  71   9   0  65 159  71   9  71   0 158\n",
      "  145  46   0 139 158   9  46 145   0 159 182  46   0  76   9 149 107 125\n",
      "  102  71   0  71 187  71 166 145 189  31   0 182 189 149 166  71   0 149\n",
      "  139   0 187 182 189 125  71   0 139 149   9   0 153 149 182 189  46   5\n",
      "  198   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]]\n",
      "[[ 63  77 113  77   0 149   9   0  63  77 170  77 151 198   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 183   0  68  46   0 145 159  71   0  71 102 149\n",
      "  166 149  10 158 102   0 102   9 158  46 158  46   0 107  71  71  76  71\n",
      "  166  46   0 182 166 107   0  65 158 107  71 166  46 133   0 145 159  71\n",
      "    0  65 149   9 189 107   0 159 182  46   0  13  71  71 166   0  46  71\n",
      "  182   9 102 159 158 166 153   0 139 149   9   0 159 158  46 145 149   9\n",
      "  158 102 182 189   0 182 166 182 189 149 153 158  71  46   0 145 149   0\n",
      "  159  71 189  76   0 125  46   0 125 166 107  71   9  46 145 182 166 107\n",
      "    0  65 159 182 145   0 159 182  46   0  13  71  71 166   0 159 182  76\n",
      "   76  71 166 158 166 153   5 198   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_vali[:2].shape)\n",
    "print(decoder_vali[:2].shape)\n",
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2], decoder_vali[:2], start_on =5)\n",
    "print(resp_pred_list)\n",
    "print(teacher_vali[:2])"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "78d21f99",
=======
   "id": "4d941a54",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Pre-Train Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "f8bd80b0",
=======
   "id": "0792f833",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "##  Pre-training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
<<<<<<< HEAD
   "id": "12c53560",
=======
   "id": "46373c79",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20480, 207)\n",
      "(20480, 1)\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_train[:10240], \n",
    "    batch_size = 1024,\n",
    ")\n",
    "\n",
    "teacher_pre_train_d = np.vstack([teacher_train[:10240], teacher_pred])\n",
    "print(teacher_pre_train_d.shape)\n",
    "\n",
    "reward_train = np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_train_d = np.vstack([reward_train, reward_pred])\n",
    "print(reward_pre_train_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
<<<<<<< HEAD
   "id": "a92597e4",
=======
   "id": "8e084764",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_train_d[-1])\n",
    "#print(reward_pre_train_d[-1])"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "88f1361c",
=======
   "id": "ed38c4e4",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## Pre-validating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
<<<<<<< HEAD
   "id": "07c8568d",
=======
   "id": "9e740650",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 207)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_vali[:1024],\n",
    "    batch_size = 512\n",
    ")\n",
    "teacher_pre_vali_d = np.vstack([teacher_vali[:1024], teacher_pred])\n",
    "print(teacher_pre_vali_d.shape)\n",
    "\n",
    "reward_vali =  np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_vali_d = np.vstack([reward_vali, reward_pred])\n",
    "print(reward_pre_vali_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
<<<<<<< HEAD
   "id": "f4aeac35",
=======
   "id": "bfda06fb",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_vali_d[0])\n",
    "#print(reward_pre_vali_d[0])"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "bd10e13d",
=======
   "id": "ef83ea33",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## Save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
<<<<<<< HEAD
   "id": "1ad12c23",
=======
   "id": "7579a4c8",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(teacher_pre_train_d, open(f'{folder_name}/teacher_pre_train_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_train_d,  open(f'{folder_name}/reward_pre_train_d.pkl','wb'))\n",
    "pickle.dump(teacher_pre_vali_d,  open(f'{folder_name}/teacher_pre_vali_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_vali_d,   open(f'{folder_name}/reward_pre_vali_d.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "e43d4ca2",
=======
   "id": "f62252c3",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## Load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
<<<<<<< HEAD
   "id": "9ee43199",
=======
   "id": "9e204644",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pre_train_d = pickle.load(open(f'{folder_name}/teacher_pre_train_d.pkl','rb'))\n",
    "reward_pre_train_d  = pickle.load(open(f'{folder_name}/reward_pre_train_d.pkl','rb'))\n",
    "teacher_pre_vali_d  = pickle.load(open(f'{folder_name}/teacher_pre_vali_d.pkl','rb'))\n",
    "reward_pre_vali_d   = pickle.load(open(f'{folder_name}/reward_pre_vali_d.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "f3874410",
=======
   "id": "08176f52",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
<<<<<<< HEAD
   "id": "0ccfec39",
=======
   "id": "379a7427",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "def getC(wv_dim): # Critic/Discriminator\n",
    "    resp = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim,\n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    resp_emb = emb(resp)\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    resp_emb = LayerNormalization(epsilon=1e-6)(resp_emb+pe)\n",
    "    bertLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim)\n",
    "    _, out = bertLayer((resp_emb, resp_emb))\n",
    "    out, *_ = tf.split(out, decoder_que_pad, axis = 1)\n",
    "    reward = Dense(1, activation = 'sigmoid')(out)\n",
    "    reward = Flatten()(reward)\n",
    "    model = Model(\n",
    "        resp,\n",
    "        reward\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
<<<<<<< HEAD
   "id": "83a2002b",
=======
   "id": "a6db37ea",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 207, 32)      6368        input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 207, 32)      0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 207, 32)      64          tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "model_12 (Functional)           [(None, 207, 32), (N 153248      layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.split (TFOpLambda)           [(None, 1, 32), (Non 0           model_12[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1, 1)         33          tf.split[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleD=getC(decoder_wv_dim)\n",
    "mleD.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "mleD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
<<<<<<< HEAD
   "id": "14aead80",
=======
   "id": "663547ed",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object_MleD = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_MleD = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
<<<<<<< HEAD
   "id": "fb5dc89d",
=======
   "id": "2064ba73",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_MleD(real, pred):\n",
    "    loss_ = loss_object_MleD(real, pred)\n",
    "    return loss_\n",
    "\n",
    "@tf.function()\n",
    "def trainMleD(te_in, y_real):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = mleD(te_in)\n",
    "        loss = loss_func_MleD(y_real, y_pred)\n",
    "    gradients = tape.gradient(loss, mleD.trainable_variables)    \n",
    "    optimizer_MleD.apply_gradients(zip(gradients, mleD.trainable_variables))\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
<<<<<<< HEAD
   "id": "7d72efaf",
=======
   "id": "aba99ff8",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved.\n",
      "Epoch 1, D loss: 0.0656, D NLL: 0.7315, elapsed time: 8 secs\n",
      "model saved.\n",
      "Epoch 2, D loss: 0.0648, D NLL: 0.7127, elapsed time: 6 secs\n",
      "model saved.\n",
      "Epoch 3, D loss: 0.0646, D NLL: 0.6951, elapsed time: 6 secs\n",
      "Epoch 4, D loss: 0.0643, D NLL: 0.7618, elapsed time: 6 secs\n",
      "model saved.\n",
      "Epoch 5, D loss: 0.0645, D NLL: 0.6933, elapsed time: 6 secs\n",
      "Epoch 6, D loss: 0.0642, D NLL: 0.6994, elapsed time: 6 secs\n",
      "Epoch 7, D loss: 0.0643, D NLL: 0.6987, elapsed time: 6 secs\n",
      "Epoch 8, D loss: 0.0642, D NLL: 0.7122, elapsed time: 6 secs\n",
      "Epoch 9, D loss: 0.0643, D NLL: 0.6960, elapsed time: 5 secs\n",
      "Epoch 10, D loss: 0.0641, D NLL: 0.6968, elapsed time: 6 secs\n"
     ]
    }
   ],
   "source": [
    "epoch = 300\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "batch_size = 256\n",
    "num_data =  len(teacher_train)\n",
    "counter = 0\n",
    "d_best_loss = 999\n",
    "\n",
    "for e in range(epoch):\n",
    "    start = int(time.time())\n",
    "    train_d_loss.reset_states()\n",
    "    # Shuffle the data\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(teacher_pre_train_d)\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(reward_pre_train_d)\n",
    "    # Training \n",
    "    for i in range(0, num_data, batch_size):\n",
    "        teacher_batch = teacher_pre_train_d[i:i+batch_size]\n",
    "        reward_batch  = reward_pre_train_d[i:i+batch_size]\n",
    "        _, d_loss = trainMleD(teacher_batch, reward_batch)\n",
    "        train_d_loss.update_state(d_loss)\n",
    "    # NLL test\n",
    "    reward_pre_vali_d_fake = mleD(teacher_pre_vali_d)\n",
    "    d_vali_loss = loss_func_MleD(\n",
    "        reward_pre_vali_d,\n",
    "        reward_pre_vali_d_fake,\n",
    "    )\n",
    "    if d_vali_loss < d_best_loss:\n",
    "        mleD.save(f'{folder_name}/mleD.h5')\n",
    "        print('model saved.')\n",
    "        d_best_loss = d_vali_loss\n",
    "        counter = 0\n",
    "    elif d_vali_loss > d_best_loss:\n",
    "        counter += 1\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\n",
    "        f'Epoch {e+1},'\n",
    "        f' D loss: {train_d_loss.result():.4f},'\n",
    "        f' D NLL: {d_vali_loss:.4f},'\n",
    "        f' elapsed time: {elapsed_time:.0f} secs'\n",
    "    )\n",
    "    # Quit condition\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "765eac68",
=======
   "id": "153b5dc9",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Load parameters onto SeqGAN models from MLE models"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "e82e2d4b",
=======
   "id": "814b02a0",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
<<<<<<< HEAD
   "id": "330e378c",
=======
   "id": "af7900e9",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "b05a0d23",
=======
   "id": "25c42141",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## SeqGAN generator and discriminator"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "37f1a48c",
=======
   "id": "490621a8",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
<<<<<<< HEAD
   "id": "6dea520a",
=======
   "id": "d7240c29",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=tf.keras.losses.Reduction.NONE # NONE for not to sum up all loss.\n",
    "    #reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "    #reduction=tf.keras.losses.Reduction.SUM,\n",
    ")\n",
    "\n",
    "optimizer_g = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "def policy_loss_function(real, pred, rewards):\n",
    "    loss_ = loss_object2(real, pred)\n",
    "    loss_ = loss_ * rewards[:,:,0]\n",
    "\n",
    "    return tf.reduce_sum(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
<<<<<<< HEAD
   "id": "f186fc12",
=======
   "id": "acd1f691",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_14 (Functional)           (None, 65, 32)       159296      input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_16 (Functional)           [(None, 207, 199), ( 174567      model_14[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_g = getLM()\n",
    "seqgan_g.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['sparse_categorical_crossentropy'],\n",
    ")\n",
    "seqgan_g.trainable = True\n",
    "seqgan_g.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_g_step(en_in, de_in, real, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = seqgan_g((en_in, de_in))\n",
    "        loss = policy_loss_function(real, pred, rewards)\n",
    "    gradients = tape.gradient(loss, seqgan_g.trainable_variables)    \n",
    "    optimizer_g.apply_gradients(zip(gradients, seqgan_g.trainable_variables))    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
<<<<<<< HEAD
   "id": "8df0f686",
=======
   "id": "3fc21637",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_g = f\"{folder_name}/seqgan_g\"\n",
    "ckpt_g = tf.train.Checkpoint(model=seqgan_g,optimizer=optimizer_g)\n",
    "ckpt_g_manager = tf.train.CheckpointManager(ckpt_g, checkpoint_path_g, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_g_manager.latest_checkpoint:\n",
    "#    ckpt_g.restore(ckpt_g_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "ef8603b1",
=======
   "id": "abc6a219",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
<<<<<<< HEAD
   "id": "0822f24f",
=======
   "id": "15871b17",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_d = tf.keras.optimizers.Adam(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
<<<<<<< HEAD
   "id": "11de0496",
=======
   "id": "975eb3a7",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 207, 32)      6368        input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_19 (TFOpLa (None, 207, 32)      0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 207, 32)      64          tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "model_18 (Functional)           [(None, 207, 32), (N 153248      layer_normalization_19[0][0]     \n",
      "                                                                 layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.split_1 (TFOpLambda)         [(None, 1, 32), (Non 0           model_18[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 1, 1)         33          tf.split_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_d = getC(decoder_wv_dim)\n",
    "seqgan_d.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "seqgan_d.trainable = True\n",
    "seqgan_d.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_d_step(resp, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = seqgan_d(resp) \n",
    "        loss = loss_d(rewards, pred)\n",
    "    gradients = tape.gradient(loss, seqgan_d.trainable_variables)    \n",
    "    optimizer_d.apply_gradients(zip(gradients, seqgan_d.trainable_variables))\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
<<<<<<< HEAD
   "id": "5c897b4d",
=======
   "id": "efe5a732",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_d = f\"{folder_name}/seqgan_d\"\n",
    "ckpt_d = tf.train.Checkpoint(model=seqgan_d,optimizer=optimizer_d)\n",
    "ckpt_d_manager = tf.train.CheckpointManager(ckpt_d, checkpoint_path_d, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_d_manager.latest_checkpoint:\n",
    "#    ckpt_d.restore(ckpt_d_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "117cd42f",
=======
   "id": "1d711232",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Reward for Every Generation Step (REGS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
<<<<<<< HEAD
   "id": "4d4f8ffd",
=======
   "id": "438f4f51",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_g_predict_batch(model, _inp_list, batch_size, num_data, step, **kwargs):\n",
    "    is_first = 1\n",
    "    y_out = None\n",
    "    num_batch = num_data // batch_size +1\n",
    "    for i in range(0, num_batch*batch_size , batch_size):\n",
    "        y = model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs)[:,step]\n",
    "        if is_first:\n",
    "            is_first = 0\n",
    "            y_out = y\n",
    "        else:\n",
    "            y_out = np.vstack([y_out, y])\n",
    "    return y_out\n",
    "\n",
    "def model_predict_batch(model, _inp_list, batch_size, num_data, **kwargs):\n",
    "    y_out = tf.stack(\n",
    "        [ model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs) \n",
    "         for i in range(0, num_data, batch_size)]\n",
    "    )\n",
    "    return y_out\n",
    "\n",
    "# Under revision, not finished yet\n",
    "def regs_mcmc(\n",
    "    model_g_mcmc,\n",
    "    model_d,\n",
    "    en_in, \n",
    "    y_inp,\n",
    "    h_in,\n",
    "    c_in,\n",
    "    start_on = 0,\n",
    "    end_on = 10,\n",
    "    beam = 2,\n",
    "):\n",
    "    # If start on the end of sequence, return.\n",
    "    if start_on == decoder_que_pad -1:\n",
    "        return model_d.predict(y_inp)\n",
    "    # Initialize sequences for Monte Carlo Tree Search\n",
    "    len_mcmc = 10\n",
    "    num_data = y_inp.shape[0]\n",
    "    en_mcmc = np.array(en_in[:], dtype = int)\n",
    "    h_mcmc  = np.array(h_in[:])\n",
    "    c_mcmc  = np.array(c_in[:])\n",
    "    y_mcmc = np.zeros(y_inp.shape, dtype = int)\n",
    "    y_mcmc[:,:start_on] = y_inp[:,:start_on]\n",
    "    de_mcmc = np.zeros((num_data, len_mcmc), dtype = int)\n",
    "    de_mcmc[:,0] = y_inp[:,start_on]\n",
    "    r_out = None\n",
    "    # It determines which word to pass down.\n",
    "    beam_list = np.ones(end_on - start_on, dtype = int)*beam\n",
    "    # bcList stands for beam-candidate list\n",
    "    bcList = []\n",
    "    for i in range(end_on - start_on):\n",
    "        bcList.append(list(range(num_decoder_words-beam, num_decoder_words)))\n",
    "    #print(beam_list)\n",
    "    #print(bcList)\n",
    "    # Generate sequences using MCMC\n",
    "    for t in range(0, end_on - start_on):\n",
    "        to_expand = beam_list[t]\n",
    "        the_last = model_g_predict_batch(\n",
    "            model_g_mcmc, \n",
    "            [en_mcmc, de_mcmc, h_mcmc, c_mcmc], \n",
    "            batch_size = 1536, \n",
    "            num_data = len(de_mcmc), \n",
    "            step = t,\n",
    "        )\n",
    "        most_possible = np.argsort(the_last, axis = 1)\n",
    "        #print(most_possible[:,bcList[t]].shape)\n",
    "        most_possible = np.transpose(\n",
    "            most_possible[:,bcList[t]]).reshape(\n",
    "            num_data * reduce(lambda x,y: x*y, beam_list[:t+1])\n",
    "        )\n",
    "        en_mcmc = np.tile(en_mcmc, (to_expand, 1))\n",
    "        de_mcmc = np.tile(de_mcmc, (to_expand, 1))\n",
    "        y_mcmc = np.tile(y_mcmc, (to_expand, 1))\n",
    "        h_mcmc = np.tile(h_mcmc, (to_expand, 1))\n",
    "        c_mcmc = np.tile(c_mcmc, (to_expand, 1))\n",
    "        y_mcmc[:,t+start_on] = most_possible\n",
    "        #print(en_mcmc.shape)\n",
    "        #print(de_mcmc.shape)\n",
    "        #print(y_mcmc.shape)\n",
    "        #print(h_mcmc.shape)\n",
    "        #print(c_mcmc.shape)\n",
    "        #print('---')\n",
    "        if t+1 < end_on - start_on:\n",
    "            de_mcmc[:,t+1] = most_possible\n",
    "    # Rank all synthetic sequences\n",
    "    r_mcmc = model_d.predict(y_mcmc)\n",
    "    r_out = np.reshape(np.array([\n",
    "        tf.reduce_mean(r_mcmc[np.arange(i, len(r_mcmc), num_data)], axis = 0) for i in range(num_data)\n",
    "    ]), (num_data, 1))\n",
    "    # Rank each tokens\n",
    "    return r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
<<<<<<< HEAD
   "id": "831d6913",
=======
   "id": "c4850a84",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7040231 ]\n",
      " [0.5734247 ]\n",
      " [0.29461342]\n",
      " [0.5256838 ]]\n"
     ]
    }
   ],
   "source": [
    "#print(decoder_train[:4])\n",
    "#print(teacher_train[:4])\n",
    "r_tmp = regs_mcmc(\n",
    "    mleGmcmc,\n",
    "    seqgan_d, \n",
    "    encoder_train[:4],\n",
    "    teacher_train[:4],\n",
    "    np.ones((4,32)), # h state\n",
    "    np.ones((4,32)), # c state\n",
    "    start_on = 5,\n",
    "    end_on = 10,\n",
    "    beam = 2,\n",
    ")\n",
    "print(r_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "363530b9",
=======
   "id": "c8f6f0f3",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "## REGS main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
<<<<<<< HEAD
   "id": "d14d68f3",
=======
   "id": "62d56781",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regs for one context\n",
    "def regs(model_g, model_d, enData, beam = 2):\n",
    "    st = float(time.time())\n",
    "    r_out = np.zeros((enData.shape[0], decoder_que_pad, 1))\n",
    "    y_out, de_in = inference(model_g, enData)\n",
    "    model_g_mcmc = getLMmcmc()\n",
    "    model_g_mcmc.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "    y_out = np.array(y_out, dtype = int)\n",
    "    de_in = np.array(de_in, dtype = int)\n",
    "    h_in = np.ones((enData.shape[0], decoder_que_pad, decoder_wv_dim))\n",
    "    c_in = np.ones((enData.shape[0], decoder_que_pad, decoder_wv_dim))\n",
    "    for q in range(0, decoder_que_pad):\n",
    "        # The roll-out length is 10\n",
    "        q10 = q + 10\n",
    "        if q+10 >= decoder_que_pad:\n",
    "            q10 = decoder_que_pad -1\n",
    "        r_tmp = regs_mcmc(\n",
    "            model_g_mcmc,\n",
    "            model_d,\n",
    "            enData,\n",
    "            y_out,\n",
    "            h_in[:,q],\n",
    "            c_in[:,q],\n",
    "            start_on = q, # Fix first q words and see the reward.\n",
    "            end_on = q10,\n",
    "            beam = beam,\n",
    "        )\n",
    "        r_out[:, q] = r_tmp[:]\n",
    "        print('{1} takes {0:.3f} sec.'.format(float(time.time()) - st,q))\n",
    "    # Variance reducing\n",
    "    r_mean = np.mean(r_out, axis = 0)\n",
    "    r_out = r_out - r_mean\n",
    "    r_out = np.array(r_out, dtype = np.float32)\n",
    "    return de_in, y_out, r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
<<<<<<< HEAD
   "id": "ee25b0c6",
=======
   "id": "77feedbe",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 takes 14.442 sec.\n",
      "1 takes 15.302 sec.\n",
      "2 takes 16.034 sec.\n",
      "3 takes 16.732 sec.\n",
      "4 takes 17.349 sec.\n",
      "5 takes 18.072 sec.\n",
      "6 takes 18.829 sec.\n",
      "7 takes 19.583 sec.\n",
      "8 takes 20.422 sec.\n",
      "9 takes 21.193 sec.\n",
      "10 takes 22.027 sec.\n",
      "11 takes 22.881 sec.\n",
      "12 takes 23.658 sec.\n",
      "13 takes 24.487 sec.\n",
      "14 takes 25.177 sec.\n",
      "15 takes 25.987 sec.\n",
      "16 takes 26.725 sec.\n",
      "17 takes 27.515 sec.\n",
      "18 takes 28.368 sec.\n",
      "19 takes 29.030 sec.\n",
      "20 takes 29.732 sec.\n",
      "21 takes 30.502 sec.\n",
      "22 takes 31.222 sec.\n",
      "23 takes 32.052 sec.\n",
      "24 takes 32.886 sec.\n",
      "25 takes 33.641 sec.\n",
      "26 takes 34.291 sec.\n",
      "27 takes 35.002 sec.\n",
      "28 takes 35.699 sec.\n",
      "29 takes 36.460 sec.\n",
      "30 takes 37.111 sec.\n",
      "31 takes 37.836 sec.\n",
      "32 takes 38.549 sec.\n",
      "33 takes 39.301 sec.\n",
      "34 takes 40.040 sec.\n",
      "35 takes 40.689 sec.\n",
      "36 takes 41.440 sec.\n",
      "37 takes 42.151 sec.\n",
      "38 takes 42.830 sec.\n",
      "39 takes 43.582 sec.\n",
      "40 takes 44.350 sec.\n",
      "41 takes 45.072 sec.\n",
      "42 takes 45.843 sec.\n",
      "43 takes 46.642 sec.\n",
      "44 takes 47.345 sec.\n",
      "45 takes 48.080 sec.\n",
      "46 takes 48.950 sec.\n",
      "47 takes 49.673 sec.\n",
      "48 takes 50.493 sec.\n",
      "49 takes 51.252 sec.\n",
      "50 takes 51.997 sec.\n",
      "51 takes 52.679 sec.\n",
      "52 takes 53.419 sec.\n",
      "53 takes 54.102 sec.\n",
      "54 takes 54.895 sec.\n",
      "55 takes 55.727 sec.\n",
      "56 takes 56.520 sec.\n",
      "57 takes 57.324 sec.\n",
      "58 takes 58.201 sec.\n",
      "59 takes 58.845 sec.\n",
      "60 takes 59.556 sec.\n",
      "61 takes 60.197 sec.\n",
      "62 takes 60.936 sec.\n",
      "63 takes 61.760 sec.\n",
      "64 takes 62.521 sec.\n",
      "65 takes 63.286 sec.\n",
      "66 takes 64.123 sec.\n",
      "67 takes 64.838 sec.\n",
      "68 takes 65.481 sec.\n",
      "69 takes 66.213 sec.\n",
      "70 takes 67.010 sec.\n",
      "71 takes 67.727 sec.\n",
      "72 takes 68.498 sec.\n",
      "73 takes 69.370 sec.\n",
      "74 takes 70.142 sec.\n",
      "75 takes 70.761 sec.\n",
      "76 takes 71.558 sec.\n",
      "77 takes 72.403 sec.\n",
      "78 takes 73.054 sec.\n",
      "79 takes 73.882 sec.\n",
      "80 takes 74.680 sec.\n",
      "81 takes 75.548 sec.\n",
      "82 takes 76.289 sec.\n",
      "83 takes 76.937 sec.\n",
      "84 takes 77.716 sec.\n",
      "85 takes 78.450 sec.\n",
      "86 takes 79.180 sec.\n",
      "87 takes 79.883 sec.\n",
      "88 takes 80.675 sec.\n",
      "89 takes 81.523 sec.\n",
      "90 takes 82.309 sec.\n",
      "91 takes 82.945 sec.\n",
      "92 takes 83.727 sec.\n",
      "93 takes 84.468 sec.\n",
      "94 takes 85.249 sec.\n",
      "95 takes 85.939 sec.\n",
      "96 takes 86.724 sec.\n",
      "97 takes 87.446 sec.\n",
      "98 takes 88.164 sec.\n",
      "99 takes 88.887 sec.\n",
      "100 takes 89.568 sec.\n",
      "101 takes 90.297 sec.\n",
      "102 takes 91.075 sec.\n",
      "103 takes 91.933 sec.\n",
      "104 takes 92.645 sec.\n",
      "105 takes 93.465 sec.\n",
      "106 takes 94.192 sec.\n",
      "107 takes 95.007 sec.\n",
      "108 takes 95.791 sec.\n",
      "109 takes 96.558 sec.\n",
      "110 takes 97.319 sec.\n",
      "111 takes 98.147 sec.\n",
      "112 takes 99.020 sec.\n",
      "113 takes 99.880 sec.\n",
      "114 takes 100.592 sec.\n",
      "115 takes 101.464 sec.\n",
      "116 takes 102.167 sec.\n",
      "117 takes 102.871 sec.\n",
      "118 takes 103.672 sec.\n",
      "119 takes 104.374 sec.\n",
      "120 takes 105.120 sec.\n",
      "121 takes 105.950 sec.\n",
      "122 takes 106.677 sec.\n",
      "123 takes 107.361 sec.\n",
      "124 takes 108.075 sec.\n",
      "125 takes 108.763 sec.\n",
      "126 takes 109.582 sec.\n",
      "127 takes 110.360 sec.\n",
      "128 takes 111.116 sec.\n",
      "129 takes 111.889 sec.\n",
      "130 takes 112.629 sec.\n",
      "131 takes 113.416 sec.\n",
      "132 takes 114.257 sec.\n",
      "133 takes 115.034 sec.\n",
      "134 takes 115.810 sec.\n",
      "135 takes 116.619 sec.\n",
      "136 takes 117.336 sec.\n",
      "137 takes 118.011 sec.\n",
      "138 takes 118.800 sec.\n",
      "139 takes 119.471 sec.\n",
      "140 takes 120.162 sec.\n",
      "141 takes 120.972 sec.\n",
      "142 takes 121.711 sec.\n",
      "143 takes 122.508 sec.\n",
      "144 takes 123.138 sec.\n",
      "145 takes 123.913 sec.\n",
      "146 takes 124.682 sec.\n",
      "147 takes 125.500 sec.\n",
      "148 takes 126.158 sec.\n",
      "149 takes 126.946 sec.\n",
      "150 takes 127.709 sec.\n",
      "151 takes 128.467 sec.\n",
      "152 takes 129.311 sec.\n",
      "153 takes 130.124 sec.\n",
      "154 takes 130.935 sec.\n",
      "155 takes 131.641 sec.\n",
      "156 takes 132.286 sec.\n",
      "157 takes 133.000 sec.\n",
      "158 takes 133.820 sec.\n",
      "159 takes 134.622 sec.\n",
      "160 takes 135.395 sec.\n",
      "161 takes 136.120 sec.\n",
      "162 takes 136.988 sec.\n",
      "163 takes 137.814 sec.\n",
      "164 takes 138.558 sec.\n",
      "165 takes 139.378 sec.\n",
      "166 takes 140.248 sec.\n",
      "167 takes 141.064 sec.\n",
      "168 takes 141.724 sec.\n",
      "169 takes 142.456 sec.\n",
      "170 takes 143.287 sec.\n",
      "171 takes 143.954 sec.\n",
      "172 takes 144.599 sec.\n",
      "173 takes 145.384 sec.\n",
      "174 takes 146.020 sec.\n",
      "175 takes 146.844 sec.\n",
      "176 takes 147.503 sec.\n",
      "177 takes 148.347 sec.\n",
      "178 takes 149.030 sec.\n",
      "179 takes 149.735 sec.\n",
      "180 takes 150.352 sec.\n",
      "181 takes 151.067 sec.\n",
      "182 takes 151.933 sec.\n",
      "183 takes 152.802 sec.\n",
      "184 takes 153.568 sec.\n",
      "185 takes 154.386 sec.\n",
      "186 takes 155.188 sec.\n",
      "187 takes 155.919 sec.\n",
      "188 takes 156.503 sec.\n",
      "189 takes 157.346 sec.\n",
      "190 takes 158.163 sec.\n",
      "191 takes 158.860 sec.\n",
      "192 takes 159.683 sec.\n",
      "193 takes 160.464 sec.\n",
      "194 takes 161.267 sec.\n",
      "195 takes 162.150 sec.\n",
      "196 takes 162.970 sec.\n",
      "197 takes 163.439 sec.\n",
      "198 takes 163.709 sec.\n",
      "199 takes 163.916 sec.\n",
      "200 takes 164.059 sec.\n",
      "201 takes 164.174 sec.\n",
      "202 takes 164.268 sec.\n",
      "203 takes 164.343 sec.\n",
      "204 takes 164.406 sec.\n",
      "205 takes 164.457 sec.\n",
      "206 takes 164.485 sec.\n",
      "int64\n",
      "int64\n",
      "float32\n",
      "(4, 207, 1)\n"
     ]
    }
   ],
   "source": [
    "#st = float(time.time())\n",
    "de_in, y_out, r_out = regs(\n",
    "    seqgan_g, \n",
    "    seqgan_d, \n",
    "    enData = encoder_train[:4],\n",
    "    beam = 2,\n",
    ")\n",
    "print(de_in.dtype)\n",
    "print(y_out.dtype)\n",
    "#print(r_out)\n",
    "print(r_out.dtype)\n",
    "print(r_out.shape)\n",
    "#print('It takes {0:.3f} sec.'.format(float(time.time()) - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
<<<<<<< HEAD
   "id": "793814ff",
=======
   "id": "9f9c22ee",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "mleD.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
<<<<<<< HEAD
   "id": "928ab0fc",
=======
   "id": "00b490da",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "seqgan_g.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "seqgan_d.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
<<<<<<< HEAD
   "id": "7e9b64b7",
=======
   "id": "c8e49abc",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 11s 14ms/step - loss: 0.5332 - accuracy: 0.8420\n",
      "0.5332431793212891\n",
      "768/768 [==============================] - 10s 13ms/step - loss: 0.5332 - sparse_categorical_crossentropy: 0.5332\n",
      "0.5332431793212891\n"
     ]
    }
   ],
   "source": [
    "loss, _acc = mleG.evaluate([encoder_vali, decoder_vali], teacher_vali)\n",
    "print(loss)\n",
    "loss, _acc = seqgan_g.evaluate([encoder_vali, decoder_vali], teacher_vali) # Full-test-data NLL test\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "405fd7de",
=======
   "id": "5a19e18e",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
<<<<<<< HEAD
   "id": "19169069",
=======
   "id": "5edde35c",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "minibatch_size = 32\n",
    "epoch = 300\n",
    "g_best_loss = 999\n",
    "num_batch = int(len(teacher_train)//batch_size)\n",
    "report_iter = 5\n",
    "g_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "d8c0210f",
=======
   "id": "6672ac00",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "model saved.\n"
     ]
    }
   ],
   "source": [
    "train_g_loss = tf.keras.metrics.Mean()\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "sec = int(time.time())\n",
    "\n",
    "g_nll_list = []\n",
    "counter = 0\n",
    "p_time = time.time() # Estimate the time for 50 batches.\n",
    "for e in range(epoch):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_g_loss.reset_states()\n",
    "    train_d_loss.reset_states()\n",
    "    \n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(encoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(decoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(teacher_train)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(encoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(decoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(teacher_vali)\n",
    "    for i in range(num_batch):\n",
    "        print(f'Batch {counter+1}')\n",
    "        #----------------------------- \n",
    "        # Evaluate the loss on model G every 50 batches\n",
    "        if counter % report_iter == 0:\n",
    "            syn_vali = [] # syn for Synthesized Data\n",
    "            for j in range(0, 1024, 128): # Define Test data size\n",
    "                t = seqgan_g.predict(\n",
    "                    [encoder_vali[j:j+128], decoder_vali[j:j+128]], \n",
    "                    batch_size = 128\n",
    "                )\n",
    "                syn_vali.append(t)\n",
    "            syn_vali = np.vstack(syn_vali)\n",
    "            g_vali_loss = loss_object(teacher_vali[:1024], syn_vali)\n",
    "            # Evaluate the loss on model D\n",
    "            syn_vali = np.argmax(syn_vali, axis = -1)\n",
    "            r_vali_fake = seqgan_d(np.vstack([teacher_vali[:1024], syn_vali]))\n",
    "            d_vali_loss = loss_d(\n",
    "                np.vstack([\n",
    "                    np.ones((1024, 1)), \n",
    "                    np.zeros((1024, 1))]),\n",
    "                r_vali_fake,\n",
    "            )\n",
    "            g_nll_list.append(g_vali_loss)\n",
    "            # Save the model G if it is better\n",
    "            if g_vali_loss < g_best_loss:\n",
    "                g_best_loss = g_vali_loss\n",
    "                ckpt_save_path = ckpt_g_manager.save()\n",
    "                ckpt_save_path = ckpt_d_manager.save()\n",
    "                print('model saved.')\n",
    "        #----------------------------- \n",
    "        # Data preparation\n",
    "        # Real part\n",
    "        e_real_batch = encoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        x_real_batch = decoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        y_real_batch = teacher_train[i*batch_size:(i+1)*batch_size]\n",
    "        r_real_batch  = np.ones((batch_size, 1))\n",
    "        # Synthesized part\n",
    "        y_fake_batch, x_fake_batch = inference(\n",
    "            seqgan_g, \n",
    "            e_real_batch,\n",
    "        )\n",
    "        r_fake_batch = np.zeros((batch_size, 1))\n",
    "        # Real + fake and then training\n",
    "        x_batch = np.vstack((x_real_batch, x_fake_batch))\n",
    "        y_batch = np.vstack((y_real_batch, y_fake_batch))\n",
    "        r_batch = np.vstack((r_real_batch, r_fake_batch))\n",
    "        #----------------------------- \n",
    "        # Train D with minibatch approaches.\n",
    "        for j in range(0, batch_size, minibatch_size):\n",
    "            y_minibatch = y_batch[j:j+minibatch_size]\n",
    "            r_minibatch = r_batch[j:j+minibatch_size]\n",
    "            _, d_loss = train_d_step(\n",
    "                y_minibatch, \n",
    "                r_minibatch,\n",
    "            )\n",
    "            train_d_loss.update_state(d_loss)\n",
    "        #----------------------------- \n",
    "        # Update Generator after certain batches\n",
    "        if counter % g_iter == 0:\n",
    "            gST = time.time()\n",
    "            de_in_mcmc, y_out_mcmc, r_out_mcmc = regs(\n",
    "                seqgan_g, \n",
    "                seqgan_d, \n",
    "                enData = e_real_batch,\n",
    "                beam = 2,\n",
    "            )\n",
    "            # Train G\n",
    "            gstep = minibatch_size\n",
    "            for k in range(0, len(de_in_mcmc), gstep):\n",
    "                # Update model\n",
    "                g_loss = train_g_step(\n",
    "                    e_real_batch[k:k+gstep],\n",
    "                    de_in_mcmc[k:k+gstep],\n",
    "                    y_out_mcmc[k:k+gstep],\n",
    "                    r_out_mcmc[k:k+gstep],\n",
    "                )\n",
    "            train_g_loss.update_state(g_loss)\n",
    "            # Teacher forcing\n",
    "            g_loss = seqgan_g.train_on_batch([e_real_batch, x_real_batch], y_real_batch)\n",
    "            train_g_loss.update_state(g_loss)\n",
    "        #-----------------------------\n",
    "        # 50 batches in time\n",
    "        if counter % report_iter == 0:\n",
    "            elapsed_time = time.time() - p_time\n",
    "            p_time = time.time()\n",
    "            print(\n",
    "                f'Batch: {counter+1}, '\n",
    "                f'AdvG loss: {train_g_loss.result():.4f}, '\n",
    "                f'D loss: {train_d_loss.result():.4f}, '\n",
    "                f'G NLL: {g_vali_loss:.4f}, '\n",
    "                f'D NLL: {d_vali_loss:.4f}, '\n",
    "                f'elapsed time: {elapsed_time:.0f} secs'\n",
    "            )\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "0995986c",
=======
   "id": "f3454e3a",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e_real_batch.shape)\n",
    "print(de_in_mcmc.shape)\n",
    "print(y_out_mcmc.shape)\n",
    "print(r_out_mcmc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
<<<<<<< HEAD
   "id": "3f4c0224",
=======
   "id": "5964b96b",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 207, 199)\n",
      "(4, 207, 1)\n",
      "(4, 207)\n",
      "tf.Tensor(4657.9746, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = seqgan_g((encoder_vali[:4], decoder_vali[:4]))\n",
    "print(pred.shape)\n",
    "\n",
    "reward = np.ones((pred.shape[0], pred.shape[1], 1))\n",
    "print(reward.shape)\n",
    "\n",
    "loss = loss_object2(teacher_vali[:4], pred)\n",
    "print(loss.shape)\n",
    "\n",
    "loss = policy_loss_function(teacher_vali[:4], pred, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "522b26ce",
=======
   "id": "8100da8d",
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.6"
=======
   "version": "3.9.9"
>>>>>>> d2fb8806c6748d9057d3438a4117a29299025202
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
