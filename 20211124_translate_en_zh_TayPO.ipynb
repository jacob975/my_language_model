{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0792cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "# If you have more than 1 GPU, you might want to specify which GPU for training.\n",
    "# In this case, I have 2 GPU and the second one is RTX 2080ti, so I pick the `second` one.\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' # The second\n",
    "tf.config.set_soft_device_placement(True)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b4e11",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820f5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = '20211116_wmt19_en_zh'\n",
    "g_name = '20211122_translate_mle_en_zh_lstm'\n",
    "folder_name = '20211124_translate_mle_en_zh_TayPO'\n",
    "\n",
    "encoder_wv_dim = 32\n",
    "decoder_wv_dim = 32\n",
    "encoder_que_pad = 65\n",
    "decoder_que_pad = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f764a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca88e8",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5bafd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train = pickle.load(open(f'{d_name}/encoder_train.pkl', 'rb'))\n",
    "decoder_train = pickle.load(open(f'{d_name}/decoder_train.pkl', 'rb'))\n",
    "teacher_train = pickle.load(open(f'{d_name}/teacher_train.pkl', 'rb'))\n",
    "encoder_vali  = pickle.load(open(f'{d_name}/encoder_vali.pkl', 'rb'))\n",
    "decoder_vali  = pickle.load(open(f'{d_name}/decoder_vali.pkl', 'rb'))\n",
    "teacher_vali  = pickle.load(open(f'{d_name}/teacher_vali.pkl', 'rb'))\n",
    "\n",
    "decoder_idx2word   = pickle.load(open(f'{d_name}/en_idx2word.pkl','rb'))\n",
    "decoder_word2idx   = pickle.load(open(f'{d_name}/en_word2idx.pkl','rb'))\n",
    "encoder_idx2word   = pickle.load(open(f'{d_name}/zh_idx2word.pkl','rb'))\n",
    "encoder_word2idx   = pickle.load(open(f'{d_name}/zh_word2idx.pkl','rb'))\n",
    "\n",
    "decoder_emb32    = pickle.load(open(f'{d_name}/en_emb32.pkl', 'rb'))\n",
    "encoder_emb32    = pickle.load(open(f'{d_name}/zh_emb32.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb09438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "4716\n"
     ]
    }
   ],
   "source": [
    "num_decoder_words = np.max([np.max(decoder_train), np.max(decoder_vali)])+1\n",
    "num_encoder_words = np.max([np.max(encoder_train), np.max(encoder_vali)])+1\n",
    "\n",
    "print(num_decoder_words)\n",
    "print(num_encoder_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f57aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2word(seq_tensor, idx2word):\n",
    "    return [''.join([idx2word[i] for i in seq]) for seq in seq_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb50bf29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>1929 or 1989?<eos>                                                                                                                                                                                                ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(decoder_vali[:1], decoder_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71eecd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年还是1989年?                                                    ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2word(encoder_vali[:1], encoder_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8fe8e",
   "metadata": {},
   "source": [
    "# Positional Encoding\n",
    "[Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167437f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1c713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n, d = 10, 64\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5f1a2e",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc4bb8",
   "metadata": {},
   "source": [
    "[Multi-Head Attention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) \n",
    "and [Positional Encoding](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "based on [Vaswani+17, Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158a73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_mask(n_gram, que_pad): # For backward sequence #中間那段的mask\n",
    "    mask_upper = np.tri(que_pad, que_pad, -1+n_gram)\n",
    "    mask_lower = np.tri(que_pad, que_pad, -1)\n",
    "    mask = mask_upper - mask_lower\n",
    "    return mask\n",
    "\n",
    "def Transformer(q_que_pad, k_que_pad, wv_dim, k_wv_dim, rate = 0.1, mask = ''):\n",
    "    # Inputs\n",
    "    mem  = Input((q_que_pad, wv_dim))\n",
    "    encode = Input((k_que_pad, k_wv_dim))\n",
    "    # Constants\n",
    "    ff_dim = wv_dim*64\n",
    "    # Multi-Head Attention\n",
    "    q = Dense(wv_dim)(mem)\n",
    "    k = Dense(wv_dim)(encode)\n",
    "    v = Dense(wv_dim)(encode)\n",
    "    # Choose a mask, default: BERT (no mask)\n",
    "    mask_weights = np.ones((q_que_pad, k_que_pad))\n",
    "    if mask == 'GPT':\n",
    "        mask_weights = np.tri(q_que_pad, k_que_pad, 0)\n",
    "    elif mask == 'band':\n",
    "        mask_weights = band_mask(10, q_que_pad)\n",
    "        print(mask_weights)\n",
    "    mem_new = MultiHeadAttention(\n",
    "        num_heads = 4,\n",
    "        key_dim = wv_dim, \n",
    "        value_dim = wv_dim\n",
    "    )(\n",
    "        q, k, v,\n",
    "        attention_mask = mask_weights,\n",
    "    )\n",
    "    mem_new = Dropout(rate)(mem_new)\n",
    "    mem_new = LayerNormalization(epsilon=1e-6)(mem_new+mem)\n",
    "    # Feed-Forward skip-connection\n",
    "    ffn = Dense(ff_dim, activation = 'relu')(mem_new)\n",
    "    ffn = Dense(wv_dim)(ffn)\n",
    "    ffn = Dropout(rate)(ffn)\n",
    "    out = LayerNormalization(epsilon=1e-6)(ffn+mem_new)\n",
    "    model = Model(\n",
    "        [mem, encode],\n",
    "        [mem_new, out],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def getE(wv_dim = 16):\n",
    "    _input = Input((encoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_encoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(encoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(encoder_emb32),\n",
    "    )\n",
    "    mem = emb(_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(encoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # forward sentence\n",
    "    for i in range(1):\n",
    "        #gptLayer = Transformer(encoder_que_pad, encoder_que_pad, wv_dim, wv_dim)\n",
    "        #mem, output = gptLayer((mem, mem))\n",
    "        #output = Activation('relu')(output)\n",
    "        #mem = Activation('relu')(mem)\n",
    "        lstmLayer = LSTM(32, return_sequences=True)\n",
    "        mem = lstmLayer(mem)\n",
    "    # Output\n",
    "    output = mem\n",
    "    model = Model(\n",
    "        _input, \n",
    "        output) \n",
    "    return model\n",
    "\n",
    "def getD(wv_dim = 8, encoder_wv_dim = 16):\n",
    "    en_output = Input((encoder_que_pad, encoder_wv_dim))\n",
    "    de_input  = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim, \n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    mem = emb(de_input)\n",
    "    # position encoding\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    mem = LayerNormalization(epsilon=1e-6)(mem+pe)\n",
    "    # Attention\n",
    "    for j in range(1):\n",
    "        # Self attention\n",
    "        for i in range(1):\n",
    "            #gptLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim, mask = 'GPT')\n",
    "            #mem, _ = gptLayer((mem, mem))\n",
    "            #mem = Activation('relu')(mem)\n",
    "            lstmLayer = LSTM(32, return_sequences=True)\n",
    "            mem = lstmLayer(mem)\n",
    "        # Cross attention\n",
    "        for i in range(1):\n",
    "            gptLayer = Transformer(decoder_que_pad, encoder_que_pad, wv_dim, encoder_wv_dim)\n",
    "            mem, output = gptLayer((mem, en_output))\n",
    "            output = Activation('relu')(output)\n",
    "            mem = Activation('relu')(mem)\n",
    "    # Concatenation and output\n",
    "    output = Dense(num_decoder_words)(output)\n",
    "    output = Activation('softmax')(output)\n",
    "    model = Model(\n",
    "        [en_output, de_input], \n",
    "        output,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Language Model\n",
    "def getLM():\n",
    "    # Inputs\n",
    "    en_input = Input((encoder_que_pad,))\n",
    "    de_input = Input((decoder_que_pad,))\n",
    "    # Encoder (Czech -> code)\n",
    "    encoder = getE(encoder_wv_dim)\n",
    "    en_output = encoder(en_input)\n",
    "    # Decoder (code -> English)\n",
    "    decoder = getD(decoder_wv_dim, encoder_wv_dim)\n",
    "    de_output = decoder([en_output, de_input])\n",
    "    # Establish the model\n",
    "    model = Model(\n",
    "        [en_input, de_input],\n",
    "        de_output,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2721bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 65, 32)       159296      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 207, 199)     174567      model[0][0]                      \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleG = getLM()\n",
    "mleG.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "mleG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19eca363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 8s 7ms/step - loss: 0.5332 - accuracy: 0.8420\n",
      "0.5332431793212891\n"
     ]
    }
   ],
   "source": [
    "mleG.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "loss, _acc = mleG.evaluate(\n",
    "    [encoder_vali, decoder_vali], \n",
    "    teacher_vali\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0c30b",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49cb8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model,\n",
    "    enData,\n",
    "    inpData = None,\n",
    "    start_on = 0,\n",
    "    end_on = decoder_que_pad,\n",
    "    batch_size = 1024,\n",
    "):\n",
    "    # Initialize\n",
    "    num_data = len(enData)\n",
    "    num_batch = (num_data-1)//batch_size +1\n",
    "    resp_pred_list = None\n",
    "    in_batch_list = None\n",
    "    the_first = True\n",
    "    for b in range(num_batch):\n",
    "        en_batch = np.zeros((batch_size, encoder_que_pad), dtype = int)\n",
    "        if b == num_batch -1:\n",
    "            en_batch[:num_data - (num_batch-1) * batch_size] = enData[b*batch_size:(b+1)*batch_size]\n",
    "        else:\n",
    "            en_batch = enData[b*batch_size:(b+1)*batch_size]\n",
    "        in_batch = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        if start_on == 0:\n",
    "            in_batch[:,0] = decoder_word2idx['<bos>']\n",
    "        elif b == num_batch -1:\n",
    "            in_batch[:num_data - (num_batch-1) * batch_size] = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        else: \n",
    "            in_batch = inpData[b*batch_size:(b+1)*batch_size]\n",
    "        resp_pred = np.zeros((batch_size, decoder_que_pad), dtype = int)\n",
    "        # Generate the sequence recurrsively.\n",
    "        for i in range(start_on, end_on):\n",
    "            # Run\n",
    "            resp_pred_wv = model([en_batch, in_batch])\n",
    "            the_last = resp_pred_wv[:,i]\n",
    "            the_last = tf.reshape(\n",
    "                tf.random.categorical(tf.math.log(the_last), 1), \n",
    "                [batch_size,]\n",
    "            )\n",
    "            try:\n",
    "                resp_pred[:,i] = the_last\n",
    "                in_batch[:,i+1] = the_last\n",
    "            except:\n",
    "                resp_pred[:,i] = the_last\n",
    "        for i in range(len(resp_pred)):\n",
    "            try:\n",
    "                index = list(resp_pred[i]).index(word2idx['<bos>'])\n",
    "            except:\n",
    "                continue\n",
    "            resp_pred[i,index+1:] = 0\n",
    "            in_batch[i,index+1:] = 0\n",
    "        if the_first:\n",
    "            resp_pred_list = resp_pred\n",
    "            in_batch_list = in_batch\n",
    "            the_first = False\n",
    "        else:\n",
    "            resp_pred_list = np.vstack((resp_pred_list, resp_pred))\n",
    "            in_batch_list = np.vstack((in_batch_list, in_batch))\n",
    "    resp_pred_list = resp_pred_list[:num_data]\n",
    "    in_batch_list = in_batch_list[:num_data]\n",
    "    if start_on != 0:\n",
    "        resp_pred_list[:,:start_on] = inpData[:,1:start_on+1]\n",
    "        in_batch_list[:, :start_on+1] = inpData[:,:start_on+1]\n",
    "    return resp_pred_list, in_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c5cefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predicted sequence\n",
      "['The 1989.<eos>                                                                                                                                                                                                     ', 'PARIS – On the economy is not look humans in the world, the world’s response likes than all wihak history have as we unexpected the link vigorously is an unevent.<eos>                                            ']\n",
      "# Real sequence\n",
      "['1929 or 1989?<eos>                                                                                                                                                                                                 ', 'PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.<eos>                                                       ']\n"
     ]
    }
   ],
   "source": [
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2])\n",
    "print('# Predicted sequence')\n",
    "print(seq2word(resp_pred_list, decoder_idx2word))\n",
    "print('# Real sequence')\n",
    "print(seq2word(teacher_vali[:2], decoder_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c69114de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 65)\n",
      "(2, 207)\n",
      "[[ 63  77 113  77   0  76 189 182 102  71  46 151 198   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 183   0  16 158 187  71 166   0  65 158 145 159\n",
      "    0  46 102 182 189  71 152 102   9 158  46 158  46   0 149 139   0 182\n",
      "   46  46  71  10  13 189  31   0  46 159 182   9  71   0  13 182   9   9\n",
      "  158  71   9  46 133   0 158 166   0   9  71 102 149 166 102 158 189 158\n",
      "  182 145 158 149 166 152  46  71  71  85 158 166 153   0 182   0  10 182\n",
      "  166 166  71   9   0 182 166 107   0 158 166   0  46  71  71  85 158 166\n",
      "  153   0  65 159 158 189  71   0  65 149 125 189 107   0  46 145 182 145\n",
      "   71   0  65 159  71 166   0  46 149  10  71   0 149 139   0 145 159  71\n",
      "    0 149  76  76 149  46 158 145  71   0 149 166   0 145 159  71   0  76\n",
      "    9  71  46 158 107  71 166 145 158 182 189   0 182 102 125 145  71   0\n",
      "  145 149   0  65 182  85  71   0 149 125 145  46  37   0  76 182 102  85\n",
      "  182 153  71   5 198   0   0   0   0]]\n",
      "[[ 63  77 113  77   0 149   9   0  63  77 170  77 151 198   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]\n",
      " [ 64  68  82 173 163   0 183   0  68  46   0 145 159  71   0  71 102 149\n",
      "  166 149  10 158 102   0 102   9 158  46 158  46   0 107  71  71  76  71\n",
      "  166  46   0 182 166 107   0  65 158 107  71 166  46 133   0 145 159  71\n",
      "    0  65 149   9 189 107   0 159 182  46   0  13  71  71 166   0  46  71\n",
      "  182   9 102 159 158 166 153   0 139 149   9   0 159 158  46 145 149   9\n",
      "  158 102 182 189   0 182 166 182 189 149 153 158  71  46   0 145 149   0\n",
      "  159  71 189  76   0 125  46   0 125 166 107  71   9  46 145 182 166 107\n",
      "    0  65 159 182 145   0 159 182  46   0  13  71  71 166   0 159 182  76\n",
      "   76  71 166 158 166 153   5 198   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_vali[:2].shape)\n",
    "print(decoder_vali[:2].shape)\n",
    "resp_pred_list, _ = inference(mleG, encoder_vali[:2], decoder_vali[:2], start_on =5)\n",
    "print(resp_pred_list)\n",
    "print(teacher_vali[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db166c",
   "metadata": {},
   "source": [
    "# Pre-Train Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbb9ad",
   "metadata": {},
   "source": [
    "##  Pre-training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d79ca10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20480, 207)\n",
      "(20480, 1)\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_train[:10240], \n",
    "    batch_size = 1024,\n",
    ")\n",
    "\n",
    "teacher_pre_train_d = np.vstack([teacher_train[:10240], teacher_pred])\n",
    "print(teacher_pre_train_d.shape)\n",
    "\n",
    "reward_train = np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_train_d = np.vstack([reward_train, reward_pred])\n",
    "print(reward_pre_train_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c39594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_train_d[-1])\n",
    "#print(reward_pre_train_d[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de28cd",
   "metadata": {},
   "source": [
    "## Pre-validating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62ffd1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 207)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "teacher_pred, decoder_pred = inference(\n",
    "    mleG, \n",
    "    encoder_vali[:1024],\n",
    "    batch_size = 512\n",
    ")\n",
    "teacher_pre_vali_d = np.vstack([teacher_vali[:1024], teacher_pred])\n",
    "print(teacher_pre_vali_d.shape)\n",
    "\n",
    "reward_vali =  np.ones((teacher_pred.shape[0], 1)) # 1 for True\n",
    "reward_pred = np.zeros((teacher_pred.shape[0], 1)) # 0 for False\n",
    "reward_pre_vali_d = np.vstack([reward_vali, reward_pred])\n",
    "print(reward_pre_vali_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9415715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(teacher_pre_vali_d[0])\n",
    "#print(reward_pre_vali_d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15699f0f",
   "metadata": {},
   "source": [
    "## Save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c319afbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teacher_pre_train_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-68382a0ce55d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_pre_train_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{folder_name}/teacher_pre_train_d.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_pre_train_d\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{folder_name}/reward_pre_train_d.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_pre_vali_d\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{folder_name}/teacher_pre_vali_d.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_pre_vali_d\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{folder_name}/reward_pre_vali_d.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'teacher_pre_train_d' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(teacher_pre_train_d, open(f'{folder_name}/teacher_pre_train_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_train_d,  open(f'{folder_name}/reward_pre_train_d.pkl','wb'))\n",
    "pickle.dump(teacher_pre_vali_d,  open(f'{folder_name}/teacher_pre_vali_d.pkl','wb'))\n",
    "pickle.dump(reward_pre_vali_d,   open(f'{folder_name}/reward_pre_vali_d.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b20e5",
   "metadata": {},
   "source": [
    "## Load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af76564",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pre_train_d = pickle.load(open(f'{folder_name}/teacher_pre_train_d.pkl','rb'))\n",
    "reward_pre_train_d  = pickle.load(open(f'{folder_name}/reward_pre_train_d.pkl','rb'))\n",
    "teacher_pre_vali_d  = pickle.load(open(f'{folder_name}/teacher_pre_vali_d.pkl','rb'))\n",
    "reward_pre_vali_d   = pickle.load(open(f'{folder_name}/reward_pre_vali_d.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c747b1",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4def21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getC(wv_dim): # Critic/Discriminator\n",
    "    resp = Input((decoder_que_pad,))\n",
    "    emb = Embedding(\n",
    "        num_decoder_words, \n",
    "        wv_dim,\n",
    "        mask_zero = False,\n",
    "        input_length=(int(decoder_que_pad)),\n",
    "        trainable = True,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(decoder_emb32),\n",
    "    )\n",
    "    resp_emb = emb(resp)\n",
    "    pe = positional_encoding(decoder_que_pad, wv_dim)\n",
    "    resp_emb = LayerNormalization(epsilon=1e-6)(resp_emb+pe)\n",
    "    bertLayer = Transformer(decoder_que_pad, decoder_que_pad, wv_dim, wv_dim)\n",
    "    _, out = bertLayer((resp_emb, resp_emb))\n",
    "    out, *_ = tf.split(out, decoder_que_pad, axis = 1)\n",
    "    #lstmLayer = LSTM(32)\n",
    "    #out = lstmLayer(resp_emb)\n",
    "    reward = Dense(1, activation = 'sigmoid')(out)\n",
    "    reward = Flatten()(reward)\n",
    "    model = Model(\n",
    "        resp,\n",
    "        reward\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34512613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 207, 32)      6368        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 207, 32)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 207, 32)      64          tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Functional)            [(None, 207, 32), (N 153248      layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.split (TFOpLambda)           [(None, 1, 32), (Non 0           model_4[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 1)         33          tf.split[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mleD=getC(decoder_wv_dim)\n",
    "mleD.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "mleD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "390e1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object_MleD = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_MleD = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab7f7649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_MleD(real, pred):\n",
    "    loss_ = loss_object_MleD(real, pred)\n",
    "    return loss_\n",
    "\n",
    "@tf.function()\n",
    "def trainMleD(te_in, y_real):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = mleD(te_in)\n",
    "        loss = loss_func_MleD(y_real, y_pred)\n",
    "    gradients = tape.gradient(loss, mleD.trainable_variables)    \n",
    "    optimizer_MleD.apply_gradients(zip(gradients, mleD.trainable_variables))\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12279e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved.\n",
      "Epoch 1, D loss: 0.0654, D NLL: 0.7686, elapsed time: 9 secs\n",
      "model saved.\n",
      "Epoch 2, D loss: 0.0645, D NLL: 0.7516, elapsed time: 9 secs\n",
      "model saved.\n",
      "Epoch 3, D loss: 0.0647, D NLL: 0.7013, elapsed time: 8 secs\n",
      "model saved.\n",
      "Epoch 4, D loss: 0.0643, D NLL: 0.6937, elapsed time: 8 secs\n",
      "Epoch 5, D loss: 0.0643, D NLL: 0.7224, elapsed time: 8 secs\n",
      "model saved.\n",
      "Epoch 6, D loss: 0.0643, D NLL: 0.6934, elapsed time: 7 secs\n",
      "model saved.\n",
      "Epoch 7, D loss: 0.0642, D NLL: 0.6932, elapsed time: 7 secs\n",
      "Epoch 8, D loss: 0.0642, D NLL: 0.7112, elapsed time: 8 secs\n",
      "Epoch 9, D loss: 0.0643, D NLL: 0.6981, elapsed time: 7 secs\n",
      "Epoch 10, D loss: 0.0642, D NLL: 0.7005, elapsed time: 8 secs\n",
      "Epoch 11, D loss: 0.0642, D NLL: 0.6961, elapsed time: 8 secs\n",
      "Epoch 12, D loss: 0.0642, D NLL: 0.6950, elapsed time: 9 secs\n"
     ]
    }
   ],
   "source": [
    "epoch = 300\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "batch_size = 256\n",
    "num_data =  len(teacher_train)\n",
    "counter = 0\n",
    "d_best_loss = 999\n",
    "\n",
    "for e in range(epoch):\n",
    "    start = int(time.time())\n",
    "    train_d_loss.reset_states()\n",
    "    # Shuffle the data\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(teacher_pre_train_d)\n",
    "    np.random.seed(start)\n",
    "    np.random.shuffle(reward_pre_train_d)\n",
    "    # Training \n",
    "    for i in range(0, num_data, batch_size):\n",
    "        teacher_batch = teacher_pre_train_d[i:i+batch_size]\n",
    "        reward_batch  = reward_pre_train_d[i:i+batch_size]\n",
    "        _, d_loss = trainMleD(teacher_batch, reward_batch)\n",
    "        train_d_loss.update_state(d_loss)\n",
    "    # NLL test\n",
    "    reward_pre_vali_d_fake = mleD(teacher_pre_vali_d)\n",
    "    d_vali_loss = loss_func_MleD(\n",
    "        reward_pre_vali_d,\n",
    "        reward_pre_vali_d_fake,\n",
    "    )\n",
    "    if d_vali_loss < d_best_loss:\n",
    "        mleD.save(f'{folder_name}/mleD.h5')\n",
    "        print('model saved.')\n",
    "        d_best_loss = d_vali_loss\n",
    "        counter = 0\n",
    "    elif d_vali_loss > d_best_loss:\n",
    "        counter += 1\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\n",
    "        f'Epoch {e+1},'\n",
    "        f' D loss: {train_d_loss.result():.4f},'\n",
    "        f' D NLL: {d_vali_loss:.4f},'\n",
    "        f' elapsed time: {elapsed_time:.0f} secs'\n",
    "    )\n",
    "    # Quit condition\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98579a",
   "metadata": {},
   "source": [
    "# Load parameters onto SeqGAN models from MLE models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef37227e",
   "metadata": {},
   "source": [
    "## Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9649307",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b38a46",
   "metadata": {},
   "source": [
    "## $\\hat{A}$, Estimator of the advantage function at timestep t\n",
    "$\\hat{A}$ is a reward estimators who consider rewards of future following steps.<br>\n",
    "See more on [Schulman+17](https://arxiv.org/abs/1707.06347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26718d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator_a(en_in, de_in, y_out, model_g, model_g_old, r, gamma = 0.99, _lambda = 1):\n",
    "    # Calculate the probabilities to sample a_t from `model_g` and `model_g_old` based on previous statement.\n",
    "    pred = model_g([en_in, de_in])\n",
    "    pred_old = model_g_old([en_in, de_in])\n",
    "    y_out_onehot = tf.one_hot(y_out, depth = num_decoder_words)\n",
    "    policy = tf.reduce_sum(pred * y_out_onehot, axis = -1)\n",
    "    policy_old = tf.reduce_sum(pred_old * y_out_onehot, axis = -1)\n",
    "    # Compute the ratio of the two probabilites\n",
    "    ratio = tf.math.divide(policy, policy_old)\n",
    "    # Compute delta\n",
    "    r = tf.reshape(r, (r.shape[0], r.shape[1]))\n",
    "    r = tf.cast(r, dtype= tf.dtypes.float32)\n",
    "    r_tmp = tf.concat([r, tf.zeros((r.shape[0],1))], axis = 1)\n",
    "    r_shift = tf.roll(r_tmp, shift = -1, axis = -1)\n",
    "    delta = ratio +gamma*r_shift[:, :decoder_que_pad] - r\n",
    "    # Compute hat_a\n",
    "    gamma_lambda_list = [ (gamma*_lambda)**i for i in range(decoder_que_pad)]\n",
    "    hat_a = tf.convert_to_tensor([\n",
    "        [ \n",
    "            tf.reduce_sum(delta[j,i:]*gamma_lambda_list[:decoder_que_pad-i]) \n",
    "            for i in range(decoder_que_pad)\n",
    "        ] \n",
    "        for j in range(de_in.shape[0])\n",
    "    ])\n",
    "    return pred, pred_old, policy, policy_old, hat_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37321504",
   "metadata": {},
   "source": [
    "# Taylor Expansion Policy Optimization\n",
    "1. Taylar Expansion for function $\\hat{A}$ based on [Tang et al. 2020](https://arxiv.org/abs/2003.06259)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee137ae3",
   "metadata": {},
   "source": [
    "## Taylar Expansion of $\\hat{A}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb3a17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The general one\n",
    "# Take the second order for example\n",
    "def getRLObjective(policy, policy_old, hat_a, k=2):\n",
    "    ratio_1o = tf.math.divide(policy, policy_old) - 1\n",
    "    ratio_list = [] # Dim = (k, trials, time_steps)\n",
    "    for i in range(k):\n",
    "        if i == 0:\n",
    "            ratio_list.append(ratio_1o)\n",
    "        else:\n",
    "            ratio_tmp = tf.concat([ratio_1o, tf.zeros((policy.shape[0],1))], axis = -1)\n",
    "            ratio_tmp = tf.roll(ratio_tmp, shift = -1, axis = -1)\n",
    "            ratio_tmp = ratio_tmp[:,:decoder_que_pad]\n",
    "            ratio_list.append(ratio_tmp)\n",
    "    hat_a_o = tf.concat([hat_a, tf.zeros((policy.shape[0],k-1))], axis = -1) # Dim = (trials, time_steps)\n",
    "    hat_a_o = tf.roll(hat_a_o, shift = -(k-1), axis = -1)\n",
    "    hat_a_o = hat_a_o[:,:decoder_que_pad]\n",
    "    ans = tf.convert_to_tensor(\n",
    "        tf.reduce_prod(ratio_list, axis = 0) * hat_a_o\n",
    "    )\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755e268",
   "metadata": {},
   "source": [
    "## Test Taylar expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e98cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g = getLM()\n",
    "test_g_old = getLM()\n",
    "test_reward = np.reshape(np.random.uniform(0,1,2*decoder_que_pad), (2, decoder_que_pad,1))\n",
    "#print(test_reward.shape)\n",
    "# hat_a\n",
    "_, _, policy, policy_old, hat_a = estimator_a(\n",
    "    encoder_vali[:2], decoder_vali[:2], teacher_vali[:2], \n",
    "    test_g, test_g_old, test_reward\n",
    ")\n",
    "#print(policy)\n",
    "#print(policy_old)\n",
    "# Loss 2\n",
    "rl_objective_2o = getRLObjective(policy, policy_old, hat_a, k =2)\n",
    "#print(rl_objective_2o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8438f6f",
   "metadata": {},
   "source": [
    "## SeqGAN generator and discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4f0ab",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b38ab8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=tf.keras.losses.Reduction.NONE # NONE for not to sum up all loss.\n",
    "    #reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "    #reduction=tf.keras.losses.Reduction.SUM,\n",
    ")\n",
    "\n",
    "optimizer_g = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "def policy_loss_function(policy, policy_old, hat_a):\n",
    "    loss_1 = getRLObjective(policy, policy_old, hat_a, k = 1)\n",
    "    loss_2 = getRLObjective(policy, policy_old, hat_a, k = 2)\n",
    "    loss_ = loss_1 + loss_2\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8141133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_207 (InputLayer)          [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_118 (Functional)          (None, 65, 32)       159296      input_207[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_208 (InputLayer)          [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_120 (Functional)          (None, 207, 199)     174567      model_118[0][0]                  \n",
      "                                                                 input_208[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 333,863\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_g = getLM()\n",
    "seqgan_g.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['sparse_categorical_crossentropy'],\n",
    ")\n",
    "seqgan_g.trainable = True\n",
    "seqgan_g.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_g_step(en_in, de_in, real, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred, pred_old, policy, policy_old, hat_a = estimator_a(\n",
    "            en_in, de_in, real, \n",
    "            seqgan_g, seqgan_g_old, \n",
    "            rewards\n",
    "        )\n",
    "        loss = policy_loss_function(policy, policy_old, hat_a)\n",
    "        #pred = seqgan_g((en_in, de_in))\n",
    "        #loss = policy_loss_function(real, pred, rewards)\n",
    "    gradients = tape.gradient(loss, seqgan_g.trainable_variables)    \n",
    "    optimizer_g.apply_gradients(zip(gradients, seqgan_g.trainable_variables))    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5808f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_g = f\"{folder_name}/seqgan_g\"\n",
    "ckpt_g = tf.train.Checkpoint(model=seqgan_g,optimizer=optimizer_g)\n",
    "ckpt_g_manager = tf.train.:q(ckpt_g, checkpoint_path_g, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_g_manager.latest_checkpoint:\n",
    "    ckpt_g.restore(ckpt_g_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2629c6",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac703716",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer_d = tf.keras.optimizers.Adam(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca1f623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_123\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_214 (InputLayer)          [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, 207, 32)      6368        input_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_123 (TFOpL (None, 207, 32)      0           embedding_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_123 (LayerN (None, 207, 32)      64          tf.__operators__.add_123[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "model_122 (Functional)          [(None, 207, 32), (N 153248      layer_normalization_123[0][0]    \n",
      "                                                                 layer_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.split_1 (TFOpLambda)         [(None, 1, 32), (Non 0           model_122[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_191 (Dense)               (None, 1, 1)         33          tf.split_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           dense_191[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 159,713\n",
      "Trainable params: 159,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_d = getC(decoder_wv_dim)\n",
    "seqgan_d.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['binary_crossentropy'],\n",
    ")\n",
    "seqgan_d.trainable = True\n",
    "seqgan_d.summary()\n",
    "\n",
    "@tf.function()\n",
    "def train_d_step(resp, rewards):\n",
    "    pred = None\n",
    "    loss = None\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = seqgan_d(resp) \n",
    "        loss = loss_d(rewards, pred)\n",
    "    gradients = tape.gradient(loss, seqgan_d.trainable_variables)    \n",
    "    optimizer_d.apply_gradients(zip(gradients, seqgan_d.trainable_variables))\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc5ad8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_d = f\"{folder_name}/seqgan_d\"\n",
    "ckpt_d = tf.train.Checkpoint(model=seqgan_d,optimizer=optimizer_d)\n",
    "ckpt_d_manager = tf.train.CheckpointManager(ckpt_d, checkpoint_path_d, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "#if ckpt_d_manager.latest_checkpoint:\n",
    "#    ckpt_d.restore(ckpt_d_manager.latest_checkpoint)\n",
    "#    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb5537",
   "metadata": {},
   "source": [
    "## Model for old parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "961108be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_127\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_217 (InputLayer)          [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_124 (Functional)          (None, 65, 32)       159296      input_217[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_218 (InputLayer)          [(None, 207)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_126 (Functional)          (None, 207, 199)     174567      model_124[0][0]                  \n",
      "                                                                 input_218[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 333,863\n",
      "Trainable params: 0\n",
      "Non-trainable params: 333,863\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqgan_g_old = getLM()\n",
    "seqgan_g_old.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate = lr),\n",
    "    metrics=['sparse_categorical_crossentropy'],\n",
    ")\n",
    "seqgan_g_old.trainable = False\n",
    "seqgan_g_old.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038c378",
   "metadata": {},
   "source": [
    "# Reward for Every Generation Step (REGS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "164ec562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_g_predict_batch(model, _inp_list, batch_size, num_data, step, **kwargs):\n",
    "    is_first = 1\n",
    "    y_out = None\n",
    "    num_batch = num_data // batch_size +1\n",
    "    for i in range(0, num_batch*batch_size , batch_size):\n",
    "        y = model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs)[:,step]\n",
    "        if is_first:\n",
    "            is_first = 0\n",
    "            y_out = y\n",
    "        else:\n",
    "            y_out = np.vstack([y_out, y])\n",
    "    return y_out\n",
    "\n",
    "def model_predict_batch(model, _inp_list, batch_size, num_data, **kwargs):\n",
    "    y_out = tf.stack(\n",
    "        [ model([_inp[i:i+batch_size] for _inp in _inp_list], **kwargs) \n",
    "         for i in range(0, num_data, batch_size)]\n",
    "    )\n",
    "    return y_out\n",
    "\n",
    "# Under revision, not finished yet\n",
    "def regs_mcmc(\n",
    "    model_g, \n",
    "    model_d,\n",
    "    en_in, \n",
    "    y_inp = None, \n",
    "    start_on = 0, \n",
    "    end_on = 10, \n",
    "    beam = 2,\n",
    "):\n",
    "    # If start on the end of sequence, return.\n",
    "    if start_on == decoder_que_pad -1:\n",
    "        return model_d.predict(y_inp)\n",
    "    # Initialize\n",
    "    num_data = y_inp.shape[0]\n",
    "    en_mcmc = np.array(en_in[:], dtype = int)\n",
    "    y_mcmc = np.zeros((num_data, decoder_que_pad), dtype = int)\n",
    "    de_mcmc = np.zeros((num_data, decoder_que_pad), dtype = int)\n",
    "    r_out = None\n",
    "    de_mcmc[:,0] = decoder_word2idx['<bos>']\n",
    "    if not isinstance(y_inp, type(None)):\n",
    "        y_mcmc[:, :start_on+1] = y_inp[:, :start_on+1]\n",
    "        de_mcmc[:, 1:start_on+2] = y_inp[:, :start_on+1]\n",
    "\n",
    "    # It determines which word to pass down.\n",
    "    beam_list = np.ones(decoder_que_pad, dtype = int)*beam\n",
    "    beam_list[:start_on+1] = 1\n",
    "    beam_list[start_on] = num_data\n",
    "    # bcList stands for beam-candidate list\n",
    "    bcList = []\n",
    "    for i in range(decoder_que_pad):\n",
    "        if i < start_on+1:\n",
    "            bcList.append([])\n",
    "        elif i >= start_on+1:\n",
    "            bcList.append(list(range(num_decoder_words-beam_list[i], num_decoder_words)))\n",
    "        else:\n",
    "            print('Warning')\n",
    "    #print(bcList)\n",
    "    # Generate sequences using MCMC\n",
    "    for t in range(start_on+1, end_on+1):\n",
    "        to_expand = beam_list[t]\n",
    "        the_last = model_g_predict_batch(\n",
    "            model_g, \n",
    "            [en_mcmc, de_mcmc], \n",
    "            batch_size = 1536, \n",
    "            num_data = len(de_mcmc), \n",
    "            step = t,\n",
    "        )\n",
    "        most_possible = np.argsort(the_last, axis = 1)\n",
    "        most_possible = np.transpose(\n",
    "            most_possible[:,bcList[t]]).reshape(\n",
    "            reduce(lambda x,y: x*y, beam_list[:t+1])\n",
    "        )\n",
    "        en_mcmc = np.tile(en_mcmc, (to_expand, 1))\n",
    "        de_mcmc = np.tile(de_mcmc, (to_expand, 1))\n",
    "        y_mcmc = np.tile(y_mcmc, (to_expand, 1))\n",
    "        y_mcmc[:,t] = most_possible\n",
    "        #print(en_mcmc.shape)\n",
    "        #print(de_mcmc.shape)\n",
    "        #print(y_mcmc.shape)\n",
    "        #print('---')\n",
    "        if t+1 < decoder_que_pad:\n",
    "            de_mcmc[:,t+1] = most_possible\n",
    "    # Rank all synthetic sequences\n",
    "    r_mcmc = model_d.predict(y_mcmc)\n",
    "    r_out = np.reshape(np.array([\n",
    "        tf.reduce_mean(r_mcmc[np.arange(i, len(r_mcmc), num_data)], axis = 0) for i in range(num_data)\n",
    "    ]), (num_data, 1))\n",
    "    # Rank each tokens\n",
    "    return r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27da69d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52445996]\n",
      " [0.39813945]\n",
      " [0.33229116]\n",
      " [0.49827617]]\n"
     ]
    }
   ],
   "source": [
    "#print(decoder_train[:4])\n",
    "#print(teacher_train[:4])\n",
    "r_tmp = regs_mcmc(\n",
    "    seqgan_g, \n",
    "    seqgan_d, \n",
    "    encoder_train[:4],\n",
    "    teacher_train[:4], \n",
    "    start_on = 2,\n",
    "    end_on = 11,\n",
    "    beam = 2,\n",
    ")\n",
    "print(r_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc43da",
   "metadata": {},
   "source": [
    "## REGS main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2986dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regs for one context\n",
    "def regs(model_g, model_d, enData, beam = 2):\n",
    "    #st = float(time.time())\n",
    "    r_out = np.zeros((enData.shape[0], decoder_que_pad, 1))\n",
    "    y_out, de_in = inference(model_g, enData)\n",
    "    y_out = np.array(y_out, dtype = np.int32)\n",
    "    de_in = np.array(de_in, dtype = np.int32)\n",
    "    for q in range(0, decoder_que_pad):\n",
    "        # The roll-out length is 10\n",
    "        q10 = q + 10 - 1\n",
    "        if q+10 >= decoder_que_pad:\n",
    "            q10 = decoder_que_pad -1\n",
    "        r_tmp = regs_mcmc(\n",
    "            model_g,\n",
    "            model_d,\n",
    "            enData,\n",
    "            y_out,\n",
    "            start_on = q, # Fix first q words and see the reward.\n",
    "            end_on = q10,\n",
    "            beam = beam,\n",
    "        )\n",
    "        r_out[:, q] = r_tmp[:]\n",
    "        #print('{1} takes {0:.3f} sec.'.format(float(time.time()) - st, q))\n",
    "    # Variance reducing\n",
    "    r_mean = np.mean(r_out, axis = 0)\n",
    "    r_out = r_out - r_mean\n",
    "    r_out = np.array(r_out, dtype = np.float32)\n",
    "    return de_in, y_out, r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "683304cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n",
      "float32\n",
      "(4, 207, 1)\n",
      "It takes 112.761 sec.\n"
     ]
    }
   ],
   "source": [
    "st = float(time.time())\n",
    "de_in, y_out, r_out = regs(\n",
    "    seqgan_g, \n",
    "    seqgan_d, \n",
    "    enData = encoder_train[:4],\n",
    "    beam = 2,\n",
    ")\n",
    "print(de_in.dtype)\n",
    "print(y_out.dtype)\n",
    "print(r_out.dtype)\n",
    "print(r_out.shape)\n",
    "#print(r_out)\n",
    "print('It takes {0:.3f} sec.'.format(float(time.time()) - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f3dbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mleG.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "mleD.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "811ef4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqgan_g.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "seqgan_g_old.load_weights(f'./{g_name}/slowmleG.h5')\n",
    "seqgan_d.load_weights(f'./{folder_name}/mleD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8ec50a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 10s 13ms/step - loss: 0.5332 - accuracy: 0.8420\n",
      "0.5332431793212891\n",
      "768/768 [==============================] - 11s 14ms/step - loss: 0.5335 - sparse_categorical_crossentropy: 0.5335\n",
      "0.5334709286689758\n"
     ]
    }
   ],
   "source": [
    "loss, _acc = mleG.evaluate([encoder_vali, decoder_vali], teacher_vali)\n",
    "print(loss)\n",
    "loss, _acc = seqgan_g.evaluate([encoder_vali, decoder_vali], teacher_vali) # Full-test-data NLL test\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49041829",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c291ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "minibatch_size = 32\n",
    "epoch = 300\n",
    "g_best_loss = 999\n",
    "num_batch = int(len(teacher_train)//batch_size)\n",
    "report_iter = 5\n",
    "g_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "623b9b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "model saved.\n",
      "Batch: 1, AdvG loss: 0.3585, D loss: 0.6822, G NLL: 0.5436, D NLL: 0.6897, elapsed time: 1207 secs\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch: 6, AdvG loss: 0.3616, D loss: 0.6797, G NLL: 0.5437, D NLL: 0.6898, elapsed time: 1088 secs\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch: 11, AdvG loss: 0.3717, D loss: 0.6762, G NLL: 0.5437, D NLL: 0.6898, elapsed time: 1083 secs\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch: 16, AdvG loss: 0.3661, D loss: 0.6745, G NLL: 0.5438, D NLL: 0.6899, elapsed time: 1323 secs\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch: 21, AdvG loss: 0.3710, D loss: 0.6728, G NLL: 0.5438, D NLL: 0.6900, elapsed time: 1452 secs\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "Batch 25\n",
      "Batch 26\n",
      "Batch: 26, AdvG loss: 0.3687, D loss: 0.6712, G NLL: 0.5438, D NLL: 0.6901, elapsed time: 1442 secs\n",
      "Batch 27\n",
      "Batch 28\n",
      "Batch 29\n",
      "Batch 30\n",
      "Batch 31\n",
      "Batch: 31, AdvG loss: 0.3686, D loss: 0.6690, G NLL: 0.5438, D NLL: 0.6902, elapsed time: 1447 secs\n",
      "Batch 32\n",
      "Batch 33\n",
      "Batch 34\n",
      "Batch 35\n",
      "Batch 36\n",
      "Batch: 36, AdvG loss: 0.3750, D loss: 0.6671, G NLL: 0.5438, D NLL: 0.6903, elapsed time: 1446 secs\n",
      "Batch 37\n",
      "Batch 38\n",
      "Batch 39\n",
      "Batch 40\n",
      "Batch 41\n",
      "Batch: 41, AdvG loss: 0.3759, D loss: 0.6650, G NLL: 0.5438, D NLL: 0.6905, elapsed time: 1462 secs\n",
      "Batch 42\n",
      "Batch 43\n",
      "Batch 44\n",
      "Batch 45\n",
      "Batch 46\n",
      "Batch: 46, AdvG loss: 0.3768, D loss: 0.6632, G NLL: 0.5438, D NLL: 0.6907, elapsed time: 1450 secs\n",
      "Batch 47\n",
      "Batch 48\n",
      "Batch 49\n",
      "Batch 50\n",
      "Batch 51\n",
      "Batch: 51, AdvG loss: 0.3717, D loss: 0.6614, G NLL: 0.5438, D NLL: 0.6909, elapsed time: 1458 secs\n",
      "Batch 52\n",
      "Batch 53\n",
      "Batch 54\n",
      "Batch 55\n",
      "Batch 56\n",
      "Batch: 56, AdvG loss: 0.3699, D loss: 0.6595, G NLL: 0.5438, D NLL: 0.6911, elapsed time: 1452 secs\n",
      "Batch 57\n",
      "Batch 58\n",
      "Batch 59\n",
      "Batch 60\n",
      "Batch 61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-095e7562762f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mseqgan_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0menData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_real_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mbeam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             )\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# Train G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-8ffd99d24a5b>\u001b[0m in \u001b[0;36mregs\u001b[0;34m(model_g, model_d, enData, beam)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mstart_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Fix first q words and see the reward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mend_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mbeam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m         \u001b[0mr_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-73d7fc55f004>\u001b[0m in \u001b[0;36mregs_mcmc\u001b[0;34m(model_g, model_d, en_in, y_inp, start_on, end_on, beam)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1536\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mnum_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_mcmc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         )\n\u001b[1;32m     69\u001b[0m         \u001b[0mmost_possible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-73d7fc55f004>\u001b[0m in \u001b[0;36mmodel_g_predict_batch\u001b[0;34m(model, _inp_list, batch_size, num_data, step, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_data\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_inp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_inp_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mis_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 421\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 421\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int32'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;31m# Instead of casting the variable as in most layers, cast the output, as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup_v2\u001b[0;34m(params, ids, max_norm, name)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[0;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[1;32m    328\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m       transform_fn=None)\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[0;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0;31m# params. Similar to the case np > 1 where parallel_dynamic_stitch is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0;31m# outside the scioe of all with ops.colocate_with(params[p]).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;31m# Flatten the ids. There are two cases where we need to do this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3950\u001b[0;31m         _ctx, \"Identity\", name, input)\n\u001b[0m\u001b[1;32m   3951\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3952\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_g_loss = tf.keras.metrics.Mean()\n",
    "train_d_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "sec = int(time.time())\n",
    "\n",
    "g_nll_list = []\n",
    "counter = 0\n",
    "p_time = time.time() # Estimate the time for 50 batches.\n",
    "for e in range(epoch):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_g_loss.reset_states()\n",
    "    train_d_loss.reset_states()\n",
    "    \n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(encoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(decoder_train)\n",
    "    np.random.seed(sec)\n",
    "    np.random.shuffle(teacher_train)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(encoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(decoder_vali)\n",
    "    #np.random.seed(sec)\n",
    "    #np.random.shuffle(teacher_vali)\n",
    "    for i in range(num_batch):\n",
    "        print(f'Batch {counter+1}')\n",
    "        #----------------------------- \n",
    "        # Evaluate the loss on model G every 50 batches\n",
    "        if counter % report_iter == 0:\n",
    "            syn_vali = [] # syn for Synthesized Data\n",
    "            for j in range(0, 1024, 128): # Define Test data size\n",
    "                t = seqgan_g.predict(\n",
    "                    [encoder_vali[j:j+128], decoder_vali[j:j+128]], \n",
    "                    batch_size = 128\n",
    "                )\n",
    "                syn_vali.append(t)\n",
    "            syn_vali = np.vstack(syn_vali)\n",
    "            g_vali_loss = loss_object(teacher_vali[:1024], syn_vali)\n",
    "            # Evaluate the loss on model D\n",
    "            syn_vali = np.argmax(syn_vali, axis = -1)\n",
    "            r_vali_fake = seqgan_d(np.vstack([teacher_vali[:1024], syn_vali]))\n",
    "            d_vali_loss = loss_d(\n",
    "                np.vstack([\n",
    "                    np.ones((1024, 1)), \n",
    "                    np.zeros((1024, 1))]),\n",
    "                r_vali_fake,\n",
    "            )\n",
    "            g_nll_list.append(g_vali_loss)\n",
    "            # Save the model G if it is better\n",
    "            if g_vali_loss < g_best_loss:\n",
    "                g_best_loss = g_vali_loss\n",
    "                ckpt_save_path = ckpt_g_manager.save()\n",
    "                ckpt_save_path = ckpt_d_manager.save()\n",
    "                print('model saved.')\n",
    "        #----------------------------- \n",
    "        # Data preparation\n",
    "        # Real part\n",
    "        e_real_batch = encoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        x_real_batch = decoder_train[i*batch_size:(i+1)*batch_size]\n",
    "        y_real_batch = teacher_train[i*batch_size:(i+1)*batch_size]\n",
    "        r_real_batch  = np.ones((batch_size, 1))\n",
    "        # Synthesized part\n",
    "        y_fake_batch, x_fake_batch = inference(\n",
    "            seqgan_g, \n",
    "            e_real_batch,\n",
    "        )\n",
    "        r_fake_batch = np.zeros((batch_size, 1))\n",
    "        # Real + fake and then training\n",
    "        x_batch = np.vstack((x_real_batch, x_fake_batch))\n",
    "        y_batch = np.vstack((y_real_batch, y_fake_batch))\n",
    "        r_batch = np.vstack((r_real_batch, r_fake_batch))\n",
    "        #----------------------------- \n",
    "        # Train D with minibatch approaches.\n",
    "        for j in range(0, batch_size, minibatch_size):\n",
    "            y_minibatch = y_batch[j:j+minibatch_size]\n",
    "            r_minibatch = r_batch[j:j+minibatch_size]\n",
    "            _, d_loss = train_d_step(\n",
    "                y_minibatch, \n",
    "                r_minibatch,\n",
    "            )\n",
    "            train_d_loss.update_state(d_loss)\n",
    "        #----------------------------- \n",
    "        # Update Generator after certain batches\n",
    "        if counter % g_iter == 0:\n",
    "            gST = time.time()\n",
    "            de_in_mcmc, y_out_mcmc, r_out_mcmc = regs(\n",
    "                seqgan_g, \n",
    "                seqgan_d, \n",
    "                enData = e_real_batch,\n",
    "                beam = 2,\n",
    "            )\n",
    "            # Train G\n",
    "            gstep = minibatch_size\n",
    "            for k in range(0, len(de_in_mcmc), gstep):\n",
    "                # Update model\n",
    "                g_loss = train_g_step(\n",
    "                    e_real_batch[k:k+gstep],\n",
    "                    de_in_mcmc[k:k+gstep],\n",
    "                    y_out_mcmc[k:k+gstep],\n",
    "                    r_out_mcmc[k:k+gstep],\n",
    "                )\n",
    "            train_g_loss.update_state(g_loss)\n",
    "            # Teacher forcing\n",
    "            g_loss = seqgan_g.train_on_batch([e_real_batch, x_real_batch], y_real_batch)\n",
    "            train_g_loss.update_state(g_loss)\n",
    "            # Update the G model with old parameters\n",
    "            seqgan_g.save(f'{folder_name}/seqgan_g_old.h5')\n",
    "            seqgan_g_old.load_weights(f'{folder_name}/seqgan_g_old.h5')\n",
    "        #-----------------------------\n",
    "        # 50 batches in time\n",
    "        if counter % report_iter == 0:\n",
    "            elapsed_time = time.time() - p_time\n",
    "            p_time = time.time()\n",
    "            print(\n",
    "                f'Batch: {counter+1}, '\n",
    "                f'AdvG loss: {train_g_loss.result():.4f}, '\n",
    "                f'D loss: {train_d_loss.result():.4f}, '\n",
    "                f'G NLL: {g_vali_loss:.4f}, '\n",
    "                f'D NLL: {d_vali_loss:.4f}, '\n",
    "                f'elapsed time: {elapsed_time:.0f} secs'\n",
    "            )\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "143e3701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(g_nll_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a320bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5af422d950>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_g.restore(ckpt_g_manager.latest_checkpoint)\n",
    "ckpt_d.restore(ckpt_d_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da4c1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 65)\n",
      "(64, 207)\n",
      "(64, 207)\n",
      "(64, 207, 1)\n"
     ]
    }
   ],
   "source": [
    "print(e_real_batch.shape)\n",
    "print(de_in_mcmc.shape)\n",
    "print(y_out_mcmc.shape)\n",
    "print(r_out_mcmc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fcbd79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 207, 199)\n",
      "(4, 207, 1)\n",
      "(4, 207)\n"
     ]
    }
   ],
   "source": [
    "pred = seqgan_g((encoder_vali[:4], decoder_vali[:4]))\n",
    "print(pred.shape)\n",
    "\n",
    "reward = np.ones((pred.shape[0], pred.shape[1], 1))\n",
    "print(reward.shape)\n",
    "\n",
    "loss = loss_object2(teacher_vali[:4], pred)\n",
    "print(loss.shape)\n",
    "\n",
    "loss = policy_loss_function(teacher_vali[:4], pred, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d22c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
